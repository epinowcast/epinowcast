---
title: Resources for help with Stan
description: "How to address issues you may encounter with Stan"
author: Michael DeWitt
output: rmarkdown::html_document
bibliography: library.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa-numeric-superscript-brackets.csl
vignette: >
  %\VignetteIndexEntry{Help with Stan}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```


<!-->

- [ ] What is Stan
- [ ] Issues with installation
- [ ] Issues with compilation and paths
- [ ] Issues with model fitting
  - [ ] Adapt Delta
  - [ ] Max Tree Depth
  - [ ] Number of samples, priors, Rhat/ ESS
- [ ] Other resources

<-->

# Epinowcast and Stan

[Stan](https://mc-stan.org/) is the probabilistic programming language and statistical platform for statistical modelling that powers the Bayesian inference in `{epinowcast}`.
The statistical models used in `{epinowcast}` are primarily written in the [Stan programming language](https://mc-stan.org/docs/reference-manual/index.html), a statically typed programming language with syntax similar to C/C++.
`{epinowcast}` utilises the [`{cmdstanr}`](https://mc-stan.org/cmdstanr/) package to inferface with CmdStan, the program which excutes the models written in the Stan programming language.
It is important to understand that CmdStan is a program that is **distinct** from but interfaced through R.
As described in the `{epinowcast}` project [README](./index.html), you will need to install [`{cmdstanr}`](https://mc-stan.org/cmdstanr/)  R package which also has the ability to install CmdStan using an R interface. 
Additionally, you will need to make sure that the software required by CmdStan is installed and configured on your machine.

## Ensuring you have the proper toolchain {.toolchain}

The Stan code that is written in the `{epinowcast}` package converted[^1] to optimised C++ code and then compiled to machine readable instructions.
Because Stan needs a several programs to execute this compilation process such as the build tool [make](https://en.wikipedia.org/wiki/Make_(software)) and a C++ compiler, you will need to ensure that your system has the appropriate supporting software, known as a toolchain.
The steps to install this additional software are in addition to R and are **platform specific**.
As a reminder, these installation steps occur **outside of R**.
The Stan team has assembled very detailed instructions for each platform:

* [**Windows**](https://mc-stan.org/docs/cmdstan-guide/cmdstan-installation.html#windows)
* [**MacOS**](https://mc-stan.org/docs/cmdstan-guide/cmdstan-installation.html#macos)
* [**Linux**](https://mc-stan.org/docs/cmdstan-guide/cmdstan-installation.html#linux)


After completing your platform specific toolshain installation, you can move on to R.

## Now install CmdStanR and CmdStan

Now you can open a session of R using your favourite IDE like Rstudio or Vscode.
You'll need to install the CmdStanR package, the R package which allows you to interface with CmdStan through R code.
There is a [very detailed installation guide available for CmdStanR](https://mc-stan.org/cmdstanr/articles/cmdstanr.html) which provides the authorative installation instructions.

Install the CmdStanR package using the below code.

```r
# In a fresh R session run the following in your R console.
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))

```

To ensure that your toolchain instllation occured sucessfully, run the following code in your R terminal:

```r
check_cmdstan_toolchain()
```

This function will report back if the toolchain is available and set-up as follows:

```r
#> The C++ toolchain required for CmdStan is setup properly!
```

If you do not get this message, return to [the installation instuctions](#toolchain) and ensure that all steps were followed.

Assuming you have the the toolchain installed, you can install CmdStanR.

```r
cmdstanr::install_cmdstan(cores = 2)
```

# Epinowcast modeling

## Installation

As described in the project README, you can install the `"{epinowcast}"` package within R.

```r
# Stable version from:
install.packages("epinowcast", repos = "https://epinowcast.r-universe.dev")

# Development version from:
remotes::install_github("epinowcast/epinowcast", dependencies = TRUE)
```

## Running your first model

The first time you fit a model with `{epinowcast}` will be **slow** compared to future fits!
This is normal as all of the Stan code is being compiled for the first time.
Note that the compiled Stan binaries will live in your user package directory (or wherever you have defined your package libraries).
Because of this package architecture

- Each time you install a new version of `{epinowcast}` you will experience this longer compilation time the first time you fit a model.
- If you upgrade your version of CmdStan, you will likely need to recompile your models. This may occur automatically, or necessitate re-installing `{epinowcast}`.


## Setting `enw_fit_opts`

The `enw_fit_opts` allows you to set several critical components for the Stan computational engine.
These parameters are passed to Stan during the model fitting process and have an influence on computation time and quality of the model fit.
Knowing when and if the defaults need to be changed is an important part of the Bayesian workflow.[@gelmanBayesianWorkflow2020]
All of the parameters are passed to the `sampling` function available from [`{cmdstanr}`](https://mc-stan.org/cmdstanr/reference/model-method-sample.html).

# Failures modes

In this section we will discuss the most common issues when working with `{epinowcast}` specifically and CmdStan/ Bayesian inference more generally.
The solutions to these issues typically require you to investigate your [sampler settings](#samplerParams), [model settings](#modelParams), or [interogate your data](#modelData) further.

## Sampler settings {.samplerParams}

`{epinowcast}` provides users the ability to pass arguments directly to CmdStan which can improve model run time and produce better inferences.
These parameters can be passed the `enw_fit_opts` function.

### `threads_per_chain` and `chains`

One of the key components of Bayesian inference is creating draws from independent Markov chains.
To assess convergence and the reliability of a given posterior distribution it is vital that at least two chains are used with **`4` chains** being the more common default.

Stan allows for multi-threading and the Stan code used within `{epinowcast}` has tried to take advantage of these capabilities where possible.
Multi-theading allows for the calculations to be spread across multiple threads, which could accelerate inference by allowing embarassingly parallel calculations to be spread across threads and then later combined.
If possible, a good default is `2`, however, if you have available compute on your machine, you can increase this to a higher value and may see some fit time reductions.
Please note that the `theads_per_chain` has not impact on model convergence or fittings and is purely a means of speeding up the model fitting time.

::: {.alert .alert-warning}
**The product of the `thread_per_chain` and `chains`** arguments should be equal to or less than the number of cores on your machine! 
:::

### iter_warmup and iter_sampling {.iters}

The number of samples using for the warmup phase of Stan and the number of sampling iterations are controlled by the `iter_warmup` and `iter_sampling` arguments, respectively.
Stan requires a sufficient number of warmup iterations to dynamically estimate the step change sizes during model fitting. 
Unlike with Gibbs sampling (such as the method used in JAGS), you do not need to set large values for `iter_warmup` or `iter_sampling`.
Conversely, setting large values for iterations is a sign of poor model fit and indicates that other approaches need to be employed (e.g., `priors`, `adapt_delta`, `max_treedepth`)
Typically, 1000-2000 samples for `iter_warmup` and `iter_sampling` are sufficient.

### max_treedepth {.maxTree}

This value controls the size of the trajectory taken by the sample (in power of 2) take for each step.
If this value is too low, the sampler may terminate too early causing excess runtimes.
You can increase the `max_treedepth` to an integer value greater than `10` up to `15` (or lower).
Given the complexity of the models used in `{epinowcast}` it is common to have the `max_treedepth` set between 12 and 15.

### adapt_delta {.adaptDelta}

This parameter sets the target average proposal acceptable probability during NUTS sampling (and is a real number values between 0 and 1).
Higher values of `adapt_delta` will result in smaller step sizes during sampling which will slow the model fitting time but can help to address *divergent transitions.*
The default value is 0.8, but it is likely that this will need to be set slightly higher like 0.9 to 0.99 given the complexity of the models being fit.

### Some decent defaults

For a computer with 8 cores, a reasonable configuration would be the following:

```r
enw_fit_opts(
    save_warmup = FALSE,
    pp = TRUE,
    chains = 4,
    threads_per_chain = 2,
    adapt_delta = 0.95,
    max_treedepth = 12,
    iter_sampling = 2000,
    iter_warmup = 1000,
    show_messages = FALSE
)
```

## Model settings {.modelParams}

### Setting priors {.settingPriors}

Setting sensible priors is important for Bayesian inference.
When pre-processing your data, you can retrieve the prior arguments using the `enw_reference` function.
As shown below, you can retrieve your current files and maniupate them as needed.

```r
(default_priors <- enw_reference(data = enw_example("preprocessed")))
#> $formula
#> $formula$parametric
#> [1] "~1"
#> 
#> 
#> $data
#> $data$refp_fdesign
#>   (Intercept)
#> 1           1
#> 
#> $data$refp_fintercept
#> [1] 1
#> 
#> $data$refp_fnrow
#> [1] 1
#> 
#> $data$refp_findex
#>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
#> [39] 1 1 1
#> 
#> $data$refp_fnindex
#> [1] 41
#> 
#> $data$refp_fncol
#> [1] 0
#> 
#> $data$refp_rdesign
#>      (Intercept)
#> attr(,"assign")
#> [1] 0
#> 
#> $data$refp_rncol
#> [1] 0
#> 
#> $data$model_refp
#> [1] 2
#> 
#> 
#> $priors
#>             variable
#> 1:     refp_mean_int
#> 2:       refp_sd_int
#> 3: refp_mean_beta_sd
#> 4:   refp_sd_beta_sd
#>                                                       description
#> 1:         Log mean intercept for parametric reference date delay
#> 2: Log standard deviation for the parametric reference date delay
#> 3:    Standard deviation of scaled pooled parametric mean effects
#> 4:      Standard deviation of scaled pooled parametric sd effects
#>             distribution mean sd
#> 1:                Normal  1.0  1
#> 2: Zero truncated normal  0.5  1
#> 3: Zero truncated normal  0.0  1
#> 4: Zero truncated normal  0.0  1
#> 
#> $inits
#> function (data, priors) 
#> {
#>     priors <- enw_priors_as_data_list(priors)
#>     fn <- function() {
#>         init <- list(refp_mean_int = numeric(0), refp_sd_int = numeric(0), 
#>             refp_mean_beta = numeric(0), refp_sd_beta = numeric(0), 
#>             refp_mean_beta_sd = numeric(0), refp_sd_beta_sd = numeric(0))
#>         if (data$model_refp > 0) {
#>             init$refp_mean_int <- array(rnorm(1, priors$refp_mean_int[1], 
#>                 priors$refp_mean_int[2]/10))
#>         }
#>         if (data$model_refp > 1) {
#>             init$refp_sd_int <- array(abs(rnorm(1, priors$refp_sd_int[1], 
#>                 priors$refp_sd_int[2]/10)))
#>         }
#>         init$refp_mean <- rep(init$refp_mean_int, data$refp_fnrow)
#>         init$refp_sd <- rep(init$refp_sd_int, data$refp_fnrow)
#>         if (data$refp_fncol > 0) {
#>             init$refp_mean_beta <- array(rnorm(data$refp_fncol, 
#>                 0, 0.01))
#>             if (data$model_refp > 1) {
#>                 init$refp_sd_beta <- array(rnorm(data$refp_fncol, 
#>                   0, 0.01))
#>             }
#>         }
#>         if (data$refp_rncol > 0) {
#>             init$refp_mean_beta_sd <- array(abs(rnorm(data$refp_rncol, 
#>                 priors$refp_mean_beta_sd_p[1], priors$refp_mean_beta_sd_p[2]/10)))
#>             if (data$model_refp > 1) {
#>                 init$refp_sd_beta_sd <- array(abs(rnorm(data$refp_rncol, 
#>                   priors$refp_sd_beta_sd_p[1], priors$refp_sd_beta_sd_p[2]/10)))
#>             }
#>         }
#>         return(init)
#>     }
#>     return(fn)
#> }
#> <bytecode: 0x55927f15dbb0>
#> <environment: 0x559280451700>
#> 

```

In the above example, if you have some reason to believe that the standard deviation of the means used could we smaller, you could reduce them by half to 0.5.

```r

new_priors <- default_priors$priors

new_priors[ ,sd := 0.5]

```

You could then pass these new priors to the `epinowcast` function.

```r
epinowcast(pobs,
  expectation = expectation_module,
  fit = fit,
  model = multithread_model,
  priors = new_priors
)
```
Similarly, you could take an emperical Bayes approach and use the posteriors of a [fitted model as described in another vignette](https://package.epinowcast.org/articles/germany-age-stratified-nowcasting.html#using-the-inflated-posterior-as-a-prior).


## Exploring your data {.modelData}

<!--
#TODO Non-stationarity, longer time scales, multi-modality from known etiologies
-->

It is important to understand the data being passed to `epinowcast` and have some ideas regarding the data generating process for your data.
For instance, if there are significant changes in your reporting triangle, this could manifest as multi-modality in the posterior distribution (i.e., Stan is trying to fit two different reporting delays with the same parameters).
These different reporting regimes could result in long model run times, very wide posteriors, and ultimately nonsensical inferences.
Given the nuances of your data, you may need to identify and fit different regimes of your data.
These problems can also manifest over longer timescales, so while more data are generally better, too much data can result in ill-fitting models.


## Common failure modes

### My model takes too long to run

One of the more common issues with Bayesian inference is that the sampler may take a long time to run.
This can occur because the sampler is having difficulty exploring the posterior parameter space given the model and your data.
You can a few simple steps to assist with this:


1. Increase the [`adapt_delta`](.adaptDelta) argument to 15 which will allow longer trajectories to used for steps when sampling. This is especially important if the `per_at_max_treedepth` value is high in the returned CmdStan diagnostics.
2. Use more [informative priors](.settingPriors). 
3. Try to simplify the model first to understand potential degeneracies.
4. Reduce the amount of data you are trying to fit. This might include reducing the duration of time overwhich you are trying to fit. Once you can confirm that the model will fit your data, it may just be a question of computational power when fitting the larger data. 


### Divergent transitions 

CmdStan may alert you that you have ["divergent transitions"](https://mc-stan.org/docs/reference-manual/divergent-transitions.html) detected during your model fit.

```r
#>1: There were 32 divergent transitions after warmup.
```

A high number of divergent transitions indicates that the model outputs are not to be trusted.
The first step in addressing this is to increase the [`adapt_delta`](#adaptDelta) argument to a numeric near one (e.g., 0.99 or 0.999).
This will allow for a smaller step size and may result in more realiable inferences.
Importantly, if the number of divergent transitions remains high, your model may be misspecified given the data that are available.
At this point it may be worthwhile to investigate if the model paramterisation is correct for the data you have available.


### My `r_hat`s are high and by `ess`s are low

High values of `r_hat`, the Gelman-Rubin statistic used to measure converge, indicates a lack of convergence.
Values greater than 1.05 are considered unreliable.
Similarly, lower values for the [effective sample size](https://mc-stan.org/docs/reference-manual/effective-sample-size.html) is especially problematic.
The effective sample size provides insight into how many independent samples you have drawn from the posterior, accounting for the autocorrelation within the Markov chains.
Ideally you want these values to be near your total number of samples passed in the `iter_sample` argument.
If `r_hat` is large and `ess_bulk`/ `ess_tail` are low, consider:

1. Increasing your [adapt_delta](#adaptDelta) argument to a numeric value near 1 (e.g., 0.99). This will reduce the step size and could help with sampling.
2. Use more [informative priors](.settingPriors). 


### The posterior estimates are very wide

Wide posterior values indicate that there is a high degree of uncertainity given the data and model.
If not other warnings are shown (e.g., divergent transitions, higher ESS), then this is simply the inference given the available data.
Posteriors could be reduced through the use of stronger, more informative [priors](#settingPriors).

# Other resources

The Stan community is a pretty warm and opening place and receptive to helping others.
If you find yourself having issues with `"{epinowcast}"`, reach out!

## Technical issues

- [epinowcast forum](https://community.epinowcast.org/)
- [epinowcast issues](https://github.com/epinowcast/epinowcast/issues)
- [Stan forums](https://discourse.mc-stan.org/)
- [Stan guide to warnings](https://mc-stan.org/misc/warnings.html)

## Learning more about Stan and Bayesian inference

- [](https://betanalpha.github.io/writing/)
- Aki Vehtari [Bayesian Data Analysis](https://avehtari.github.io/BDA_R_demos/demos_rstan/) and [case studies](https://users.aalto.fi/~ave/casestudies.html)



[^1]: The Stan code is actually first passed to a Stan specific compiled written in Ocaml called [stanc3](https://github.com/stan-dev/stanc3).
The optimised C++ code generated from this first step is then passed to the C++ compiler.