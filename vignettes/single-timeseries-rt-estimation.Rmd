---
title: "Estimating the effective reproduction number in real-time for a single timeseries with reporting delays"
description: ""
author: Sam Abbott
opengraph:
  image: 
    src: figures/performance-1.png
output: 
  bookdown::html_vignette2:
    fig_caption: yes
    code_folding: show
pkgdown:
  as_is: true
vignette: >
  %\VignetteIndexEntry{Estimating the effective reproduction number in real-time for a single timeseries with reporting delays}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  eval = TRUE,
  cache = TRUE,
  message = FALSE,
  warning = FALSE,
  dpi = 330
)
```

::: {.alert .alert-info}
This vignette borrows heavily from this [nowcasting example](https://github.com/epiforecasts/nowcasting.example) by Sebastian Funk and Sam Abbott.
:::

- Introduce the package and sign post to further documentation
- Introduce the problem targeted in this vignette (Rt estimation by date of infection where observed cases are right truncated due to reporting delays). 

::: {.alert .alert-primary}
## Use case {-}

An epidemic is in progress. We want to know what the **effective reproduction number is at the current time**. This is the average number of secondary infections caused by a single infected individual at a given point in time and is a measure of the transmissibility of the infection in the population at that time.

Unfortunately, we can't directly observe infections and the data we do observe suffers from reporting delays.

:::

::: {.alert .alert-secondary}
### What we have {-}

  1. A linelist of cases with a date of interest (for example hospitalisation date) and a date of report (for example date of hospitalisation report);
  2. An estimate of the distribution of times from infection to hospitalisation;
  3. An estimate of the generation time distribution, which is the distribution of the time intervals between the infection of a primary case and the infection of secondary cases caused by the primary case.
 
:::

## Getting setup

See the [package documentation](https://epiforecasts.io/epinowcast/) for guidance on installing the package and getting setup with `cmdstanr` (the backend used for fitting models). 

As well as the `epinowcast` package we will use the following packages in this vignette.

```{r setup}
library(epinowcast)
library(data.table) 
library(purrr)
library(ggplot2)
```

::: {.alert .alert-secondary}

Here we make use of `data.table` for simple data transformations but tools from the tidyverse or base R tools could just as easily be used. We also use `purrr` to make use of the `partial()` function which allows us to partially specify a function. This is useful for specifying the model as we can specify the parts of the model that are common to all models and then specify the parts that are specific to each model. Finally we use `ggplot2` for plotting.

:::

## Introducing the case study data: COVID-19 hospitalisations in Germany

- Germany hospitalisations
- Introduce the data
- Explain why we are using it here. Reference the Germany nowcasting preprint.
- Graph data (or use a graph from the Germany nowcasting preprint)

## Model

### Overview

The `epinowcast` package provides a flexible framework for modelling hopsitalisations 


### Expected hospitalisations

In settings where data is sparse or where users want to understand the underlying generative process our flexible default model is likely not a good choice. In these settings our generic model offers a range of options that are context specific. Our generic model is currently based on a renewal process [@Fraser2007; @Cori2013] with additional latent reporting delays [@EpiNow2; @Abbott2020; @Bhatt2020]. As previously noted [@champredon], this corresponds to the commonly used Susceptible-Exposed-Infected-Recovered (SEIR) model when appropriate generation time is specified [@champredon]

#### Instantaneous reproduction number

We model the instantaneous reproduction number ($R_t$) on the log scale as a weekly random walk as follows

\begin{align}
  \text{log} (R_{t}) &= r_0 + \sum_{i = 0}^{t \% 7} \epsilon_i \\
  \epsilon_i &\sim \text{Normal}\left(0, \sigma_{\epsilon} \right) \\
  \sigma_{\epsilon} &\sim \text{HalfNormal}\left(0, 1 \right)
\end{align}

where $r_0$ is the intercept, and $\sum_{i = 0}^{t \% 7} \epsilon_i$ is a weekly random walk.

#### Latent infections

We model the expected number of infections/latent notifications ($\lambda^l$) using a renewal process [@Fraser2007; @Cori2013]. This model is a generalisation of the default model and can be used to model the expected number of latent notifications in a setting where the generation time is not fixed to be a day. It implies that current infections/notifications are dependent on past infections/notifications based on a kernel (usually interpreted as the generation time or serial interval). An instantaneous daily growth rate model can be recovered by setting the generation time to be fixed at 1 day. The model is defined as follows,

\begin{align}
  \lambda^l_{t} &\sim \text{LogNormal}\left(\mu^{l}, \sigma^{l} \right),\ t \leq P \\
  \lambda^l_{t} &= R_{t} \sum_{p = 1}^{P} g\left(t - p \right)  \lambda^l_{t-p},\ t \gt P  
\end{align}

#### Latent reporting delay and ascertainment

In some settings there may be additional reporting delays on top of those that are directly observed in the data, and therefore "nowcastable", a common example is the delay from exposure to symptom onset. For these settings we support modelling "latent" reporting delays as a convolution of the underlying expected counts with the potential for these delays to vary over time and by group. This implementation is similar to that implemented in `EpiNow2` and `epidemia` as well as other similar models  [@EpiNow2; @Abbott2020; @Bhatt2020; @Lison2022]. In addition to this we support modelling ascertainment through the use of improper probability mass functions (i.e. by not enforcing a sum to 1 constraint) and inferring ascertainment where possible (for example day of the week reporting patterns).

\begin{align}
  \lambda_{t} &= \nu_{t \% 7} \sum_{\tau = 0}^{L - 1} f_{g}\left(t - \tau \right)  \lambda^l_{t - \tau} \\
  \text{log} (\nu_{i}) &\sim \text{Normal}\left(0, \sigma_{\nu} \right) \\
  \sigma_{\nu} &\sim \text{HalfNormal}\left(0, 1 \right) \\
\end{align}

Where $\nu_{i}$ is a random effect for each day of the week which represents reporting periodicity.

#### Specifying the model using `epinowcast::enw_expectation()`

```{r expected-infections}
expectation_module <- partial(
  epinowcast::enw_expectation,
  r = ~ 1 + rw(week),
  generation_time = c(0.1, 0.4, 0.4, 0.1),
  observation = ~ (1 | day_of_week),
  latent_reporting_delay = c(0.05, 0.3, 0.6, 0.05)
)
```

### Delay distribution

#### Defining the delay distribution

Given case counts both by date of reference and by date of report, we can estimate the reporting delay distribution directly and jointly with the underlying process model, rather than relying on external estimates from other sources (though we may want to account for external information in our priors). In the following section, we describe our default parametric delay distribution model and its extension into a generic, highly flexible delay model based on discrete time-to-event modelling.

We consider the reporting delay to follow a $\text{LogNormal} \left(\mu^d, \sigma^d \right)$ distribution, with parameters

\begin{align}
  \mu^d &\sim \text{Normal} \left(0, 1 \right) \\
  \sigma^d &\sim \text{Half-Normal} \left(0, 1 \right).
\end{align}

This distribution is discretised into daily probabilities $p_{t,d}$ and adjusted for the maximum delay, see `vignette("distributions")` for details.

#### Specifying the model using `epinowcast::enw_reference()`

```{r reference_module}
reference_module <- partial(enw_reference, ~1, distribution = "lognormal")
```

### Observation model and nowcast

Expected notifications by date of hospitalisations ($t$) and reporting date can now be found by multiplying expected final notifications for each $t$ with the probability of reporting for each day of delay ($p_{t,d}$). We assume a Poisson observation model and produce a nowcast of final observed hospitalisations at each reference date by summing posterior estimates for unobserved notification and observed notifications for that reference date.

\begin{align}
  n_{t,d} \mid \lambda_{t},p_{t,d}  &\sim \text{Poisson} \left(\lambda_{t} \times p_{t,d),\ t=1,...,T. \\
  N_{g,t} &= \sum_{d=0}^{D} n_{g,t,d}
\end{align}

#### Specifying the model using `epinowcast::enw_obs()`

```{r observation-module}
obs_module <- partial(enw_obs, family = "negbin")
```

## Simulated data to evaluate the model

### Simulating the data

- Rt trajectory with a change point and a trend
- Specify a gamma distributed generation time.
- Use the renewal equaton to simulate cases (uu)
- Specify a delay from infection to hospitalisation.
- Specify a day of the week reporting model.
- Specify a reporting fraction.
- Convolve the reporting delay with the underlying cases to get expected hospitalisations.
- Add noise to the expected hospitalisations to get observed hospitalisations
- Specify a lognormal reporting delay model.
- Project the observed hospitalisations using the reporting delay into a linelist.

### Preprocessing the simulated data

```{r, eval = FALSE}
synth_obs <- linelist_to_obs(synth_linelist)

# Make a retrospective dataset
retro_synth_obs <- synth_obs |>
  # Remove the last 40 days of reproted data
  enw_filter_report_dates(remove_days = 40) |>
  # INlcude on refernece dates within the last 40 days
  enw_filter_reference_dates(include_days = 40)

# Get latest observations for the same time period
latest_synth_obs <- enw_latest_data(synth_obs) |>
  enw_filter_reference_dates(remove_days = 40, include_days = 40)

# Preprocess observations
synth_pobs <- enw_preprocess_data(retro_synth_obs, max_delay = 30)
germany_pobs
```

### Visualising the simulated data

#### Plotting the simulated data by report date

```{r latest-data, eval = FALSE}
plot_obs_by_report_date <- function(pobs, report_dates) {
  pobs$new_confirm[[1]] |>
    mutate(report_date = case_when(
      report_date <= as.Date("2020-03-15") ~ as.Date("2020-03-15"),
      report_date <= as.Date("2020-04-01") ~ as.Date("2020-04-01"),
      report_date <= as.Date("2020-04-15") ~ as.Date("2020-04-15"),
      report_date <= max(report_date) ~ as.Date(max(report_date))
    )) |>
    group_by(reference_date, report_date) |>
    summarise(confirm = sum(new_confirm), .groups = "drop") |>
    mutate(report_date = factor(report_date) |>
      forcats::fct_rev()
    ) |>
    ggplot() +
    aes(
      x = reference_date, y = confirm, fill = report_date, group = report_date
    ) +
    geom_col(
      data = pobs$new_confirm[[1]] |>
        group_by(report_date) |>
        summarise(confirm = sum(new_confirm)),
      fill = "lightgrey", alpha = 0.8,
      aes(x = report_date)
    ) +
    geom_col(position = "stack", alpha = 1, col = "lightgrey") +
    geom_vline(
      aes(xintercept = as.Date(report_date)), linetype = 2, alpha = 0.9
    ) +
    scale_y_continuous(labels = ~ scales::comma(.x, accuracy = 1)) +
    scale_fill_brewer(palette = "Blues") +
    theme_bw() +
    labs(
      x = "Reference date",
      y = "Reported notifications",
      fill = "Report date"
    ) +
    theme(legend.position = "bottom")
}

```

### Fitting the `epinowcast` model

We first need to specify some fitting options for the model using `cmdstanr` (more information on these options can be found in the `cmdstanr` documentation). We use 2 chains with 2 threads per chain (so using 4 CPU cores in total) 500 warmup samples and 1000 iterations per chain. As this is a complex model we set `adapt_delta` to 0.99 (the default is 0.8)  that the Hamiltonian Monte Carlo sampler can explore the posterior distribution more efficiently. We have also set the `max_treedepth` to 12 (the default is 10) to again ensure that the Hamiltonian Monte Carlo sampler can explore the posterior distribution more efficiently. Finally, we set `save_warmup` to `FALSE` to save space (we don't need the warmup samples for this analysis).

```{r fit-options}
fit_module <- partial(enw_fit_opts,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 500,
  iter_sampling = 1000,
  adapt_delta = 0.99,
  max_treedepth = 12,
  save_warmup = FALSE
)
```

We also need to compile the model using `cmdstanr` before fitting it (we only have to do this once after installing the package).

```{r compile-model}
epinowcast_model <- enw_model(threads = TRUE, profile = FALSE)
```

Now we are ready to bring together all the modules we have specified, combine them with the model we have just compiled, and fit our synthetic data.

```{r, eval = FALSE}
synth_nowcast <- epinowcast(synth_pobs,
  expectation = expectation_module(data = synth_pobs),
  reference = reference_module(data = synth_pobs),
  fit = fit_module(),
  model = model
)
```

::: {.alert .alert-info}

You may see a number of warning messages from `cmdstanr` when fitting the model. These generally occur when the model is being initialised and are due to this process not currently being optimised in `epinowcast`. The model should still fit correctly unless these warnings continue into the fitting process (outside of the warmup phase). This is something we are working on improving in future versions of `epinowcast`.

:::

### Plot the nowcast against observed data

```{r plot-synth-nowcast, eval = FALSE}
plot(synth_nowcast, latest_obs)
```

### Plot the effective reproduction number

```{r plot-synth-rt, eval = FALSE}
rt <- synth_nowcast$fit[[1]] |>
  enw_posterior(variables = "r")
cols <- c("mean", "median", "q5", "q20", "q80", "q95")
rt[, (cols) := lapply(.SD, exp), .SDcols = cols]
rt <- cbind(
  expectation_module(data = synth_pobs)$data_raw$r[, .(date)], rt
)

ggplot(rt) +
  aes(x = date) +
  geom_line(aes(y = median), linewidth = 1, alpha = 0.6) +
  geom_line(aes(y = mean), linetype = 2) +
  geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2, linewidth = 0.2) +
  geom_ribbon(aes(ymin = q20, ymax = q80, col = NULL), alpha = 0.2) +
  geom_hline(yintercept = 1, linetype = 2) +
  theme_bw() +
  labs(
    x = "Reference date",
    y = "Effective reproduction number"
  )
```

### Plot the posterior distribution of the reporting delay

```{r plot-germany-delay, eval = FALSE}

```

### Plot the posterior distribution of the day of the week reporting model

## Fitting the model to COVID-19 hospitalisations in Germany

### Preprocess the data

Load and filter germany hospitalisations for the 00+ age group (i.e. all hospitalisations regardless of age) and just the national counts.

```{r}
germany_hosp <- germany_covid19_hosp[location == "DE"][age_group %in% "00+"]
germany_hosp <- germany_hosp[, .(reference_date, report_date, confirm)]
germany_hosp
```

Make sure that the data is complete and filter so that the latest reported data is from the 1st of October 2021.
```{r}
germany_hosp <- germany_hosp |>
  enw_filter_report_dates(latest_date = "2021-09-01") |>
  enw_complete_dates()
```

As for the synthetic example we need to make a "real-time" dataset and get the latest observations for the same time period as this will allows us to compare real-time estimates with what was ultimately retrospectively observed. Again as in the synthetic example we use 40 days of data with a maximum delay of 30 days. We also construct a retrospective dataset using the same time period but assuming that the data is complete (i.e. everything has been reported). We can then use this to compare the real-time estimates with the retrospective estimates.

```{r}
# Make a real-time dataset
realtime_germany <- germany_hosp |>
  # Remove the last 40 days of reported data
  enw_filter_report_dates(remove_days = 40) |>
  # Include on refernece dates within the last 30 days
  enw_filter_reference_dates(include_days = 30)

# Make a retrospective dataset
retro_germany <- germany_hosp[!is.na(reference_date)] |>
  enw_filter_reference_dates(remove_days = 40, include_days = 30)

# Get latest observations for the same time period
latest_obs <- germany_hosp |>
  enw_latest_data() |>
  enw_filter_reference_dates(remove_days = 40, include_days = 30)
```

Finally, we preprocess that data ready for modelling. As in the synthetic example this produces several useful intermediate datasets that can be used for plotting and checking the model fit as well as summary information about the proprocessed data (such as the number of groups, the maximum delay, and the number of observations in each group).

```{r}
germany_pobs <- enw_preprocess_data(realtime_germany, max_delay = 30)
germany_pobs
```

and do the same for the retrospective data

```{r}
retro_germany_pobs <- enw_preprocess_data(retro_germany, max_delay = 30)
```

### Fit the `epinowcast` model

On real-time data,

```{r}
# Fit nowcast model with these modules and produce a nowcast
germany_nowcast <- epinowcast(
  data = germany_pobs,
  expectation = expectation_module(data = germany_pobs),
  reference = reference_module(data = germany_pobs),
  obs = obs_module(data = germany_pobs),
  fit = fit_module(),
  model = epinowcast_model
)
```

and then on retrospective data.

```{r}
retro_germany_nowcast <- epinowcast(
  data = retro_germany_pobs,
  expectation = expectation_module(data = retro_germany_pobs),
  reference = reference_module(data = retro_germany_pobs),
  obs = obs_module(data = retro_germany_pobs),
  fit = fit_module(),
  model = epinowcast_model
)
```

### Plot the real-time nowcast against observed data

```{r plot-germany-nowcast
plot(germany_nowcast, latest_obs)
```

### Plot the effective reproduction number

```{r plot-germany-rt}
rt <- germany_nowcast$fit[[1]] |>
  enw_posterior(variables = "r")
cols <- c("mean", "median", "q5", "q20", "q80", "q95")
rt[, (cols) := lapply(.SD, exp), .SDcols = cols]
rt <- cbind(
  expectation_module(data = germany_pobs)$data_raw$r[, .(date)], rt
)

ggplot(rt) +
  aes(x = date) +
  geom_line(aes(y = median), linewidth = 1, alpha = 0.6) +
  geom_line(aes(y = mean), linetype = 2) +
  geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2, linewidth = 0.2) +
  geom_ribbon(aes(ymin = q20, ymax = q80, col = NULL), alpha = 0.2) +
  geom_hline(yintercept = 1, linetype = 2) +
  theme_bw() +
  labs(
    x = "Reference date",
    y = "Effective reproduction number"
  )
```

### Plot expected latent cases

```{r plot-germany-latent-cases}
latent_exp_cases <- enw_posterior(
  germany_nowcast$fit[[1]],
  variables = "exp_llatent"
)
latent_exp_cases[, (cols) := lapply(.SD, exp), .SDcols = cols]
latent_exp_cases <- cbind(
  enw_extend_date(
    expectation_module(data = germany_pobs)$data_raw$r[, .(date, .group = 1)],
    days = germany_nowcast$data[[1]]$expl_lrd_n,
    direction = "start"
  ),
  latent_exp_cases
)

ggplot(latent_exp_cases) +
  aes(x = date) +
  geom_line(aes(y = median), linewidth = 1, alpha = 0.6) +
  geom_line(aes(y = mean), linetype = 2) +
  geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2, linewidth = 0.2) +
  geom_ribbon(aes(ymin = q20, ymax = q80, col = NULL), alpha = 0.2) +
  theme_bw() +
  labs(
    x = "Reference date",
    y = "Expected latent cases"
  )
```

### Plot expected reported cases

```{r plot-germany-reported-cases}
exp_cases <- enw_posterior(
  germany_nowcast$fit[[1]],
  variables = "exp_lobs"
)
exp_cases[, (cols) := lapply(.SD, exp), .SDcols = cols]
exp_cases <- cbind(
  expectation_module(data = germany_pobs)$data_raw$observation,
  exp_cases
)

exp_cases <- enw_latest_data(germany_hosp)[, date := reference_date][
  exp_cases,
  on = "date"
]

ggplot(exp_cases) +
  aes(x = date) +
  geom_point(aes(y = confirm)) +
  geom_line(aes(y = median), linewidth = 1, alpha = 0.6) +
  geom_line(aes(y = mean), linetype = 2) +
  geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2, linewidth = 0.2) +
  geom_ribbon(aes(ymin = q20, ymax = q80, col = NULL), alpha = 0.2) +
  theme_bw() +
  labs(
    x = "Reference date",
    y = "Expected reported cases"
  )
```

::: {.alert .alert-primary}
  ## Summary {-}

:::

::: {.alert .alert-secondary}
  ### Strengths {-}

  - We have used a single model to estimate the effective reproduction number and the expected number of latent and reported cases from right truncated data. This means that we have propogated uncertainty from the estimation of the effective reproduction number into the estimation of the expected number of latent and reported cases which would be difficult using a mulit-stage approach.

  ### Limitations {-}

  - Assumed a known and static generation time distribution and latent reporting delay distribution. In reality these would need to be estimated from data, have uncertainty, and be liable to change over time.
  - Used a fixed parametric reporting delay distribution. In reality this would likely vary over time and depend on things like day of the week reporting effects. This could be addressed by using a more flexible reporting delay distribution which is supported by `epinowcast`.

  ### Alternative models {-}

  - `EpiNow2`:
  - `EpiEstim`:
  - `epidemia`:

### Further work {-}

  - Use a more flexible reporting delay distribution.
  - Use a more flexible generation time distribution.
  - Use a more flexible model for the effective reproduction number.
  - Add functionality to allow forecasting beyond the horizon of the observed data.

:::

::: {.alert .alert-primary}
  ## Conclusions {-}

:::

## References