---
title: "Estimating the effective reproduction number in real-time for a single timeseries with reporting delays"
description: ""
author: Sam Abbott
opengraph:
  image: 
    src: figures/performance-1.png
output: 
  bookdown::html_vignette2:
    fig_caption: yes
    code_folding: show
pkgdown:
  as_is: true
bibliography: resources/library.json
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa-numeric-superscript-brackets.csl
link-citations: true
vignette: >
  %\VignetteIndexEntry{Estimating the effective reproduction number in real-time for a single timeseries with reporting delays}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE,
  cache = TRUE,
  message = FALSE,
  warning = FALSE,
  dpi = 330
)
```

::: {.alert .alert-warning}
This vignette is partly based on this [nowcasting example](https://github.com/epiforecasts/nowcasting.example) by Sebastian Funk and Sam Abbott.
:::

In this case study we walk through a simple approach to jointly estimating the effective reproduction number over time and the delay from a positive test to this test being reported. For more on the `epinowcast` package see the [documentation](https://package.epinowcast.org/).

::: {.alert .alert-primary}
## Use case {-}

An epidemic is in progress. We want to know what the **effective reproduction number is at the current time**. This is the average number of secondary infections caused by a single infected individual at a given point in time and is a measure of the transmissibility of the infection in the population at that time.

Unfortunately, we can't directly observe infections and the data we do observe suffers from reporting delays.

:::

::: {.alert .alert-secondary}

### What we have {-}

1. A linelist of cases with a date of interest (for example test positive date) and a date of report (for example date of hospitalisation report);
2. An estimate of the distribution of times from infection to positive test;
3. An estimate of the generation time distribution, which is the distribution of the time intervals between the infection of a primary case and the infection of secondary cases caused by the primary case.
4. An estimate of the ascertainment rate, which is the proportion of infections that are reported as hospitalisations.
 
### What do we do {-}

1. Visualise and contextualise the data this case study uses (COVID-19 hositalisations in Germany);
2. Specify a joint model of the effective reproduction number, the delay from infection to hospitalisation and the delay from hospitalisation to report;
3. Fit this model to both the data that would have been available in real-time, and retrospectively;
4. Visualise the nowcast from the real-time data in comparison to the data that was ultimately observed;
5. Compare real-time and retrospective reproduction number estimates and delay distribution estimates;
6. Outline the limitations and strengths of this approach and highlight areas where it can be extended.
 
:::

## Getting setup

See the [package documentation](https://epiforecasts.io/epinowcast/) for guidance on installing the package and getting setup with `cmdstanr` (the backend used here for fitting models). 

As well as the `epinowcast` package we will use the following packages in this vignette.

```{r setup}
library(epinowcast)
library(data.table)
library(purrr)
library(ggplot2)
```

::: {.alert .alert-warning}

- Here we make use of `data.table` for simple data transformations but tools from the tidyverse or base R tools could just as easily be used;
- We also use `purrr` to make use of the `partial()` function which allows us to partially specify a function for later reuse. This is useful for specifying the model as we can specify the parts of the model that are common to all models and then specify the parts that are specific to each model when we call the updated function;
- Finally, we use `ggplot2` for plotting.

:::

## Introducing the data: COVID-19 hospitalisations in Germany

### Overview

In this case study, we use data sourced from the [Robert Koch Institute via the Germany Nowcasting hub](https://github.com/KITmetricslab/hospitalization-nowcast-hub/wiki/Truth-data#role-an-definition-of-the-seven-day-hospitalization-incidence). The data represent hospitalisation counts by date of positive test and date of test report in Germany. These data have been used extensively for nowcasting and forecasting COVID-19 hospitalisations in Germany and are described in detail in [Wolffram et al. (2023)](https://doi.org/10.1101/2023.04.17.23288668). We use these data as they are a good example of the type of data that are available in many settings. We first summarise the data,

```{r}
summary(germany_covid19_hosp)
```

In this case study we only consider national level data without stratification by age group. We can filter these data using `data.table` as follows,


```{r}
germany_hosp <- germany_covid19_hosp[location == "DE"][age_group %in% "00+"]
germany_hosp <- germany_hosp[, .(reference_date, report_date, confirm)]
germany_hosp
```

### Data transformations

These data are already in a format that can be used with `epinowcast`, as it contains

- a reference date (column `reference_date`): the date of the observation, in this example the date of a positive test
- a report date (column `report_date`): the date of report for a given set of observations by reference date
- a count (column `confirm`): the total number of hospitalisations by reference date and report date. Note that this is cumulative by report date.

The package also provides a range of tools to convert data from line list, incidence, or other common formats into the required format (see [Data converters](https://package.epinowcast.org/dev/reference/index.html#data-converters)). For example we could convert the data to a individual case linelist,

```{r}
germany_covid19_hosp_linelist <- germany_covid19_hosp |>
  enw_add_incidence() |>
  enw_incidence_to_linelist()

germany_covid19_hosp_linelist
```

This linelist could then be itself converted into the format `epinowcast` requires using the `enw_linelist_to_incidence()` function,

```{r}
incidence_from_linelist <- enw_linelist_to_incidence(
  germany_covid19_hosp_linelist,
  reference_date = "reference_date",
  report_date = "report_date",
  by = c("age_group", "location"),
  max_delay = 30
)

incidence_from_linelist
```

::: {.alert .alert-warning}
Here we have specifed the `reference_date` and `report_date` columns, the `by` columns (which are used to group the data), and the `max_delay` which is the maximum delay between the reference date and the report date (note that the observed delay is longer than our specified delay and so is used instead). The `enw_linelist_to_incidence()` function will then calculate the incidence by reference date and report date for each group.
:::

### Filering the data

For this case study we will only consider data from the 1st of March 2020 onwards. We can filter the data using `data.table` as follows,

```{r}
complete_germany_hosp <- germany_hosp |>
  enw_filter_report_dates(latest_date = "2021-08-01") |>
  enw_filter_reference_dates(earliest_date = "2021-05-01") |>
  enw_complete_dates(missing_reference = FALSE) |>
  enw_add_incidence()
```

```{r}
rt_nat_germany <- complete_germany_hosp |>
  enw_filter_report_dates(latest_date = "2021-07-01")
rt_nat_germany
```

```{r}
retro_nat_germany <- complete_germany_hosp |>
  enw_filter_reference_dates(latest_date = "2021-07-01")
retro_nat_germany
```

```{r}
latest_germany_hosp <- retro_nat_germany  |>
  enw_latest_data()
head(latest_germany_hosp, n = 10)
```

### Visualising the data

```{r}
gh_vis_cohorts <- copy(retro_nat_germany)[,
  report_date := fcase(
      report_date <= as.Date("2021-05-15"), as.Date("2021-05-15"),
      report_date <= as.Date("2021-06-01"), as.Date("2021-06-01"),
      report_date <= as.Date("2021-06-15"), as.Date("2021-06-15"),
      report_date <= as.Date("2021-07-01"), as.Date("2021-07-01"),
      report_date <= as.Date("2021-07-15"), as.Date("2021-07-15"),
      report_date <= as.Date("2021-08-01"), as.Date("2021-08-01")
  ) |>
    factor(levels = rev(c(
      "2021-05-15", "2021-06-01", "2021-06-15", "2021-07-01",
      "2021-07-15", "2021-08-01"
      ))
    )
]

gh_vis_cohorts_by_reference <- gh_vis_cohorts[,
 .(confirm = sum(new_confirm)), by = .(reference_date)
]

gh_vis_cohorts_by_ref_rep <- gh_vis_cohorts[,
  .(confirm = sum(new_confirm)), by = .(reference_date, report_date)
]

gh_vis_cohorts_by_ref_rep |>
  ggplot() +
  aes(
    x = reference_date, y = confirm, fill = report_date, group = report_date
  ) +
  geom_col(position = "stack", alpha = 1, col = "lightgrey") +
  geom_vline(
    aes(xintercept = as.Date(report_date)), linetype = 2, alpha = 0.9
  ) +
  scale_y_continuous(labels = \(x)(scales::comma(x, accuracy = 1))) +
  scale_fill_brewer(
    palette = "Blues", aesthetics = c("color", "fill")
  ) +
  theme_bw() +
  labs(
    x = "Date of positive test",
    y = "Hospitalised cases by date of positive test",
    fill = "Report date"
  ) +
  guides(fill = guide_legend(reverse = TRUE)) +
  theme(legend.position = "bottom")
```

## Model

### Overview

The `epinowcast` package provides a flexible framework for modelling hopsitalisations 


### Expected hospitalisations

In settings where data is sparse or where users want to understand the underlying generative process our flexible default model is likely not a good choice. In these settings our generic model offers a range of options that are context specific. Our generic model is currently based on a renewal process [@Fraser2007; @Cori2013] with additional latent reporting delays [@EpiNow2; @Abbott2020; @Bhatt2020]. As previously noted [@champredon], this corresponds to the commonly used Susceptible-Exposed-Infected-Recovered (SEIR) model when appropriate generation time is specified [@champredon]

#### Instantaneous reproduction number

We model the instantaneous reproduction number ($R_t$) on the log scale as a weekly random walk as follows

\begin{align}
  \text{log} (R_{t}) &= r_0 + \sum_{i = 0}^{t \% 7} \epsilon_i \\
  \epsilon_i &\sim \text{Normal}\left(0, \sigma_{\epsilon} \right) \\
  \sigma_{\epsilon} &\sim \text{HalfNormal}\left(0, 1 \right)
\end{align}

where $r_0$ is the intercept, and $\sum_{i = 0}^{t \% 7} \epsilon_i$ is a weekly random walk.

#### Latent infections

We model the expected number of infections/latent notifications ($\lambda^l$) using a renewal process [@Fraser2007; @Cori2013]. This model is a generalisation of the default model and can be used to model the expected number of latent notifications in a setting where the generation time is not fixed to be a day. It implies that current infections/notifications are dependent on past infections/notifications based on a kernel (usually interpreted as the generation time or serial interval). An instantaneous daily growth rate model can be recovered by setting the generation time to be fixed at 1 day. The model is defined as follows,

\begin{align}
  \lambda^l_{t} &\sim \text{LogNormal}\left(\mu^{l}, \sigma^{l} \right),\ t \leq P \\
  \lambda^l_{t} &= R_{t} \sum_{p = 1}^{P} g\left(t - p \right)  \lambda^l_{t-p},\ t \gt P  
\end{align}

#### Latent reporting delay and ascertainment

In some settings there may be additional reporting delays on top of those that are directly observed in the data, and therefore "nowcastable", a common example is the delay from exposure to symptom onset. For these settings we support modelling "latent" reporting delays as a convolution of the underlying expected counts with the potential for these delays to vary over time and by group. This implementation is similar to that implemented in `EpiNow2` and `epidemia` as well as other similar models  [@EpiNow2; @Abbott2020; @Bhatt2020; @Lison2022]. In addition to this we support modelling ascertainment through the use of improper probability mass functions (i.e. by not enforcing a sum to 1 constraint) and inferring ascertainment where possible (for example day of the week reporting patterns).

\begin{align}
  \lambda_{t} &= \nu_{t \% 7} \sum_{\tau = 0}^{L - 1} f_{g}\left(t - \tau \right)  \lambda^l_{t - \tau} \\
  \text{log} (\nu_{i}) &\sim \text{Normal}\left(0, \sigma_{\nu} \right) \\
  \sigma_{\nu} &\sim \text{HalfNormal}\left(0, 1 \right) \\
\end{align}

Where $\nu_{i}$ is a random effect for each day of the week which represents reporting periodicity.

#### Specifying the model using `epinowcast::enw_expectation()`

```{r expected-infections}
expectation_module <- partial(
  epinowcast::enw_expectation,
  r = ~ 1 + rw(week),
  generation_time = c(0.1, 0.4, 0.4, 0.1),
  observation = ~ (1 | day_of_week),
  latent_reporting_delay = c(0.05, 0.3, 0.6, 0.05)
)
```

- TODO: Define the generation time from a literature source
- TODO: Define the delay from infection to reporting from a literature source. Use a convolution of the incubation period and the delay between symptom onset and positive test.

### Delay distribution

#### Defining the delay distribution

Given case counts both by date of reference and by date of report, we can estimate the reporting delay distribution directly and jointly with the underlying process model, rather than relying on external estimates from other sources (though we may want to account for external information in our priors). 

We consider the reporting delay to follow a $\text{LogNormal} \left(\mu^d, \sigma^d \right)$ distribution, with parameters

\begin{align}
  \mu^d &\sim \text{Normal} \left(0, 1 \right) \\
  \sigma^d &\sim \text{Half-Normal} \left(0, 1 \right).
\end{align}

This distribution is discretised into daily probabilities $p_{t,d}$ and adjusted for the maximum delay, see `vignette("distributions")` for details.

#### Specifying the model using `epinowcast::enw_reference()`

```{r reference_module}
reference_module <- partial(enw_reference, ~1, distribution = "lognormal")
```

### Observation model and nowcast

Expected notifications by date of positive test ($t$) and reporting date can now be found by multiplying expected final notifications by date of positive test for each $t$ with the probability of reporting for each day of delay ($p_{t,d}$). We assume a Poisson observation model and produce a nowcast of final observed hospitalisations at each reference date by summing posterior estimates for unobserved notification and observed notifications for that reference date.

\begin{align}
  n_{t,d} \mid \lambda_{t},p_{t,d}  &\sim \text{Poisson} \left(\lambda_{t} \times p_{t,d) \right),\ t=1,...,T. \\
  N_{g,t} &= \sum_{d=0}^{D} n_{g,t,d}
\end{align}

#### Specifying the model using `epinowcast::enw_obs()`

```{r observation-module}
obs_module <- partial(enw_obs, family = "poisson")
```

## Fitting the model to COVID-19 hospitalisations in Germany

### Preprocess the data

We first need to make sure that the data is complete and filter so that the latest reported data is from the 1st of October 2021.

```{r}
germany_hosp <- germany_hosp |>
  enw_filter_report_dates(latest_date = "2021-09-01") |>
  enw_complete_dates(missing_reference = FALSE)
```

We now need to make a "real-time" dataset and get the latest observations for the same time period as this will allows us to compare real-time estimates with what was ultimately retrospectively observed. We use 40 days of data with a maximum delay of 30 days. 

```{r}
# Make a real-time dataset
realtime_germany <- germany_hosp |>
  # Remove the last 40 days of reported data
  enw_filter_report_dates(remove_days = 40) |>
  # Include on refernece dates within the last 30 days
  enw_filter_reference_dates(include_days = 30)

# Get latest observations for the same time period
latest_obs <- germany_hosp |>
  enw_filter_reference_dates(remove_days = 40, include_days = 30) |>
  enw_latest_data()
```

We also construct a "retrospective" dataset using the same time period for reference date but using all reported data. We can then use this to compare the real-time estimates with what could be estimated once data was completely observed (i.e., after the epidemic has ended). This is useful for assessing the performance of the model in real-time. 

```{r}
# Make a retrospective dataset
retro_germany <- germany_hosp |>
  enw_filter_reference_dates(remove_days = 40, include_days = 30)

```

Finally, we preprocess these data ready for modelling. This produces several useful intermediate datasets that can be used for plotting and checking the model fit as well as summary information about the proprocessed data (such as the number of groups, the maximum delay, and the number of observations in each group).

```{r}
germany_pobs <- enw_preprocess_data(realtime_germany, max_delay = 30)
germany_pobs
```

and do the same for the retrospective data

```{r}
retro_germany_pobs <- enw_preprocess_data(retro_germany, max_delay = 30)
retro_germany_pobs
```

### Fitting the `epinowcast` model

Before we are ready to fit the model we need to first specify some fitting options for using `cmdstanr` (more information on these options can be found in the `cmdstanr` documentation). We use 2 chains with 2 threads per chain (so using 4 CPU cores in total) 500 warmup samples and 1000 iterations per chain. As this is a complex model we set `adapt_delta` to 0.99 (the default is 0.8)  that the Hamiltonian Monte Carlo sampler can explore the posterior distribution more efficiently. We have also set the `max_treedepth` to 12 (the default is 10) to again ensure that the Hamiltonian Monte Carlo sampler can explore the posterior distribution more efficiently. Finally, we set `save_warmup` to `FALSE` to save space (we don't need the warmup samples for this analysis), and `pp` to `TRUE` so that we can use posterior predictive checks to assess the model fit.

```{r fit-options}
fit_module <- partial(enw_fit_opts,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 500,
  iter_sampling = 1000,
  adapt_delta = 0.99,
  max_treedepth = 12,
  save_warmup = FALSE,
  pp = TRUE
)
```

We also need to compile the model using `cmdstanr` before fitting it (we only have to do this once after installing the package).

```{r compile-model}
epinowcast_model <- enw_model(threads = TRUE, profile = FALSE)
```

Now we are ready to bring together all the modules we have specified, combine them with the model we have just compiled, and fit our synthetic data. We first fit to the data that would have been available in real-time,

```{r}
germany_nowcast <- epinowcast(
  data = germany_pobs,
  expectation = expectation_module(data = germany_pobs),
  reference = reference_module(data = germany_pobs),
  obs = obs_module(data = germany_pobs),
  fit = fit_module(),
  model = enw_model(threads = TRUE, profile = FALSE)
)
```

and then on the retrospectivly observed data.

```{r}
retro_germany_nowcast <- epinowcast(
  data = retro_germany_pobs,
  expectation = expectation_module(data = retro_germany_pobs),
  reference = reference_module(data = retro_germany_pobs),
  obs = obs_module(data = retro_germany_pobs),
  fit = fit_module(),
  model = enw_model(threads = TRUE, profile = FALSE)
)
```

::: {.alert .alert-warning}

  You may see a number of warning messages from `cmdstanr` when fitting the model. These generally occur when the model is being initialised and are due to this process not currently being optimised in `epinowcast`. The model should still fit correctly unless these warnings continue into the fitting process (outside of the warmup phase). This is something we are working on improving in future versions of `epinowcast`.

:::

### Visualising the nowcast based on real-time data

We first plot the nowcast based on real-time data. Effectively here we are trying to use our model to estimate the hospitalisations that will ultimately be reported based on the data that is currently available. We can compare this to the most recent observations to see how well the model is doing.

```{r plot-germany-nowcast}
#| fig.cap: "Nowcast of hospitalisations in Germany based on real-time data"
plot(germany_nowcast, latest_obs)
```

In this instance, the model has done a good job of estimating the number of hospitalisations that will ultimately be reported based on the data that is currently available. This is not always the case, and the model can sometimes over or under estimate the number of hospitalisations that will ultimately be reported. 

::: {.alert .alert-warning}

  An important thing to note here is that this model is clearly not perfect with more complete data being less well estimated by the model. This likely indicates some misspecification in the reporting delay model which could be fixed by making it more complex or even by making it entirely non-parametric (vs being based on a LogNormal).

:::

### Real-time and retrospective estimates of the effective reproduction number

A key output of the model is the posterior distribution of the effective reproduction number. We can plot this for both the real-time and retrospective data to see how the estimates change as more data becomes available. Ideally, we would hope that the real-time estimates would overlap with the retrospective estimates. This would indicate that our model is able to accurately estimate hospitalisations that will be ultimately reported based on those that have already been reported.

```{r plot-germany-rt}
get_rt_posterior <- function(nowcast, expectation = expectation_module) {
  rt <- enw_posterior(nowcast$fit[[1]], variables = "r")
  cols <- c("mean", "median", "q5", "q20", "q80", "q95")
  rt[, (cols) := lapply(.SD, exp), .SDcols = cols]
  rt <- cbind(
    expectation(data = nowcast)$data_raw$r[, .(date)], rt
  )
  return(rt)
}

rt <- rbind(
    get_rt_posterior(germany_nowcast)[, Data := "Real-time"],
    get_rt_posterior(retro_germany_nowcast)[, Data := "Retrospective"]
  )

ggplot(rt) +
  aes(x = date, col = Data, fill = Data) +
  geom_line(aes(y = median), linewidth = 1, alpha = 0.6) +
  geom_line(aes(y = mean), linetype = 2) +
  geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2, linewidth = 0.2) +
  geom_ribbon(aes(ymin = q20, ymax = q80, col = NULL), alpha = 0.2) +
  geom_hline(yintercept = 1, linetype = 2) +
  scale_fill_brewer(palette = "Dark2", aesthetics = c("color", "fill")) +
  theme_bw() +
  labs(
    x = "Date of infection",
    y = "Effective reproduction number"
  ) +
  theme(legend.position = "bottom")
```

### Estimates of the delay from testing postive to hospitalisation both in real-time and retrospectively

We can also plot the posterior distribution of the delay from testing positive to hospitalisation. This is the delay that is used to estimate the number of hospitalisations that will ultimately be reported based on the number of positive tests that have been reported. We can plot this for both the real-time and retrospective data to see how the estimates change as more data becomes available. Ideally, we would hope that the real-time estimates would overlap with the retrospective estimates. This would indicate that our model is able to accurately estimate hospitalisations that will be ultimately reported based on those that have already been reported.

```{r plot-germany-delay}
extract_epinowcast_cdf <- function(nowcast) {
  draws <- nowcast |>
  (\(x) x$fit[[1]]$draws(variables = c("refp_mean", "refp_sd"), format = "df"))() |>
  as.data.table()

  draws[, 
    cdf := purrr::map2(
    `refp_mean[1]`, `refp_sd[1]`,
    ~ data.table(
      delay = 1:26, cdf = plnorm(1:26, .x, .y) /  plnorm(26, .x, .y)
    ))
  ]
  draws <- draws[, rbindlist(cdf)]
  draws <- draws[,
    .(
      mean = mean(cdf),
      lower_90 = quantile(cdf, probs = 0.05),
      upper_90 = quantile(cdf, probs = 0.95)
    ),
    by = "delay"
  ]
}

nowcast_cdf <- list(
  "Real-time" = germany_nowcast,
  "Retrospective" = retro_germany_nowcast
) |>
  map(extract_epinowcast_cdf) |>
  rbindlist(idcol = "Data")

ggplot(nowcast_cdf) +
  aes(x = delay, y = mean, col = Data, fill = Data) +
  geom_line(size = 1.1, alpha = 0.7) +
  geom_ribbon(
    aes(ymin = lower_90, ymax = upper_90), alpha = 0.25
  ) +
  theme_bw() +
  theme(legend.position = "bottom") +
  scale_fill_brewer(palette = "Dark2", aesthetics = c("color", "fill")) +
  guides(
    fill = guide_legend(nrow = 2),
    col = guide_legend(nrow = 2)
  ) +
  labs(
    x = "Delay between positive test and hospitalisation",
    y = "Cumulative density function of the reporting distribution"
  )
```

### Estimates of the number of expected hospitalisations both in real-time and retrospectively

We can also plot the posterior predictions for the number of expected hospitalisations. This is the number of hospitalisations that would be reported if there was no observation error. We can compare this to the number of hospitalisations that are ultimately reported to see how well the model is doing. 

Retrospectively, we would expect the model to fit very well to this data with any differences being due to the observation error. If this is not the case it indicates we may neeed to revisit our model specification to make it closer to the generative process of the data we have.

In real-time, we would expect the model to fit less well to this data as it is trying to estimate the number of hospitalisations that will ultimately be reported based on the data that is currently available.

```{r plot-germany-reported-cases}
get_expected_infections <- function(nowcast, expectation = expectation_module) {
  exp_cases <- enw_posterior(
    nowcast$fit[[1]],
    variables = "exp_lobs"
  )
  cols <- c("mean", "median", "q5", "q20", "q80", "q95")
  exp_cases[, (cols) := lapply(.SD, exp), .SDcols = cols]
  exp_cases <- cbind(
    expectation(data = nowcast)$data_raw$observation,
    exp_cases
  )
  return(exp_cases)
}

exp_cases <- rbind(
  get_expected_infections(germany_nowcast)[, Data := "Real-time"],
  get_expected_infections(retro_germany_nowcast)[, Data := "Retrospective"]
)

exp_cases <- enw_latest_data(germany_hosp)[, date := reference_date][
  exp_cases,
  on = "date"
]

ggplot(exp_cases) +
  aes(x = date, fill = Data, col = Data) +
  geom_point(aes(y = confirm), col = "Black") +
  geom_line(aes(y = median), linewidth = 1, alpha = 0.6) +
  geom_line(aes(y = mean), linetype = 2) +
  geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2, linewidth = 0.2) +
  geom_ribbon(aes(ymin = q20, ymax = q80, col = NULL), alpha = 0.2) +
  theme_bw() +
  labs(
    x = "Date of positive test",
    y = "Expected hospitalisations"
  ) +
  scale_fill_brewer(palette = "Dark2", aesthetics = c("color", "fill")) +
  theme(legend.position = "bottom")
```

As expected the retrospective estimates fit very well to the data. The real-time estimates are slightly less good, but still capture the recent change in trend in the data which would not be possible without a nowcast.

### Posterior predictions for cases by date of postive test and report

Plotting posterior predictions can be a useful way of assessing performance and checking that the model is capturing the underlying data generation process adequately. We can do this using a `plot` method as follows for the real-time data,

```{r pp, fig.width = 16, fig.height = 16, message = FALSE}
plot(germany_nowcast, type = "posterior") +
  facet_wrap(vars(reference_date), scale = "free")
```

::: {.alert .alert-warning}
Visualising the model predictions highlights some clear fitting issues. One clear issue is that there appears to be periodicity in the observed data that is not present in this model. We could address this by using a report date reporting model (via `enw_report()`) that accounts for differences in reporting by weekday.
:::


## Wrapping up

::: {.alert .alert-primary}
  ### Summary {-}
  In this case study we have shown how to use `epinowcast` to estimate the effective reproduction number and the expected number of latent and reported cases from right truncated data. 
  
  We have also shown how to use the package to perform retrospective and real-time nowcasts which can be a useful way of understanding the real-time
  performance of the model.
:::

::: {.alert .alert-secondary}
  ### Strengths {-}

  - We have used a single model to estimate the effective reproduction number and the expected number of latent and reported cases from right truncated data. This means that we have propogated uncertainty from the estimation of the effective reproduction number into the estimation of the expected number of latent and reported cases which would be difficult using a mulit-stage approach.

  ### Limitations {-}

  - Assumed a known and static generation time distribution and latent reporting delay distribution. In reality these would need to be estimated from data, have uncertainty, and be liable to change over time.
  - Used a fixed parametric reporting delay distribution. In reality this would likely vary over time and depend on things like day of the week reporting effects. This could be addressed by using a more flexible reporting delay distribution which is supported by `epinowcast`.

  ### Alternative models {-}

  - `EpiNow2`:
  - `EpiEstim`:
  - `epidemia`:

  ### Further work {-}

    - Use a more flexible reporting delay distribution.
    - Use a more flexible generation time distribution.
    - Use a more flexible model for the effective reproduction number.
    - Add functionality to allow forecasting beyond the horizon of the observed data.
    - Use an observation model that supports overdispersion in the number of reported cases, for example the negative binomial distribution.
:::

## References