[{"path":[]},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behaviour contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behaviour include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behaviour take appropriate fair corrective action response behaviour deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behaviour may reported community leaders responsible enforcement [INSERT CONTACT METHOD]. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behaviour deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behaviour inappropriate. public apology may requested.","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behaviour. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behaviour. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behaviour, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"package.epinowcast.org/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"package.epinowcast.org/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing","title":"Contributing","text":"Development community effort, welcome participation. details forms contribution please see community contribution page.","code":""},{"path":"package.epinowcast.org/dev/CONTRIBUTING.html","id":"community","dir":"","previous_headings":"","what":"Community","title":"Contributing","text":"hold monthly community call discuss package development, research questions, developments literature. also run slack community additional development discussion takes places. welcome new comers, please contact package author invite.","code":""},{"path":"package.epinowcast.org/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing","text":"participating project, agree abide code conduct.","code":""},{"path":"package.epinowcast.org/dev/CONTRIBUTING.html","id":"discussions","dir":"","previous_headings":"","what":"Discussions","title":"Contributing","text":"https://community.epinowcast.org, can post general questions, brainstorm ideas, ask help.","code":""},{"path":"package.epinowcast.org/dev/CONTRIBUTING.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"Contributing","text":"https://github.com/epinowcast/epinowcast/issues bug reports, performance issues, maintenance tasks, feature requests. post, please abide following guidelines. posting new issue, please take moment search existing similar issues order avoid duplication. bug reports: can, please install latest GitHub version epinowcast (.e. remotes::install_github(\"epinowcast/epinowcast\")) verify issue still persists. Describe issue prose clearly concisely possible. problem identify, post minimal reproducible example like one contributors authors can troubleshoot. reproducible example : Runnable: post enough R code data onlooker can create error computer. Minimal: reduce runtime wherever possible remove complicated details irrelevant issue hand. Readable: format code according tidyverse style guide.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/CONTRIBUTING.html","id":"contributions","dir":"","previous_headings":"Development","what":"Contributions","title":"Contributing","text":"External code contributions extremely helpful appreciated. recommended steps. Prior contribution, please propose idea new issue thread reviewer can define intent scope work. Fork repository. Follow GitHub flow create new branch, add commits, open pull request. Discuss code reviewer pull request thread. everything looks good, reviewer merge code project. Please also follow additional guidelines. Respect architecture reasoning package. Depending scope work, may want read design documents (package vignettes). general aim use data.table manipulate data. However, barrier contributing please use tools familiar raise pull request. reviewer work refactor contribution appropriate add dependencies require. possible, keep contributions small enough easily review manually. okay split work multiple pull requests. Format code according package style specified tidyverse style guide. Automatic tidyverse styling can achieved running styler::style_pkg() styler (rewrites files) lintr::lint_package() lintr (provides list complaints resolve). Note: styler::style_pkg() examine roxygen content .e. @examples need check manually. Check code coverage covr::package_coverage(). Automated tests cover new changed functionality pull request. Run overall package checks devtools::check() goodpractice::gp() Describe contribution project’s NEWS.md file. sure mention relevant GitHub issue numbers GitHub name done existing news entries. feel contribution substantial enough author contributor status, please add Authors@R field DESCRIPTION file. general, consider contribution sufficient contributor status several minor single major contributions sufficient author status. planning writing paper similar package extension please note contribution feel free suggest like managed. Note run locally testing suite tests R level code. run cloud (.e PR opened) also run additional tests stan level code. making stan level changes contributors may want run tests manually prior opening PR.","code":""},{"path":"package.epinowcast.org/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 epinowcast authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"package.epinowcast.org/dev/PULL_REQUEST_TEMPLATE.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"NA","text":"PR closes #. [Describe changes made pull request.]","code":""},{"path":"package.epinowcast.org/dev/PULL_REQUEST_TEMPLATE.html","id":"checklist","dir":"","previous_headings":"","what":"Checklist","title":"NA","text":"PR based package issue explicitly linked . included target issue issues PR title Issue(s) issue-numbers: PR title read contribution guidelines. tested changes locally. added updated unit tests necessary. updated documentation required. code follows established coding standards. added news item linked PR. updated package development version one increment NEWS.md DESCRIPTION. reviewed CI checks PR addressed far able.","code":""},{"path":"package.epinowcast.org/dev/STYLE_GUIDE.html","id":null,"dir":"","previous_headings":"","what":"Style Guide","title":"Style Guide","text":"document outlines style guide epinowcast package. guide work progress updated package evolves. welcome contributions guide encourage raise issues submit PRs suggestions. addition guide also follow tidyverse style guide. guide subset tidyverse style guide outlines additional style requirements epinowcast package.","code":""},{"path":"package.epinowcast.org/dev/STYLE_GUIDE.html","id":"naming-conventions","dir":"","previous_headings":"","what":"Naming conventions","title":"Style Guide","text":"use enw_ prefix delineate functions exported epinowcast package. avoid conflicts packages make clear users functions part package. use prefix required internal functions (.e. functions exported) unlikely naming conflicts packages.","code":""},{"path":"package.epinowcast.org/dev/STYLE_GUIDE.html","id":"dependencies","dir":"","previous_headings":"","what":"Dependencies","title":"Style Guide","text":"general aim minimise dependencies packages possible. makes easier maintain package reduces risk breaking changes packages impacting users. However, additional dependencies sometimes necessary improve functionality package. following guidelines followed using adding dependencies: Added Imports Suggests field DESCRIPTION file alphabetical order. dependency Imports required package function Suggests required certain non-core functions vignettes. PR adds dependency clearly stated PR description along justification dependency, number type downstream dependencies, assessment risk dependency breaking. general, barrier adding dependencies high lower Suggests dependencies. generally adding functions external packages (.e. even already dependency) following followed: Documented function documentation using @importFrom tag. Used within functions using package::function format (though make exception functions data.table imported epinowcast).","code":""},{"path":"package.epinowcast.org/dev/STYLE_GUIDE.html","id":"input-types-and-checking","dir":"","previous_headings":"","what":"Input types and checking","title":"Style Guide","text":"support inputs coercible data.table objects using data.table::.data.table(). includes data.frame tibble objects. clearly documented function documentation. required inputs clearly documented function documentation. use internal function coerce_dt() check inputs coercible data.table objects correct columns. function used functions take data input. following function demonstrates pattern (note requires use devtools::load_all() package directory): general, aim check inputs external facing functions. ensure user aware issues input data provide consistent error message. See documentation coerce_dt() details. may also helpful review usage package widely, data-converters.R sensible place start. external facing functions coerce_dt() generally update reference (.e. copy = TRUE set, default). cases users may benefit updating reference external function pass copy argument coerce_dt(). However, external functions may invoked within package functions, case coerce_dt() can often update reference (.e. copy = FALSE set). avoid unnecessary copying data. purely internal functions, coerce_dt() can generally used copy = FALSE, copying unnecessary.","code":"print_dt <- function(dt) {     dt <- coerce_dt(dt, required_cols = c(\"date\", \"cases\"))     return(dt[]) }  print_dt(mtcars) # Error in epinowcast:::coerce_dt(dt, required_cols = c(\"date\", \"cases\")) :  #   The following columns are required: date, cases but are not present among mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb # (all `required_cols`: date, cases) print_dt(data.frame(cases = 1, date = Sys.Date())) #    cases       date # 1:     1 2023-04-27"},{"path":"package.epinowcast.org/dev/STYLE_GUIDE.html","id":"internal-data-manipulation","dir":"","previous_headings":"","what":"Internal data manipulation","title":"Style Guide","text":"data.table objects used internal data manipulation. unfamiliar data.table please see documentation cheatsheet. Prototype code may written tools generally need refactored use data.table submission (PRs help needed please clearly state ). aim use readable vs efficient data.table syntax trade-(course exact trade-requirers developer judgement). example, rather bracket chaining prefer use one-line statements re-assignment. following functions demonstrate patterns: also use list structures complex objects data.table appropriate. appropriate data structure unclear problem hand please flag issue addressing PR discussion.","code":"library(data.table) # we prefer this dt <- as.data.table(mtcars) dt[, mpg := mpg + 1] dt[mpg > 20, cyl := 10] dt[, cyl := cyl + 1] #over this dt_chain <- as.data.table(mtcars)[, mpg := mpg + 1][mpg > 20, cyl := 10][, cyl := cyl + 1]"},{"path":"package.epinowcast.org/dev/STYLE_GUIDE.html","id":"output-types","dir":"","previous_headings":"","what":"Output types","title":"Style Guide","text":"external functions aim output data.table object possible unless custom class used (generally aim inherit data.table class). ensure consistency input types allow easy chaining functions. returned data.table objects followed [] ensures object prints automatically. holds internal external functions order improve user developer experience. following functions demonstrate pattern:","code":"library(data.table)  no_print_iris <- function(dt) {     dt <- coerce_dt(dt)     return(dt) }  print_iris <- function(dt) {     dt <- coerce_dt(dt)     return(dt[]) }  no_print_iris(iris) print_iris(iris) #      Sepal.Length Sepal.Width Petal.Length Petal.Width   Species #   1:          5.1         3.5          1.4         0.2    setosa #   2:          4.9         3.0          1.4         0.2    setosa #   3:          4.7         3.2          1.3         0.2    setosa #   4:          4.6         3.1          1.5         0.2    setosa #   5:          5.0         3.6          1.4         0.2    setosa #  ---                                                             # 146:          6.7         3.0          5.2         2.3 virginica # 147:          6.3         2.5          5.0         1.9 virginica # 148:          6.5         3.0          5.2         2.0 virginica # 149:          6.2         3.4          5.4         2.3 virginica # 150:          5.9         3.0          5.1         1.8 virginica"},{"path":"package.epinowcast.org/dev/articles/distributions.html","id":"available-distributions","dir":"Articles","previous_headings":"","what":"Available distributions","title":"Discretised distributions","text":"currently available parametric delay distributions continuous probability distributions () two parameters \\(\\mu_{g,t}\\) \\(\\upsilon_{g,t}\\). table provides link definition distribution, specifies parameters \\(\\mu_{g,t}\\) \\(\\upsilon_{g,t}\\) mapped parameters distribution (according referenced definition), states resulting mean distribution (discretization adjustment assumed maximum delay).","code":""},{"path":"package.epinowcast.org/dev/articles/distributions.html","id":"discretisation-and-adjustment-for-maximum-delay","dir":"Articles","previous_headings":"","what":"Discretisation and adjustment for maximum delay","title":"Discretised distributions","text":"epinowcast, delays modeled discrete time assumed maximum delay (specified via max_delay argument). Therefore, continuous delay distributions must discretised adjusted maximum delay. exact form discretisation complex due interaction primary secondary events. Rather modelling explicitly, approximate assuming uniform censoring interval 2 days delay. comes assuming daily censoring primary secondary events, together define delay distribution, ignoring potential interactions primary secondary events. result, probability reporting delay \\(d\\) days equals probability reporting delay \\(d+1\\) days less, minus probability reporting delay \\(d-1\\) days less. normalised overall probability reporting delay maximum observed delay, \\(D\\). formally, define terms cumulative distribution function delay distribution. Let \\(F^{\\mu_{g,t}, \\upsilon_{g,t}}\\) cumulative distribution function continuous probability distribution delays parameters \\(\\mu_{g,t}\\) \\(\\upsilon_{g,t}\\). , probability reporting delay \\(d\\) days \\[p_{g,t,d} = \\frac{F^{\\mu_{g,t}, \\upsilon_{g,t}}(d+1) - F^{\\mu_{g,t}, \\upsilon_{g,t}}(d-1)}{F^{\\mu_{g,t}, \\upsilon_{g,t}}(D + 1 ) + F^{\\mu_{g,t}, \\upsilon_{g,t}}(D)}.\\] Unless \\(d = 0\\) instead \\[p_{g,t,0} = \\frac{F^{\\mu_{g,t}, \\upsilon_{g,t}}(1)}{F^{\\mu_{g,t}, \\upsilon_{g,t}}(D + 1 ) + F^{\\mu_{g,t}, \\upsilon_{g,t}}(D)}.\\] Normalising \\(F^{\\mu_{g,t}, \\upsilon_{g,t}}(D+1) + F^{\\mu_{g,t}, \\upsilon_{g,t}}(D)\\), ensures \\(p^{\\prime}_{g,t,d}\\) sum 1. Since \\(F^{\\mu_{g,t}, \\upsilon_{g,t}}(D)\\) probability reporting maximum delay, can also interpreted conditioning distribution maximum delay. Note discretisation normalization, discrete delay distribution obtain approximates original continuous distribution, approximation worse shorter delays.","code":""},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"packages","dir":"Articles","previous_headings":"","what":"Packages","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"use epinowcast package, data.table purrr data manipulation, ggplot2 plotting, knitr produce tables output, loo approximately evaluate sample performance scoringutils evaluate sample forecast performance. vignette includes several models take upwards 30 minutes fit data moderately equipped laptop. speed model fitting CPUs available set number threads used per chain half number real cores available (6 using 2 MCMC chains 12 real cores available). Note may cause conflicts processes running computer issue reduce number threads used.","code":"library(epinowcast) library(data.table) library(purrr) library(ggplot2) library(loo) library(scoringutils) library(knitr) threads <- 6 options(mc.cores = 2)"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"Nowcasting effectively estimation reporting patterns recently reported data. requires data patterns previous observations, typically means time series data reported multiple consecutive days (theory non-consecutive days used yet supported epinowcast). use COVID-19 hospitalisations date positive test Germany stratified age group available 1st September 2020 (40 days data included prior ) example data available real-time hospitalisations date positive test available 20th October represent hospitalisations finally reported. data sourced Robert Koch Institute via Germany Nowcasting hub deconvolved weekly data days negative reported hospitalisations adjusted. first filter data available 1st September last 40 days. Similarly find data available 20th October dates, serve target “true” data.","code":"nat_germany_hosp <- epinowcast::germany_covid19_hosp[location == \"DE\"]  retro_nat_germany <- nat_germany_hosp |>   enw_filter_report_dates(latest_date = \"2021-09-01\") |>   enw_filter_reference_dates(include_days = 40) retro_nat_germany #>       reference_date location age_group confirm report_date #>    1:     2021-07-23       DE       00+      30  2021-07-23 #>    2:     2021-07-24       DE       00+      31  2021-07-24 #>    3:     2021-07-25       DE       00+       8  2021-07-25 #>    4:     2021-07-26       DE       00+       9  2021-07-26 #>    5:     2021-07-27       DE       00+      35  2021-07-27 #>   ---                                                       #> 6023:     2021-07-23       DE     05-14       1  2021-09-01 #> 6024:     2021-07-23       DE     15-34      21  2021-09-01 #> 6025:     2021-07-23       DE     35-59      39  2021-09-01 #> 6026:     2021-07-23       DE     60-79      21  2021-09-01 #> 6027:     2021-07-23       DE       80+       5  2021-09-01 latest_nat_germany <- nat_germany_hosp |>   enw_filter_report_dates(latest_date =\"2021-10-20\") |>   enw_latest_data() |>   enw_filter_reference_dates(latest_date = \"2021-09-01\", include_days = 40)"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"data-preprocessing","dir":"Articles","previous_headings":"","what":"Data preprocessing","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"epinowcast works assuming data preprocessed reporting format requires, coupled meta data reference report dates. enw_preprocess_data() can used , although users can also use internal functions produce custom preprocessing steps. stage arbitrary groupings observations can defined, propagated throughout subsequent modelling steps. data stratified age, hence grouped age group, principle grouping combination groups independent reference report date models. furthermore assume maximum delay required make model identifiable. set 40 days due evidence long reporting delays example data. However, note cases majority right truncation occurs first days increasing maximum delay non-linear effect run-time (.e. model maximum delay 20 days much faster fit 40 days). Note also current formulation delays longer maximum ignored adjusted estimate really data reported maximum delay rather finally reported data. Another key modelling choice make stage model overall hospitalisations jointly age groups rather aggregation age group estimates. implicitly assumes aggregated non-aggregated data comparable (may may case) reporting process shares mechanisms. Another way approach model age stratified hospitalisations aggregate nowcast estimates total counts fitting model.","code":"pobs <- enw_preprocess_data(retro_nat_germany, max_delay = 40, by = \"age_group\") pobs #>                     obs           new_confirm               latest #> 1: <data.table[6020x9]> <data.table[6020x11]> <data.table[287x10]> #>    missing_reference   reporting_triangle       metareference #> 1: <data.table[0x6]> <data.table[287x42]> <data.table[287x9]> #>              metareport          metadelay time snapshots        by groups #> 1: <data.table[560x12]> <data.table[40x4]>   41       287 age_group      7 #>    max_delay   max_date #> 1:        40 2021-09-01"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"models","dir":"Articles","previous_headings":"","what":"Models","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"explore range increasingly complex models using subject area knowledge posterior predictive checks motivate modelling choices.","code":""},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"shared-reporting-delay-distribution","dir":"Articles","previous_headings":"Models","what":"Shared reporting delay distribution","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"first explore relatively simple model assumes reporting delays fixed across age groups time. model default simply call epinowcast. want make use CmdStan’s support within-chain parallelisation first compile default model enabled (also need pass threads_per_chain epinowcast). Note use two chains using 6 threads demonstration general using 4 chains recommended. Also note warm-sampling iterations set default values reduce compute requirements may sufficient many real world use cases. Finally, note silenced fitting progress potential warning messages general done. first visualise observations available model, nowcast final reported hospitalisations actual reported observations. plot chunk nowcast","code":"multithread_model <- enw_model(threads = TRUE) fit <- enw_fit_opts(   save_warmup = FALSE, output_loglik = TRUE, pp = TRUE,   chains = 2, threads_per_chain = threads,    iter_sampling = 500, iter_warmup = 500,   show_messages = FALSE, refresh = 0,   adapt_delta = 0.98, max_treedepth = 15 ) nowcast <- epinowcast(pobs,   fit = fit,   model = multithread_model ) plot(nowcast, latest_obs = latest_nat_germany) +   facet_wrap(vars(age_group), scales = \"free_y\")"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"using-the-inflated-posterior-as-a-prior","dir":"Articles","previous_headings":"Models","what":"Using the inflated posterior as a prior","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"speed model fitting make use posterior information previous model (inflation) parameters. Note truly Bayesian approach situations may problematic.","code":"priors <- summary(   nowcast,   type = \"fit\",   variables = c( \"refp_mean_int\", \"refp_sd_int\", \"sqrt_phi\") ) priors[, sd := sd * 2] priors #>            variable      mean    median         sd        mad        q5 #> 1: refp_mean_int[1] 1.1212838 1.1200800 0.08829821 0.04312883 1.0465460 #> 2:   refp_sd_int[1] 1.7304364 1.7283450 0.09136750 0.04443352 1.6572085 #> 3:      sqrt_phi[1] 0.5943754 0.5945225 0.03663196 0.01858736 0.5650664 #>          q20       q80       q95     rhat ess_bulk ess_tail #> 1: 1.0863640 1.1559380 1.1949585 1.000267 1919.003 779.4026 #> 2: 1.6931480 1.7692440 1.8097575 1.023093 1564.573 706.6420 #> 3: 0.5786032 0.6097982 0.6246353 1.002526 1328.925 783.8134"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"reference-day-of-the-week-effect","dir":"Articles","previous_headings":"Models","what":"Reference day of the week effect","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"underlying data trying nowcast clearly day week periodicity. default model, group specific random walk log notified cases, accounted . Accounting , using random effect day week likely improve nowcast performance reduce computation needed fit model. can specify using enw_expectation() module formula interface follows. visualise nowcasts plot chunk exp_nowcast","code":"expectation_module <- enw_expectation(   ~ 0 + (1 | day_of_week) + (1 | day:.group), data = pobs )  exp_nowcast <- epinowcast(pobs,   expectation = expectation_module,   fit = fit,   model = multithread_model,   priors = priors ) plot(exp_nowcast, latest_obs = latest_nat_germany) +   facet_wrap(vars(age_group), scales = \"free_y\")"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"posterior-predictions","dir":"Articles","previous_headings":"Models","what":"Posterior predictions","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"order identify areas current model poorly reproducing data plot posterior predictions data. plot faceted age group reference data y axis showing number observations reported given day given reference day x axis showing report date. see fairly clearly oscillations reported cases every 7 days expressed plot oscillations facet appear move left right across facets. indicates kind week day adjustment may needed. plot chunk simple_pp","code":"plot(exp_nowcast, type = \"posterior\") +   facet_wrap(vars(age_group, reference_date), scales = \"free\")"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"reporting-day-of-the-week-effect","dir":"Articles","previous_headings":"Models","what":"Reporting day of the week effect","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"noted using posterior predictions simple model fit appears day week effect reported observations. adjust introduce random effect day week date report using following helper function uses metadata produced enw_preprocess_data(). Note epinowcast uses sparse design matrix reduce runtimes modules design matrix shows unique rows index containing mapping full design matrix. now repeat nowcasting step day week reporting model included. Nowcast performance looks visually improved notable variation across age groups 35-59 year old nowcast appearing quite poor (result aggregate nowcast also showing great performance). also plot posterior predictions model way previous model. plot chunk dow_nowcast","code":"report_module_dow <- enw_report(~ (1 | day_of_week), data = pobs) dow_nowcast <- epinowcast(pobs,   report = report_module_dow,   expectation = expectation_module,   fit = fit,   model = multithread_model,   priors = priors ) plot(dow_nowcast, latest_obs = latest_nat_germany) +   facet_wrap(vars(age_group), scales = \"free_y\")"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"age-group-variation","dir":"Articles","previous_headings":"Models","what":"Age group variation","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"quite likely variation reporting delay age may driving variation nowcast performance noted last model. model using random effect 5 year age group (groups supplied data). nowcast time using age adjusted reference date model day week adjusted report date model. Fit looks slightly better adjustment though uncertainty also increased age groups performance final day data may reduced compared first model. plot chunk age_nowcast","code":"reference_module_age <- enw_reference(~ 1 + (1 | age_group), data = pobs) age_nowcast <- epinowcast(pobs,   reference = reference_module_age,   report = report_module_dow,   expectation = expectation_module,   fit = fit,   model = multithread_model,   priors = priors ) plot(age_nowcast, latest_obs = latest_nat_germany) +   facet_wrap(vars(age_group), scales = \"free_y\")"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"variation-based-on-reference-date","dir":"Articles","previous_headings":"Models","what":"Variation based on reference date","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"case reporting delays change time well across age groups. One way modelling assume piecewise constant variation time modelled first order weekly random walk. attractive property approach limits number report date distributions need evaluated model number weeks data expensive computational step using approach introducing time-varying parameter limits additional computational overhead. fit nowcasting model, comparison previous model looks like introduction variation time introduce slight improvement capturing hospitalisations age groups. plot chunk week_nowcast","code":"reference_module_age_week <- enw_reference(   ~ 1 + (1 | age_group) + rw(week), data = pobs ) week_nowcast <- epinowcast(pobs,   reference = reference_module_age_week,   report = report_module_dow,   expectation = expectation_module,   fit = fit,   model = multithread_model,    priors = priors ) plot(week_nowcast, latest_obs = latest_nat_germany) +   facet_wrap(vars(age_group), scales = \"free_y\")"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"variation-based-on-reference-date-stratified-by-age","dir":"Articles","previous_headings":"Models","what":"Variation based on reference date stratified by age","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"final hierarchical model makes sense explore whether evidence reporting delays vary week age group jointly. scenario assumption delays may evolve differently time age group reporting effects measurement error still shared across data sets. can now fit model . comparison previous model looks like introduction variation time introduce slight improvement capturing hospitalisations age groups. plot chunk age_week_nowcast","code":"reference_module_week_by_age <- enw_reference(   ~ 1 + (1 | age_group) + rw(week, by = age_group), data = pobs ) age_week_nowcast <- epinowcast(pobs,   reference = reference_module_week_by_age,   report = report_module_dow,   expectation = expectation_module,   fit = fit,   model = multithread_model,   priors = priors ) plot(age_week_nowcast, latest_obs = latest_nat_germany) +   facet_wrap(vars(age_group), scales = \"free_y\")"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"independent-models-for-each-age-group-","dir":"Articles","previous_headings":"Models","what":"Independent models for each age group.","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"obvious question ask stage using model jointly fits age groups actually beneficial. explore fitting model previously (day week effect report date random walk week reference date stratified age) age group independently. define model single call epinowcast fitting dataset independently joint setting likely lead long fit times real benefit. Instead write small helper function preprocess input data, define report reference date models run nowcast. can now use wrapper function data available age group, summarise resulting nowcast, join single data.frame. now summarised nowcasts rather object class epinowcast need make use underlying plot function . see performance generally quite good across board though width credible intervals also increased. Importantly 35-59 year old age group captured least well heirarchical models minor reductions performance age groups. suggests dataset nowcast date may relatively little benefit jointly modelling age groups. plot chunk ind_nowcast","code":"independent_epinowcast <- function(obs, max_delay = 40, ...) {   pobs_ind <- enw_preprocess_data(obs, max_delay = max_delay)    nowcast <- epinowcast(     data = pobs_ind,     reference = enw_reference(~ rw(week), data = pobs_ind),     report = enw_report(~ (1 | day_of_week), data = pobs_ind),     expectation = enw_expectation(       ~ 0 + (1 | day_of_week) + (1 | day), data = pobs_ind     ),      ...   )    nowcast_summary <- summary(     nowcast,     probs = c(0.025, 0.05, seq(0.1, 0.9, by = 0.1), 0.95, 0.975)   )   return(nowcast_summary) } options(mc.cores = 2)  independent_nowcast <- map(   split(retro_nat_germany, by = \"age_group\"),   independent_epinowcast,   fit = enw_fit_opts(     save_warmup = FALSE, output_loglik = TRUE, pp = TRUE,     chains = 2, threads_per_chain = threads,      iter_sampling = 500, iter_warmup = 500,     show_messages = FALSE, refresh = 0,     adapt_delta = 0.95, max_treedepth = 12   ),   model = multithread_model,   priors = priors ) independent_nowcast <- rbindlist(independent_nowcast) enw_plot_nowcast_quantiles(   independent_nowcast, latest_obs = latest_nat_germany ) +   facet_wrap(vars(age_group), scales = \"free_y\")"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"alternative-models","dir":"Articles","previous_headings":"Models","what":"Alternative models","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"models defined assumed delay distribution, aside report date effects, parametric lognormal distribution. assumptions may less optimal. Alternatives include assuming different distributional form (gamma distribution also supported epinowcast) assuming report delay fully non-parametric yet supported future package versions. number additional models explore within framework supported epinowcast well large number alternative parameterisations yet supported. example, explore models complex reporting day effects, including holidays (supported epinowcast either separate effect assuming reporting hazard Sundays) variation time represent reporting delays changing independently reference date (similar time varying model defined effect occurring report date model rather reference date model). choices data dependent domain knowledge needs used assess likely mechanisms. interested expanding functionality underlying model address issues note epinowcast allows users pass models meaning alternative parameterisations may easily tested within package infrastructure. testing done alterations increase flexibility package model improves defaults welcome pull requests.","code":""},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"evaluation","dir":"Articles","previous_headings":"","what":"Evaluation","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"nowcast single date, visualised performance went, evaluation anything complete rigorous can give examples might evaluate performance generally potentially draw useful initial conclusions. first list models (including simplest case) give informative names, summarise nowcast posterior model join tidy data.frame make analysis easier. allows us plot nowcasts model age group compared latest data. Looking plot shows small differences across models uncertainty generally decreasing model complexity increases. age groups clearly better nowcast others 35-59 year old age group particular poor nowcast coverage. plot chunk unnamed-chunk-20 crude measure general sample performance can use leave one information criterion supplied loo package though note typically appropriate time series data (approximate LFO cross validation likely perform better), approximation used avoid refitting likely poor, accounting refitting model required. see model includes day week effects date report substantially outperformed baseline model adjustment complex models adjusted variation age week date test improved estimated sample performance uncertainty around estimates wide. rigorously, can evaluate nowcasts using proper scoring rules scoringutils package including weighted interval score. limit nowcasts scored last 7 days data make interpretation easier, transform nowcasts format required scoringutils, link latest available data, finally call scoringutils::eval_forecasts(). Note scoring single nowcasts difficult generalise findings one day reporting may unusual. informed view model pick ideally nowcast range dates evaluate . first step score overall performance. see baseline model variation actually performs well models include least day week, age groups variation week performing comparably. performance characteristics relatively similar across models (models biased towards underprediction example). Finally look across scores relative simple model variation. nicely captures role last data point performance also highlights variation across reference dates age groups models. difference performance hierarchical age models model treats age groups independently also clear. plot chunk performance","code":"nowcasts <- list(   \"Reference: Fixed, Report: Fixed\" = exp_nowcast,   \"Reference: Fixed, Report: Day of week\" = dow_nowcast,   \"Reference: Age, Report: Day of week\" = age_nowcast,   \"Reference: Age and week, Report: Day of week\" = week_nowcast,   \"Reference: Age and week by age, Report: Day of week\" = age_week_nowcast ) summarised_nowcasts <- map(   nowcasts, summary,   probs = c(0.025, 0.05, seq(0.1, 0.9, by = 0.1), 0.95, 0.975) ) summarised_nowcasts$`Independent by age, Reference: Week, Report: Day of week` <- independent_nowcast # nolint  summarised_nowcasts <- rbindlist(summarised_nowcasts, idcol = \"model\",                                  use.names = TRUE) summarised_nowcasts[, `:=`(   model = factor(     model,     levels = c(\"Reference: Fixed, Report: Fixed\",                \"Reference: Fixed, Report: Day of week\",                \"Reference: Age, Report: Day of week\",                \"Reference: Age and week, Report: Day of week\",                \"Reference: Age and week by age, Report: Day of week\",                \"Independent by age, Reference: Week, Report: Day of week\")),   age_group = factor(     age_group,     levels = c(\"00+\", \"00-04\", \"05-14\", \"15-34\", \"35-59\", \"60-79\", \"80+\")) )] enw_plot_nowcast_quantiles(   summarised_nowcasts, latest_obs = latest_nat_germany ) +   facet_grid(vars(age_group), vars(model), scales = \"free_y\") loos <- map(nowcasts, ~ .$fit[[1]]$loo()) loo_compare(loos) #>                                                     elpd_diff se_diff #> Reference: Age and week, Report: Day of week           0.0       0.0  #> Reference: Age, Report: Day of week                  -11.1       5.3  #> Reference: Age and week by age, Report: Day of week  -11.4       3.4  #> Reference: Fixed, Report: Day of week                -49.9      10.6  #> Reference: Fixed, Report: Fixed                     -611.8      45.2 score <- enw_score_nowcast(  summarised_nowcasts,  latest_nat_germany[reference_date > (max(reference_date) - 7)] )  score |>   summarise_scores(by = \"model\") |>   kable() age_date_score <- score |>   summarise_scores(by = c(\"model\", \"reference_date\", \"age_group\")) fixed_score <- age_date_score[   model %in% \"Reference: Fixed, Report: Fixed\",   .(reference_date, age_group, fixed_is = interval_score) ] age_date_score <- merge(   age_date_score, fixed_score, by = c(\"reference_date\", \"age_group\") )  age_date_score <- age_date_score[, interval_score := interval_score / fixed_is] age_date_score <- age_date_score[!model %in% \"Reference: Fixed, Report: Fixed\"] plot <- ggplot(age_date_score) +   aes(x = reference_date, y = interval_score, col = model) +   geom_hline(yintercept = 1, linetype = 2, linewidth = 1.2, alpha = 0.5) +   geom_line(linewidth = 1.1, alpha = 0.6) +   geom_point(size = 1.2) +   facet_wrap(vars(age_group)) +   scale_color_brewer(palette = \"Dark2\") +   scale_y_log10(labels = scales::percent)  plot <- enw_plot_theme(plot) +   labs(x = \"Reference date\",        y = \"Weighted interval score (relative to Reference: Fixed, Report: Fixed model)\") + # nolint   guides(col = guide_legend(title = \"Model\", ncol = 2)) plot"},{"path":"package.epinowcast.org/dev/articles/germany-age-stratified-nowcasting.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Hierarchical nowcasting of age stratified COVID-19 hospitalisations in Germany","text":"vignette showcased using epinowcast nowcast age stratified COVID-19 hospitalisations Germany date test series increasingly complex models motivated data. also showed simple methods exploring nowcasts evaluating . Using limited information available us (nowcast single date used performance date motivate new models) appears models performed acceptably , aside last data point, models age day week effects likely performed better. also fairly clear performance degrades amount reported data reduced intuitively makes sense performance particularly sensitive first day reported data available (.e “now”). apparent finding delays evolve fairly independently across age groups motivates choosing model flexible , least date reference model. Despite independent model fixed effect model well overall, applications choosing model based evaluation, likely select relatively flexible model (day week, age group, age stratified weekly variation) relying hierarchical structure limit overfitting, excepting small reduction performance edge cases (hope edge cases common feature data). However practice, want explore nowcasting evaluating dates possible greater range model structures (discussed alternative modelling section vignette). Note proper scoring approach taken understand model performance (commonly used literature) ranking models based absolute errors groups high counts (35-59 age group) important nowcast correctly groups smaller counts (aged 80+).","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Model definition and implementation","text":"epinowcast package aims modular toolbox real-time infectious disease surveillance outbreak routine contexts. provide modular modelling framework optimised range common surveillance tasks whilst maintaining flexibility supporting user extension. provide flexible semi-parametric model underlying generative process similar implemented real-time infectious disease modelling packages[1,2]. optionally includes renewal process[3,4] latent reporting process[1,5,6]. Combined appropriate generation time distribution approach shown correspond Susceptible-Exposed-Infected-Recovered (SEIR) model[7] addition reporting delays. However, default model contains minimal mechanism order flexibly fit highly informative data. nowcasting approach extension proposed Günther et al.[8] extension model proposed Höhle Heiden[9] implemented surveillance R package[10]. Compared model proposed Günther et al.[8], epinowcast adds support jointly nowcasting multiple related datasets, flexible formula interface allowing specification large range models, optional parametric assumption underlying reporting delay. also support flexible joint modelling missing data assuming reporting delay consistent reported unreported observations following methodology Lison et al.[11]. modelling framework implemented stan probabilistic programming language via cmdstanr[12,13] focus computational efficiency robustness. following sections outline modelling methodology, current feature set stratified module, highlight implementation details. module present default implementation well generic framework support. Note extensions methodology warmly welcomed community site good first point contact.","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"decomposition-into-expected-final-notifications-and-report-delay-components","dir":"Articles","previous_headings":"","what":"Decomposition into expected final notifications and report delay components","title":"Model definition and implementation","text":"concerned outcomes occur time reference (e.g., date symptom onset test disease) reported delay, time report (e.g., date onsets entered central database become available analysis). assume times measured discrete time steps, usually day (case times dates). follow approach Höhle Heiden[9] consider distribution notifications (\\(n_{g,t,d}\\)) date reference (\\(t\\)) reporting delay (\\(d\\)) conditional final observed count \\(N_{g,t}\\) dataset (\\(g\\)) , \\[\\begin{equation}   N_{g,t} = \\sum_{d=0}^{D} n_{g,t,d} \\end{equation}\\] \\(D\\) represents maximum delay date reference time report theory infinite practice set finite value order make model identifiable computationally feasible. \\(t\\) \\(g\\) notifications assumed drawn multinomial distribution \\(N_{g,t}\\) trials probability vector (\\(p_{g,t,d}\\)) length \\(D\\). aim nowcasting predict final observed counts \\(N_{g,t}\\) given information available time \\(t\\). estimating components probability vector jointly expected number final notifications (\\(\\lambda_{g,t} = \\mathbb{E}[N_{g,t}]\\)) dataset \\(g\\) time \\(t\\). alternative approach consider \\(n_{g,t,d}\\) independently point model can defined regression can fit using standard software appropriate observation model adjustment reporting delay (.e., becomes Poisson Negative Binomial regression). implementation approach available Bastos et al.[14]. downside simplified approach reporting conditionally dependent may make specifying models complex reporting distributions difficult.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/articles/model.html","id":"default-model","dir":"Articles","previous_headings":"Expected final notifications","what":"Default model","title":"Model definition and implementation","text":"follow approach Günther et al.[8] specify model expected final notifications first order random walk. simple model highly flexible good fit nowcasting problems data highly informative. \\[\\begin{align}   \\log (\\lambda_{g,t}) &\\sim \\text{Normal}\\left(\\log (\\lambda_{g,t-1}) , \\sigma^{\\lambda}_{g} \\right) \\\\   \\log (\\lambda_{g,0}) &\\sim \\text{Normal}\\left(\\log (N_{g,0} + 1), 1 \\right) \\\\ \\sigma^{\\lambda}_{g} &\\sim \\text{Half-Normal}\\left(0, 1\\right) \\end{align}\\] \\(N_{g0}\\), first time point expected observations dataset \\(d\\), assumed completely observed.","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"generalised-model","dir":"Articles","previous_headings":"Expected final notifications","what":"Generalised model","title":"Model definition and implementation","text":"settings data sparse users want understand underlying generative process flexible default model likely good choice. settings generic model offers range options context specific. generic model currently based renewal process[3,4] additional latent reporting delays[1,5,6]. previously noted[7], corresponds commonly used Susceptible-Exposed-Infected-Recovered (SEIR) model appropriate generation time specified[7]","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"instantaneous-reproduction-numbergrowth-rate","dir":"Articles","previous_headings":"Expected final notifications","what":"Instantaneous reproduction number/growth rate","title":"Model definition and implementation","text":"model instantaneous reproduction number (\\(R_t\\)) log scale (though support link functions planned). generation time fixed day can interpreted instantaneous growth rate (\\(r_t\\)) defined difference log expected number final notifications time \\(t\\) \\(t-1\\). \\[\\begin{equation}   \\text{log} (R_{g,t}) = r_0 + \\beta_{f,r} X_{r} + \\beta_{r,r} Z_{r} \\end{equation}\\] \\(r_0\\) optional intercept, \\(X_{r}\\) design matrix fixed effects (\\(\\beta_{f,r}\\)), \\(Z_{r}\\) design matrix random effects (\\(\\beta_{r,r}\\). Within specification default model can specified random effect day intercept. Alternative specifications may interest include weekly random walk (specified ~ 1 + rw(week)), piecewise linear model (specified ~ 1 + day:week), group specific random effect (specified ~ 1 + (1 | .group)).","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"latent-infectionsnotifications","dir":"Articles","previous_headings":"Expected final notifications","what":"Latent infections/notifications","title":"Model definition and implementation","text":"model expected number infections/latent notifications (\\(\\lambda^l\\)) using renewal process[3,4]. model generalisation default model can used model expected number latent notifications setting generation time fixed day. implies current infections/notifications dependent past infections/notifications based kernel (usually interpreted generation time serial interval). instantaneous daily growth rate model can recovered setting generation time fixed 1 day. model defined follows, \\[\\begin{align}   \\lambda^l_{g,t} &\\sim \\text{LogNormal}\\left(\\mu^{l}_{g,t}, \\sigma^{l}_{g,t} \\right),\\ t \\leq P \\\\   \\lambda^l_{g,t} &= R_{g,t} \\sum_{p = 1}^{P} G_{g}\\left(p, t - p \\right)  \\lambda^l_{g, t-p},\\ t \\gt P   \\end{align}\\] \\(G_{g}\\left(p, t - p \\right)\\) probability infection \\(p\\) days infection \\(t - p\\) days ago group \\(g\\), \\(P\\) maximum generation time. initialise model assume first \\(P\\) latent notifications log-normally distributed mean \\(\\mu^{l}_{g,t}\\) standard deviation \\(\\sigma^{l}_{g,t}\\). equivalent assuming first \\(P\\) latent notifications independent identically distributed. mean log-normal distribution group log latest reported case count first reference date group scaled sum latent reporting delay. standard deviation assumed 1. assumptions can altered user.","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"latent-reporting-delay-and-ascertainment","dir":"Articles","previous_headings":"Expected final notifications","what":"Latent reporting delay and ascertainment","title":"Model definition and implementation","text":"settings may additional reporting delays top directly observed data, therefore “nowcastable”, common example delay exposure symptom onset. settings support modelling “latent” reporting delays convolution underlying expected counts potential delays vary time group. implementation similar implemented EpiNow2 epidemia well similar models[1,5,6,11]. addition support modelling ascertainment use improper probability mass functions (.e., enforcing sum 1 constraint) inferring ascertainment possible (example day week reporting patterns). \\[\\begin{align}   \\lambda_{g,t} &= \\upsilon_{g,t} \\sum_{\\tau = 0}^{L - 1} F_{g}\\left(\\tau + 1, t - \\tau \\right)  \\lambda^l_{g, t - \\tau} \\\\   \\nu_{g,t} &= \\nu_0 + \\beta_{f,\\nu} X_{\\nu} + \\beta_{r,\\nu} Z_{\\nu} \\end{align}\\] \\(\\nu_{g,t}\\) inferred ascertainment modelled flexibly using optional intercept (\\(\\nu_0\\)), design matrix (\\(X_{\\nu}\\)) fixed effects (\\(\\beta_{f,\\nu}\\)), design matrix (\\(Z_{\\nu}\\)) random effects (\\(\\beta_{r,\\nu}\\).","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"delay-distribution","dir":"Articles","previous_headings":"","what":"Delay distribution","title":"Model definition and implementation","text":"Given case counts date reference date report, can estimate reporting delay distribution directly jointly underlying process model, rather relying external estimates sources (though may want account external information priors). following section, describe default parametric delay distribution model extension generic, highly flexible delay model based discrete time--event modelling.","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"default-model-1","dir":"Articles","previous_headings":"Delay distribution","what":"Default model","title":"Model definition and implementation","text":"default model, consider reporting delay follow \\(\\text{LogNormal} \\left(\\mu^d, \\sigma^d \\right)\\) distribution, parameters \\[\\begin{align}   \\mu^d &\\sim \\text{Normal} \\left(0, 1 \\right) \\\\   \\sigma^d &\\sim \\text{Half-Normal} \\left(0, 1 \\right). \\end{align}\\] distribution discretised daily probabilities \\(p_{g,t,d}\\) (case group \\(g\\) reference date \\(t\\) reported delay \\(d\\)) adjusted maximum delay, see vignette(\"distributions\") details.","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"generalised-model-1","dir":"Articles","previous_headings":"Delay distribution","what":"Generalised model","title":"Model definition and implementation","text":"generalise model order support range delay distributions well effects reporting process delay. Following approach Günther et al.[8] others, parameterise delay probability (\\(p_{g,t,d}\\)) via discrete-time hazard model, .e., \\[\\begin{equation}   p_{g,t,0} = h_{g,t,0},\\ p_{g,t,d} = \\left(1 -\\sum^{d-1}_{d^{\\prime}=0} p_{g,t,d^{\\prime}} \\right) \\times h_{g,t,d}, \\end{equation}\\] \\[ h_{g,t,d} =\\text{P} \\left(\\text{delay}=d|\\text{delay} \\geq d, W_{g,t,d}\\right), \\] -called reporting hazard. case group \\(g\\) reference date \\(t\\), hazard \\(h_{g,t,d}\\) states probability reported delay \\(d\\), given case reported earlier. hazard depends design matrix \\(W_{g,t,d}\\), encodes baseline delay distribution covariates affect reporting delay. extend model Günther et al. decomposing hazard three components, Parametric baseline hazard \\(\\gamma_{g,t,d}\\): hazard derived parametric delay distribution, parameters depending covariates date reference Non-parametric reference date effect \\(\\delta_{g,t,d}\\): effect hazard depends covariates date reference Non-parametric report date effect \\(\\epsilon_{g,t,d}\\): effect hazard depends covariates date report component adds overall hazard regression logit link \\[\\begin{equation}   \\text{logit} (h_{g,t,d}) = \\gamma_{g,t,d} + \\delta_{g,t,d} + \\epsilon_{g,t,d}, \\end{equation}\\] maximum delay hazard \\(h_{g,t,D}=1\\), order enforce assumption observations reported within specified maximum delay. following, describe parameterisation different components.","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"parametric-baseline-hazard","dir":"Articles","previous_headings":"Delay distribution > Generalised model","what":"Parametric baseline hazard","title":"Model definition and implementation","text":"parametric baseline hazard \\(\\gamma_{g,t,d}\\) case group \\(g\\) reference date \\(t\\) modelled according certain discretised parametric probability distribution parameters \\(\\mu_{g,t}\\) \\(\\upsilon_{g,t}\\). Currently, epinowcast supports four different parametric distributions: () log-normal (default), (ii) exponential, (iii) gamma, (iv) log-logistic. distributions discretised adjusted assumed maximum delay, see vignette(\"distributions\") details. delay probabilities \\(p^{\\prime}_{g,t,d}\\) obtained discretised delay distribution converted hazards logit scale using \\[\\begin{equation}   \\gamma_{g,t,d} = \\text{logit} \\left(\\frac{p^{\\prime}_{g,t,d}}{\\left(1 -\\sum^{d-1}_{d^{\\prime}=0} p^{\\prime}_{g,t,d^{\\prime}} \\right)} \\right). \\end{equation}\\] default case log-normal distribution, parameters \\(\\mu_{g,t}\\) \\(\\upsilon_{g,t}\\) represent log mean log standard deviation. parameter defined using (log-)linear model. model consists intercept number arbitrary, shared covariates, indexed reference date. covariates multiplied fixed (\\(\\beta_{f,}\\)) random (\\(\\beta_{r,}\\)) coefficients (note can include auto-regressive terms), .e., \\[\\begin{align}   \\mu_{g,t} &= \\mu_0 + \\beta_{f,\\mu} X_{\\gamma} + \\beta_{r,\\mu} Z_{\\gamma} \\\\   \\text{log} (\\upsilon_{g,t}) &= \\upsilon_0 + \\beta_{f,\\upsilon} X_{\\gamma} + \\beta_{r,\\upsilon} Z_{\\gamma} \\end{align}\\]","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"non-parametric-reference-date-effect-delta_gtd-and-report-date-effect-epsilon_gtd","dir":"Articles","previous_headings":"Delay distribution > Generalised model","what":"Non-parametric reference date effect \\(\\delta_{g,t,d}\\) and report date effect \\(\\epsilon_{g,t,d}\\)","title":"Model definition and implementation","text":"addition parametric reporting effects may also non-parametric effects referenced reference report dates. represented non-distributional logit hazard components date reference report, defined using intercept (\\(\\delta_0\\)) arbitrary, shared covariates fixed (\\(\\beta_{f,}\\)) random (\\(\\beta_{r,}\\)) coefficients (note can include auto-regressive terms). \\[\\begin{align}   \\delta_{g,t,d} &= \\delta_0 + \\beta_{f,\\delta} X_{\\delta} + \\beta_{r,\\delta} Z_{\\delta} \\\\   \\epsilon_{g,t,d} &= \\beta_{f,\\epsilon} X_{\\epsilon} + \\beta_{r,\\epsilon} Z_{\\epsilon} \\end{align}\\] fixed (\\(\\beta_{f,}\\)) random (\\(\\beta_{r,}\\)) coefficients standard normal priors default standard half-normal priors pooled standard deviations. implementation details see enw_reference() delays linked date reference, enw_report() delays linked date report.","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"observation-model-and-nowcast","dir":"Articles","previous_headings":"","what":"Observation model and nowcast","title":"Model definition and implementation","text":"Expected notifications date reference (\\(t\\)) reporting delay can now found multiplying expected final notifications \\(t\\) probability reporting day delay (\\(p_{g,t,d}\\)). assume negative binomial observation model, default, joint overdispersion parameter (standard half normal prior 1 square root overdispersion[15]) produce nowcast final observed notifications reference date summing posterior estimates unobserved notification observed notifications reference date. \\[\\begin{align}   n_{g,t,d} \\mid \\lambda_{g,t},p_{g,t,d}  &\\sim \\text{NB} \\left((1 - \\alpha_{g,t})\\lambda_{g,t} \\times p_{g,t,d}, \\phi \\right),\\ t=1,...,T. \\\\     \\frac{1}{\\sqrt{\\phi}} &\\sim \\text{Half-Normal}(0, 1) \\\\   N_{g,t} &= \\sum_{d=0}^{D} n_{g,t,d} \\end{align}\\] \\(\\alpha_{g,t}\\) proportion cases reference date report reference date. default modelled set zero , see accounting reported cases missing reference date section defaults. observation models Poisson distribution also supported. See documentation enw_obs() details. order make best use observed data nowcasting use observations available reported given report reference date use posterior prediction observation model . means nowcast dates become increasingly truncated depend modelled estimates whereas complete majority final count known. Depending use case posterior predictions alone may also interest.","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"accounting-for-reported-cases-with-a-missing-reference-date","dir":"Articles","previous_headings":"","what":"Accounting for reported cases with a missing reference date","title":"Model definition and implementation","text":"real-world settings observations may reported without linked reference date. common example cases date symptom onset report date often known onset date may . account support modelling missing process assuming cases missing reference date reporting delay distribution cases known reference date processes drive probability missing reference date (\\(\\alpha_{g,t}\\)) linked unknown date reference rather date report based Lison et al.[11]. model probability flexibly logit scale follows, \\[\\begin{equation}   \\text{logit} (\\alpha_{g,t}) = \\alpha_0 + \\beta_{f,\\alpha} X_{\\alpha} + \\beta_{r,\\alpha} Z_{\\alpha} \\end{equation}\\] \\(\\alpha_0\\) represents intercept, \\(\\beta_{f,\\alpha}\\) fixed effects, \\(\\beta_{r,\\alpha}\\) random effects. link observations date report missing reference date (\\(M_{g,t}\\)) convolve expected notifications probability missing reference date probability reporting given day follows, \\[\\begin{equation}   M_{g,t} \\mid \\lambda_{g,t},p_{g,t,d}, \\alpha_{g,t}  \\sim \\text{NB} \\left( \\sum^D_{d=0} \\alpha_{g,t-d} \\lambda_{g,t-d} p_{g,t-d,d}, \\phi \\right),\\ t=1,...,T. \\end{equation}\\] cases known reference dates observation models supported. implementation details see enw_missing().","code":""},{"path":"package.epinowcast.org/dev/articles/model.html","id":"implementation","dir":"Articles","previous_headings":"","what":"Implementation","title":"Model definition and implementation","text":"model implemented probabilistic programming language stan use cmdstanr interact model[12,13]. Optional within chain parallelisation available across times reference reduce runtimes. Sparse design matrices used covariates limit number probability mass functions need calculated. epinowcast incorporates additional functionality written R[16] enable plotting nowcasts posterior predictions, summarising nowcasts, scoring using scoringutils[17]. flexible formula interface provided enable easier implementation complex user specified models without interacting underlying code base. functionality modular allowing users extend alter underlying model whilst continuing use package framework.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"use-case","dir":"Articles","previous_headings":"","what":"Use case","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"epidemic progress. want know effective reproduction number current time. average number secondary infections caused single infected individual given point time measure transmissibility infection population time. Unfortunately, can’t directly observe infections data observe suffers reporting delays.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"what-we-have","dir":"Articles","previous_headings":"","what":"What we have","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"linelist cases date interest (example test positive date) date report (example date hospitalisation report); estimate distribution times infection positive test; estimate generation time distribution, distribution time intervals infection primary case infection secondary cases caused primary case. estimate ascertainment rate, proportion infections reported hospitalisations.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"what-do-we-do","dir":"Articles","previous_headings":"","what":"What do we do","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"Visualise contextualise data case study uses (COVID-19 hositalisations Germany); Specify joint model effective reproduction number, delay infection hospitalisation delay hospitalisation report; Fit model data available real-time, retrospectively; Visualise nowcast real-time data comparison data ultimately observed; Compare real-time retrospective reproduction number estimates delay distribution estimates; Outline limitations strengths approach highlight areas can extended.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"getting-setup","dir":"Articles","previous_headings":"","what":"Getting setup","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"See package documentation guidance installing package getting setup cmdstanr (backend used fitting models). well epinowcast package use following packages vignette. make use data.table simple data transformations tools tidyverse base R tools just easily used; also use purrr make use partial() function allows us partially specify function later reuse. useful specifying model can specify parts model common models specify parts specific model call updated function; Finally, use ggplot2 plotting.","code":"library(epinowcast) library(data.table) library(purrr) library(ggplot2)"},{"path":[]},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"overview","dir":"Articles","previous_headings":"Introducing the data: COVID-19 hospitalisations in Germany","what":"Overview","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"case study, use data sourced Robert Koch Institute via Germany Nowcasting hub. data represent hospitalisation counts date positive test date test report Germany. data used extensively nowcasting forecasting COVID-19 hospitalisations Germany described detail Wolffram et al. (2023). use data good example type data available many settings. first summarise data, case study consider national level data without stratification age group. can filter data using data.table follows,","code":"summary(germany_covid19_hosp) #>  reference_date          location      #>  Min.   :2021-04-06   DE     : 90405   #>  1st Qu.:2021-05-15   DE-BB  : 90405   #>  Median :2021-06-23   DE-BE  : 90405   #>  Mean   :2021-06-25   DE-BW  : 90405   #>  3rd Qu.:2021-08-02   DE-BY  : 90405   #>  Max.   :2021-10-20   DE-HB  : 90405   #>                       (Other):994455   #>  age_group         confirm        #>  00-04:219555   Min.   :   0.00   #>  00+  :219555   1st Qu.:   0.00   #>  05-14:219555   Median :   1.00   #>  15-34:219555   Mean   :  11.44   #>  35-59:219555   3rd Qu.:   6.00   #>  60-79:219555   Max.   :1552.00   #>  80+  :219555                     #>   report_date         #>  Min.   :2021-04-06   #>  1st Qu.:2021-06-24   #>  Median :2021-08-03   #>  Mean   :2021-07-31   #>  3rd Qu.:2021-09-11   #>  Max.   :2021-10-20   #> germany_hosp <- germany_covid19_hosp[location == \"DE\"][age_group %in% \"00+\"] germany_hosp <- germany_hosp[, .(reference_date, report_date, confirm)] germany_hosp #>        reference_date report_date confirm #>     1:     2021-04-06  2021-04-06     149 #>     2:     2021-04-07  2021-04-07     312 #>     3:     2021-04-08  2021-04-08     424 #>     4:     2021-04-09  2021-04-09     288 #>     5:     2021-04-10  2021-04-10     273 #>    ---                                    #> 12911:     2021-07-27  2021-10-16      81 #> 12912:     2021-07-28  2021-10-17     159 #> 12913:     2021-07-29  2021-10-18     145 #> 12914:     2021-07-30  2021-10-19     117 #> 12915:     2021-07-31  2021-10-20     132"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"data-transformations","dir":"Articles","previous_headings":"Introducing the data: COVID-19 hospitalisations in Germany","what":"Data transformations","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"data already format can used epinowcast, contains reference date (column reference_date): date observation, example date positive test report date (column report_date): date report given set observations reference date count (column confirm): total number hospitalisations reference date report date. Note cumulative report date. package also provides range tools convert data line list, incidence, common formats required format (see Data converters). example convert data individual case linelist, linelist converted format epinowcast requires using enw_linelist_to_incidence() function, specifed reference_date report_date columns, columns (used group data), max_delay maximum delay reference date report date (note observed delay longer specified delay used instead). enw_linelist_to_incidence() function calculate incidence reference date report date group.","code":"germany_covid19_hosp_linelist <- germany_covid19_hosp |>   enw_add_incidence() |>   enw_incidence_to_linelist()  germany_covid19_hosp_linelist #>                 id reference_date location #>        1:        1     2021-04-06       DE #>        2:        2     2021-04-06       DE #>        3:        3     2021-04-06       DE #>        4:        4     2021-04-06       DE #>        5:        5     2021-04-06       DE #>       ---                                  #> 11486202: 11486202     2021-10-20    DE-TH #> 11486203: 11486203     2021-10-20    DE-TH #> 11486204: 11486204     2021-10-20    DE-TH #> 11486205: 11486205     2021-10-20    DE-TH #> 11486206: 11486206     2021-10-20    DE-TH #>           age_group report_date delay #>        1:       00+  2021-04-06     0 #>        2:       00+  2021-04-06     0 #>        3:       00+  2021-04-06     0 #>        4:       00+  2021-04-06     0 #>        5:       00+  2021-04-06     0 #>       ---                             #> 11486202:     15-34  2021-10-20   115 #> 11486203:     60-79  2021-10-20   117 #> 11486204:     60-79  2021-10-20   117 #> 11486205:     60-79  2021-10-20   117 #> 11486206:     60-79  2021-10-20   117 incidence_from_linelist <- enw_linelist_to_incidence(   germany_covid19_hosp_linelist,   reference_date = \"reference_date\",   report_date = \"report_date\",   by = c(\"age_group\", \"location\"),   max_delay = 30 )  incidence_from_linelist #>          age_group location report_date #>       1:     00-04    DE-BY  2021-04-06 #>       2:     00-04    DE-BY  2021-04-07 #>       3:     00-04    DE-BY  2021-04-08 #>       4:     00-04    DE-BY  2021-04-09 #>       5:     00-04    DE-BY  2021-04-10 #>      ---                                #> 2049593:       80+    DE-TH  2021-10-19 #> 2049594:       80+    DE-TH  2021-10-20 #> 2049595:       80+    DE-TH  2021-10-19 #> 2049596:       80+    DE-TH  2021-10-20 #> 2049597:       80+    DE-TH  2021-10-20 #>          reference_date new_confirm confirm delay #>       1:           <NA>           0       0     0 #>       2:           <NA>           0       0     1 #>       3:           <NA>           0       0     2 #>       4:           <NA>           0       0     3 #>       5:           <NA>           0       0     4 #>      ---                                          #> 2049593:     2021-10-18           0       0     1 #> 2049594:     2021-10-18           0       0     2 #> 2049595:     2021-10-19           1       1     0 #> 2049596:     2021-10-19           0       1     1 #> 2049597:     2021-10-20           0       0     0"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"filtering-the-data","dir":"Articles","previous_headings":"Introducing the data: COVID-19 hospitalisations in Germany","what":"Filtering the data","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"case study consider data 1st March 2020 onwards. first step, filter data include observations 1st May 2021 1st August 2021. using enw_filter_report_dates() enw_filter_reference_dates() functions, also used enw_complete_dates() make sure complete data dates earliest latest dates. also used enw_add_incidence() add incidence column data. Next split data two parts, data available time used fit model (rt_nat_germany) data available retrospectively time period used evaluate model (retro_nat_germany). using enw_filter_report_dates() enw_filter_reference_dates() functions follows: Create real-time dataset (rt_nat_germany) filtering data include reported observations 1st May 2021 1st July 2021; Create retrospective dataset (retro_germany) filtering data include observations reference dates (.e. may reported anytime 1st August 2021) 1st May 2021 1st July 2021; Finally can create dataset contains latest data available reference date. using enw_latest_data() function,","code":"complete_germany_hosp <- germany_hosp |>   enw_filter_report_dates(latest_date = \"2021-08-01\") |>   enw_filter_reference_dates(earliest_date = \"2021-05-01\") |>   enw_complete_dates(missing_reference = FALSE) |>   enw_add_incidence() rt_germany <- complete_germany_hosp |>   enw_filter_report_dates(latest_date = \"2021-07-01\") rt_germany #>       report_date reference_date confirm #>    1:  2021-05-01     2021-05-01     234 #>    2:  2021-05-02     2021-05-01     352 #>    3:  2021-05-03     2021-05-01     391 #>    4:  2021-05-04     2021-05-01     464 #>    5:  2021-05-05     2021-05-01     507 #>   ---                                    #> 1949:  2021-06-30     2021-06-29      31 #> 1950:  2021-07-01     2021-06-29      35 #> 1951:  2021-06-30     2021-06-30      20 #> 1952:  2021-07-01     2021-06-30      37 #> 1953:  2021-07-01     2021-07-01      20 #>       new_confirm delay #>    1:         234     0 #>    2:         118     1 #>    3:          39     2 #>    4:          73     3 #>    5:          43     4 #>   ---                   #> 1949:          11     1 #> 1950:           4     2 #> 1951:          20     0 #> 1952:          17     1 #> 1953:          20     0 retro_germany <- complete_germany_hosp |>   enw_filter_reference_dates(latest_date = \"2021-07-01\") retro_germany #>       report_date reference_date confirm #>    1:  2021-05-01     2021-05-01     234 #>    2:  2021-05-02     2021-05-01     352 #>    3:  2021-05-03     2021-05-01     391 #>    4:  2021-05-04     2021-05-01     464 #>    5:  2021-05-05     2021-05-01     507 #>   ---                                    #> 3871:  2021-07-28     2021-07-01      57 #> 3872:  2021-07-29     2021-07-01      57 #> 3873:  2021-07-30     2021-07-01      57 #> 3874:  2021-07-31     2021-07-01      57 #> 3875:  2021-08-01     2021-07-01      57 #>       new_confirm delay #>    1:         234     0 #>    2:         118     1 #>    3:          39     2 #>    4:          73     3 #>    5:          43     4 #>   ---                   #> 3871:           0    27 #> 3872:           0    28 #> 3873:           0    29 #> 3874:           0    30 #> 3875:           0    31 latest_germany_hosp <- retro_germany |>   enw_latest_data() head(latest_germany_hosp, n = 10) #>     reference_date report_date confirm new_confirm #>  1:     2021-05-01  2021-08-01    1007           0 #>  2:     2021-05-02  2021-08-01     781           0 #>  3:     2021-05-03  2021-08-01     467           0 #>  4:     2021-05-04  2021-08-01     823           0 #>  5:     2021-05-05  2021-08-01    1028           0 #>  6:     2021-05-06  2021-08-01    1016           0 #>  7:     2021-05-07  2021-08-01     892           0 #>  8:     2021-05-08  2021-08-01     822           0 #>  9:     2021-05-09  2021-08-01     561           0 #> 10:     2021-05-10  2021-08-01     364           0 #>     delay #>  1:    92 #>  2:    91 #>  3:    90 #>  4:    89 #>  5:    88 #>  6:    87 #>  7:    86 #>  8:    85 #>  9:    84 #> 10:    83"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"visualising-the-data","dir":"Articles","previous_headings":"Introducing the data: COVID-19 hospitalisations in Germany","what":"Visualising the data","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"define, fit, model visualise data get idea trends data reporting structure. currently function epinowcast visualise data, can use ggplot2 package manually follows, Hospitalisations Germany date positive test date report","code":"gh_vis_cohorts <- copy(retro_germany)[   ,   report_date := fcase(     report_date <= as.Date(\"2021-05-15\"), as.Date(\"2021-05-15\"),     report_date <= as.Date(\"2021-06-01\"), as.Date(\"2021-06-01\"),     report_date <= as.Date(\"2021-06-15\"), as.Date(\"2021-06-15\"),     report_date <= as.Date(\"2021-07-01\"), as.Date(\"2021-07-01\"),     report_date <= as.Date(\"2021-07-15\"), as.Date(\"2021-07-15\"),     report_date <= as.Date(\"2021-08-01\"), as.Date(\"2021-08-01\")   ) |>     factor(levels = rev(c(       \"2021-05-15\", \"2021-06-01\", \"2021-06-15\", \"2021-07-01\",       \"2021-07-15\", \"2021-08-01\"     ))) ]  gh_vis_cohorts_by_reference <- gh_vis_cohorts[,   .(confirm = sum(new_confirm)),   by = .(reference_date) ]  gh_vis_cohorts_by_ref_rep <- gh_vis_cohorts[,   .(confirm = sum(new_confirm)),   by = .(reference_date, report_date) ]  gh_vis_cohorts_by_ref_rep |>   ggplot() +   aes(     x = reference_date, y = confirm, fill = report_date, group = report_date   ) +   geom_col(position = \"stack\", alpha = 1, col = \"grey\") +   geom_vline(     aes(xintercept = as.Date(report_date)),     linetype = 2, alpha = 0.9   ) +   scale_y_continuous(labels = \\(x)(scales::comma(x, accuracy = 1))) +   scale_fill_brewer(     palette = \"Blues\", aesthetics = c(\"color\", \"fill\")   ) +   theme_bw() +   labs(     x = \"Date of positive test\",     y = \"Hospitalised cases by date of positive test\",     fill = \"Report date\"   ) +   guides(fill = guide_legend(reverse = TRUE)) +   theme(legend.position = \"bottom\")"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"model","dir":"Articles","previous_headings":"","what":"Model","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"epinowcast package provides flexible framework modelling incidence infections subsequent measures hospitalisations reported delay. framework based generative model describes hypothesised process data generated. generative model used define likelihood function describes probability observing data given model parameters. likelihood function combined prior information used fit model parameters data. following sections describe generative model incidence infections hospitalisations. like know general framework see model vignette.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"expected-hospitalisations","dir":"Articles","previous_headings":"Model","what":"Expected hospitalisations","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"first part generative process consider expected number hospitalisations date positive test. number hospitalisations expect observe perfect reporting hospitalisations unmodelled variance. part model also decomposed three parts: expected number infections, delay infection positive test, probability hospitalisation given infection. three parts combined give expected number hospitalisations date positive test. describe parts turn.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"expected-infections","dir":"Articles","previous_headings":"Model > Expected hospitalisations","what":"Expected infections","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"model expected infections function effective (instantaneous) reproduction number previous infections weighted generation time using renewal equation[1,2]. corresponds commonly used Susceptible-Exposed-Infected-Recovered (SEIR) model appropriate generation time specified[3].","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"instantaneous-reproduction-number","dir":"Articles","previous_headings":"Model > Expected hospitalisations > Expected infections","what":"Instantaneous reproduction number","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"model instantaneous reproduction number (\\(R_t\\)) log scale weekly random walk follows \\[\\begin{align}   \\text{log} (R_{t}) &= r_0 + \\sum_{= 0}^{t \\% 7} \\epsilon_i \\\\   \\epsilon_i &\\sim \\text{Normal}\\left(0, \\sigma_{\\epsilon} \\right) \\\\   \\sigma_{\\epsilon} &\\sim \\text{HalfNormal}\\left(0, 1 \\right) \\end{align}\\] \\(r_0\\) intercept, \\(\\sum_{= 0}^{t \\% 7} \\epsilon_i\\) weekly random walk. choose model flexible, can used model range different scenarios, parsimonious. example, set \\(\\sigma_{\\epsilon} = 0\\) model reduces constant reproduction number. set \\(\\sigma_{\\epsilon} > 0\\) model allows changes reproduction number time. sensible choices model include random walk longer time scale (e.g. monthly) shorter time scale (e.g. daily), random walk drift term, random walk drift term seasonal component.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"latent-infections","dir":"Articles","previous_headings":"Model > Expected hospitalisations > Expected infections","what":"Latent infections","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"model expected number infections/latent notifications (\\(\\lambda^l\\)) using renewal process[1,2]. model generalisation default epinowcast model implies current infections/notifications dependent past infections/notifications based kernel. kernel defined generation time distribution, probability distribution time infection subsequent infectiousness, previously defined model effective reproduction number. model defined follows, \\[\\begin{align}   \\lambda^l_{t} &\\sim \\text{LogNormal}\\left(\\mu^{l}, \\sigma^{l} \\right),\\ t \\leq P \\\\   \\lambda^l_{t} &= R_{t} \\sum_{p = 1}^{P} g\\left(t - p \\right)  \\lambda^l_{t-p},\\ t \\gt P   \\end{align}\\] assume generation time (\\(g\\)) gamma distribution mean 4 days standard deviation 3 days. initialise model assume first \\(P\\) latent notifications log-normally distributed mean \\(\\mu^{l}_{g,t}\\) standard deviation \\(\\sigma^{l}_{g,t}\\). equivalent assuming first \\(P\\) latent notifications independent identically distributed. mean log-normal distribution group log latest reported case count first reference date group scaled sum latent reporting delay. standard deviation assumed 1.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"latent-reporting-delay-and-ascertainment","dir":"Articles","previous_headings":"Model > Expected hospitalisations","what":"Latent reporting delay and ascertainment","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"many settings, case study, may additional reporting delays top directly observed data, therefore “nowcastable”, common example delay exposure symptom onset. settings support modelling “latent” reporting delays convolution underlying expected counts potential delays vary time group. implementation similar implemented EpiNow2 epidemia well similar models[4–7]. addition , support modelling ascertainment use improper probability mass functions (.e. enforcing sum 1 constraint) inferring ascertainment possible (example day week reporting patterns). assume infection hospistalisation ratio 2% modified random effect day week account within week reporting periodicity. also assume lognormal reporting delay mean 5 days standard deviation 2 days, representing delay infection positive test. assume reporting delay days week. model defined follows, \\[\\begin{align}   \\lambda_{t} &= \\nu_{t \\% 7} \\sum_{\\tau = 0}^{L - 1} f_{g}\\left(t - \\tau \\right)  \\lambda^l_{t - \\tau} \\\\   \\text{log} (\\nu_{}) &\\sim \\text{Normal}\\left(-3.91, \\sigma_{\\nu} \\right) \\\\   \\sigma_{\\nu} &\\sim \\text{HalfNormal}\\left(0, 1 \\right) \\\\ \\end{align}\\] \\(\\nu_{}\\) random effect day week represents reporting periodicity.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"specifying-the-model-using-epinowcastenw_expectation","dir":"Articles","previous_headings":"Model > Expected hospitalisations","what":"Specifying the model using epinowcast::enw_expectation()","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"first need define weekly random walk model effective reproduction number. can using formula interface follows, Next define generation time distribution. already discussed, assume gamma distribution mean 4 days standard deviation 3 days. summary parameters first need transformed shape scale parameters used gamma distribution. need account daily censoring finally normalise probability mass function (PMF) account right truncation. plot chunk unnamed-chunk-12 PMFs set maximum delay 15 days gives good coverage majority distribution limits computational burden fitting model. Now define latent reporting delay similar way remembering specified lognormal distribution mean 5 days standard deviation 2 days. also need account daily censoring normalise PMF account right truncation. plot chunk unnamed-chunk-13 last part model define remaining part ascertainment model expected hospitalisations. already defined base ascertainment ratio (.e. 2% infection hospitalisation ratio) need define day week random effect. can using formula interface follows, Finally, can combine four parts model define expected hospitalisations date positive test. using epinowcast::enw_expectation() function follows,","code":"rt_formula <- ~ 1 + rw(week) # first transform mean and sd to shape and scale gamma_mean <- 4 gamma_sd <- 3 gamma_shape <- gamma_mean^2 / gamma_sd^2 gamma_scale <- gamma_sd^2 / gamma_mean  # then discretise the distribution gt_pmf <- simulate_double_censored_pmf(   max = 15, shape = gamma_shape, scale = gamma_scale, fun_dist = rgamma ) |> # and normalise it to account for right truncation   (\\(x) x / sum(x))()  plot(gt_pmf) lgn_mean <- 5 lgn_sd <- 2 meanlog <- log(lgn_mean^2 / sqrt(lgn_sd^2 + lgn_mean^2)) sdlog <- sqrt(log(1 + lgn_sd^2 / lgn_mean^2))  # then discretise the distribution reporting_pmf <- simulate_double_censored_pmf(   max = 15, meanlog = meanlog, sdlog = sdlog, fun_dist = rlnorm ) |> # normalise it to account for right truncation   (\\(x) x / sum(x))() |> # and scale it by the infection to hospitalisation ration (2%)   (\\(x) x * 0.02)()  plot(reporting_pmf) observation_formula <- ~ 1 + (1 | day_of_week) expectation_module <- partial(   epinowcast::enw_expectation,   r = rt_formula,   generation_time = gt_pmf,   latent_reporting_delay = reporting_pmf,   observation = observation_formula )"},{"path":[]},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"defining-the-delay-distribution","dir":"Articles","previous_headings":"Model > Delay distribution","what":"Defining the delay distribution","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"Given case counts date reference date report, can estimate reporting delay distribution directly jointly underlying process model, rather relying external estimates sources (though may want account external information priors). consider reporting delay follow \\(\\text{LogNormal} \\left(\\mu^d, \\sigma^d \\right)\\) distribution, parameters \\[\\begin{align}   \\mu^d &\\sim \\text{Normal} \\left(0, 1 \\right) \\\\   \\sigma^d &\\sim \\text{Half-Normal} \\left(0, 1 \\right). \\end{align}\\] distribution discretised daily probabilities \\(p_{t,d}\\) adjusted maximum delay, see vignette(\"distributions\") details.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"specifying-the-model-using-epinowcastenw_reference","dir":"Articles","previous_headings":"Model > Delay distribution","what":"Specifying the model using epinowcast::enw_reference()","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"can define reporting delay distribution using epinowcast::enw_reference() function follows,","code":"reference_module <- partial(enw_reference, ~1, distribution = \"lognormal\")"},{"path":[]},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"defining-the-observation-model","dir":"Articles","previous_headings":"Model > Observation model and nowcast","what":"Defining the observation model","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"Expected notifications date positive test (\\(t\\)) reporting date can now found multiplying expected final notifications date positive test \\(t\\) probability reporting day delay (\\(p_{t,d}\\)). assume Poisson observation model produce nowcast final observed hospitalisations reference date summing posterior estimates unobserved notification observed notifications reference date. \\[\\begin{align}   n_{t,d} \\mid \\lambda_{t},p_{t,d}  &\\sim \\text{Poisson} \\left(\\lambda_{t} \\times p_{t,d} \\right),\\ t=1,...,T. \\\\   N_{t} &= \\sum_{d=0}^{D} n_{t,d} \\end{align}\\]","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"specifying-the-model-using-epinowcastenw_obs","dir":"Articles","previous_headings":"Model > Observation model and nowcast","what":"Specifying the model using epinowcast::enw_obs()","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"","code":"obs_module <- partial(enw_obs, family = \"poisson\")"},{"path":[]},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"preprocess-the-data","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany","what":"Preprocess the data","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"fitting model just defined need preprocess data order correct format work epinowcast produce metadata describes aspects data use model (example maximum delay, number groups, number observations group). using enw_preprocess_data() function follows real-time retrospective datasets. Note set max_delay = 30 constrain modelled maximum delay 30 days. pragmatic choice ensure model can fit reasonable amount time, also set longer wanted data suggested longer delay possible. retrospective data","code":"rt_germany_pobs <- enw_preprocess_data(rt_germany, max_delay = 30) rt_germany_pobs #>                     obs          new_confirm #> 1: <data.table[1425x8]> <data.table[1425x9]> #>                latest missing_reference #> 1: <data.table[62x8]> <data.table[0x4]> #>     reporting_triangle      metareference #> 1: <data.table[62x32]> <data.table[62x8]> #>             metareport          metadelay time #> 1: <data.table[91x10]> <data.table[30x4]>   62 #>    snapshots by groups max_delay   max_date #> 1:        62         1        30 2021-07-01 #>    timestep #> 1:      day retro_germany_pobs <- enw_preprocess_data(retro_germany, max_delay = 30) retro_germany_pobs #>                     obs          new_confirm #> 1: <data.table[1860x8]> <data.table[1860x9]> #>                latest missing_reference #> 1: <data.table[62x8]> <data.table[0x4]> #>     reporting_triangle      metareference #> 1: <data.table[62x32]> <data.table[62x8]> #>              metareport          metadelay time #> 1: <data.table[120x10]> <data.table[30x4]>   62 #>    snapshots by groups max_delay   max_date #> 1:        62         1        30 2021-07-30 #>    timestep #> 1:      day"},{"path":[]},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"specifying-the-fitting-options","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany > Fitting the epinowcast model","what":"Specifying the fitting options","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"ready fit model need first specify fitting options using cmdstanr (information options can found cmdstanr documentation). use 2 chains 2 threads per chain (using 4 CPU cores total) 500 warmup samples 1000 iterations per chain. complex model set adapt_delta 0.99 (default 0.8) Hamiltonian Monte Carlo sampler can explore posterior distribution efficiently. reason, also set max_treedepth 15 (default 10). Finally, set save_warmup FALSE save space (don’t need warmup samples analysis), pp TRUE can use posterior predictive checks assess model fit. 4 CPU cores available can increase number threads per chain make use additional cores. example 8 CPU cores available set threads_per_chain = 4 use 8 cores (2 chains).","code":"fit_module <- partial(enw_fit_opts,   chains = 2,   parallel_chains = 2,   threads_per_chain = 2,   iter_warmup = 500,   iter_sampling = 1000,   adapt_delta = 0.99,   max_treedepth = 15,   save_warmup = FALSE,   pp = TRUE,   show_messages = interactive(),   refresh = as.numeric(interactive()) )"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"compiling-the-model","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany > Fitting the epinowcast model","what":"Compiling the model","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"also need compile model using cmdstanr fitting (installing package). order line work followed installation guide README. take around minute run called first time.","code":"epinowcast_model <- enw_model(threads = TRUE, profile = FALSE) #>  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /  -  \\  |  /"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"fitting-the-model","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany > Fitting the epinowcast model","what":"Fitting the model","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"Now ready bring together modules specified, combine model just compiled, fit synthetic data. first fit data available real-time, Fitting model default options take around 5 minutes run laptop 4 CPU cores. CPU cores available can reduce time takes fit model increasing number threads per chain (see fitting options section ). retrospectivly observed data. may see number warning messages cmdstanr fitting model. generally occur model initialised due process currently optimised epinowcast. model still fit correctly unless warnings continue fitting process (outside warmup phase). something actively working improving future versions epinowcast.","code":"germany_nowcast <- epinowcast(   data = rt_germany_pobs,   expectation = expectation_module(data = rt_germany_pobs),   reference = reference_module(data = rt_germany_pobs),   obs = obs_module(data = rt_germany_pobs),   fit = fit_module(),   model = epinowcast_model ) #> Running MCMC with 2 parallel chains, with 2 thread(s) per chain... #>  #> Chain 1 Iteration:    1 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    2 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    3 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    4 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    5 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    6 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    7 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    8 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    9 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   10 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   11 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   12 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   13 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   14 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   15 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   16 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   17 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   18 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   19 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   20 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   21 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   22 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   23 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   24 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   25 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   26 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   27 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   28 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   29 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   30 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   31 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   32 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   33 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   34 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   35 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   36 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   37 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   38 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   39 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   40 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   41 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   42 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   43 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   44 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   45 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   46 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   47 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   48 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   49 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:    1 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    2 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    3 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    4 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    5 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    6 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    7 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    8 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    9 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   10 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   11 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   12 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   13 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   14 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   15 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   16 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   17 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   18 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   19 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   20 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   21 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   22 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   23 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   24 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   25 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   26 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   27 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   28 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   29 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   30 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   31 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   32 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   33 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   34 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   35 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   36 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   37 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   38 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   39 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   40 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   41 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   42 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   43 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   44 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   45 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   46 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   47 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   48 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   49 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   50 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   51 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   52 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   53 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   54 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   55 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   56 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   57 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   58 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   59 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   60 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   61 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   62 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   63 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   64 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   65 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   66 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   67 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   68 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   69 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   70 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   71 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   50 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   51 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   72 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   73 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   74 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   75 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   76 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   77 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   78 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   79 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   80 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   81 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   82 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   83 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   84 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   85 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   86 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   87 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   88 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   89 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   90 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   91 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   92 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   93 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   94 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   95 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   96 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   97 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   98 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   99 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  100 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  101 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  102 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  103 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   52 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   53 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:  104 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  105 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  106 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  107 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   54 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:  108 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  109 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   55 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   56 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   57 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   58 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   59 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   60 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   61 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   62 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  110 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   63 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   64 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   65 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   66 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   67 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   68 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   69 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   70 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  111 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   71 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   72 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   73 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   74 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   75 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   76 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   77 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  112 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   78 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   79 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   80 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   81 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   82 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   83 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  113 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   84 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   85 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   86 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   87 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   88 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   89 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  114 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   90 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  115 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   91 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   92 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  116 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   93 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   94 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   95 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   96 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   97 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  117 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   98 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   99 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  100 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  101 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  102 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  103 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  104 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  118 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  105 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  106 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  107 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  119 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  108 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  109 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  110 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  111 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  120 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  112 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  113 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  114 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  115 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  121 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  116 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  117 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  118 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  119 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  120 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  121 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  122 / 1500 [  8%]  (Warmup)  #> Chain 2 Iteration:  122 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  123 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  124 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  125 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  126 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  127 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  128 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  129 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  130 / 1500 [  8%]  (Warmup)  #> Chain 2 Iteration:  123 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  131 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  132 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  133 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  134 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  135 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  136 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  137 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  138 / 1500 [  9%]  (Warmup)  #> Chain 2 Iteration:  124 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  139 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  140 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  141 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  142 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  143 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  144 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  145 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  146 / 1500 [  9%]  (Warmup)  #> Chain 2 Iteration:  125 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  147 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  148 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  149 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  150 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  151 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  152 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  153 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  154 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  155 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  156 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  157 / 1500 [ 10%]  (Warmup)  #> Chain 2 Iteration:  126 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  158 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  159 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  160 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  161 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  162 / 1500 [ 10%]  (Warmup)  #> Chain 2 Iteration:  127 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  163 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  164 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  165 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  166 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  167 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  168 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  169 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  170 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  171 / 1500 [ 11%]  (Warmup)  #> Chain 2 Iteration:  128 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  172 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  173 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  174 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  175 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  176 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  177 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  178 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  179 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  180 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  181 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  182 / 1500 [ 12%]  (Warmup)  #> Chain 2 Iteration:  129 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  183 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  184 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  185 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  186 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  187 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  188 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  189 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  190 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  191 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  192 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  193 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  194 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  195 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  196 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  197 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  198 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  199 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  200 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  201 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  202 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  203 / 1500 [ 13%]  (Warmup)  #> Chain 2 Iteration:  130 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  204 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  205 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  206 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  207 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  208 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  209 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  210 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  211 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  212 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  213 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  214 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  215 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  216 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  217 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  218 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  219 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  220 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  221 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  222 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  223 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  224 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  225 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  226 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  227 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  228 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  229 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  230 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  231 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  232 / 1500 [ 15%]  (Warmup)  #> Chain 2 Iteration:  131 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  233 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  234 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  235 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  236 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  237 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  238 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  239 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  240 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  241 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  242 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  243 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  244 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  245 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  246 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  247 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  248 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  249 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  250 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  251 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  252 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  253 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  254 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  255 / 1500 [ 17%]  (Warmup)  #> Chain 2 Iteration:  132 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  256 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  257 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  258 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  259 / 1500 [ 17%]  (Warmup)  #> Chain 2 Iteration:  133 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  260 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  261 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  262 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  263 / 1500 [ 17%]  (Warmup)  #> Chain 2 Iteration:  134 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  264 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  265 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  266 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  267 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  268 / 1500 [ 17%]  (Warmup)  #> Chain 2 Iteration:  135 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  269 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  270 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  271 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  272 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  273 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  274 / 1500 [ 18%]  (Warmup)  #> Chain 2 Iteration:  136 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  275 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  276 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  277 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  278 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  279 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  280 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  281 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  282 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  283 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  284 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  285 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  286 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  137 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  287 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  288 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  289 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  290 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  291 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  292 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  293 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  294 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  295 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  296 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  297 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  298 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  299 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  300 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  301 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  302 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  303 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  304 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  305 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  306 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  307 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  308 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  138 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  309 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  310 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  311 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  312 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  313 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  314 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  315 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  316 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  317 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  318 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  319 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  320 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  321 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  322 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  323 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  324 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  325 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  326 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  327 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  328 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  329 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  330 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  331 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  332 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  333 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  334 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  335 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  336 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  337 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  338 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  339 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  139 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  340 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  341 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  342 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  343 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  344 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  345 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  346 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  347 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  348 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  349 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  350 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  351 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  352 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  353 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  354 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  355 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  356 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  357 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  358 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  359 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  360 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  140 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  361 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  362 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  363 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  364 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  365 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  366 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  367 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  368 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  369 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  370 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  371 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  372 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  373 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  374 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  375 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  376 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  377 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  378 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  379 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  380 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  381 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  382 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  383 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  384 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  385 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  386 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  141 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  387 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  388 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  389 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  390 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  391 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  392 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  393 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  394 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  395 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  396 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  397 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  398 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  399 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  400 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  401 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  402 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  403 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  404 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  405 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  406 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  407 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  408 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  409 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  410 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  411 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  412 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  413 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  142 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  414 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  415 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  416 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  417 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  418 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  419 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  420 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  421 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  422 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  423 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  424 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  425 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  426 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  427 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  428 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  429 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  430 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  431 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  432 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  433 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  434 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  435 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  436 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  437 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  438 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  439 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  440 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  441 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  442 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  143 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  443 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  444 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  445 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  446 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  447 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  448 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  449 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  450 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  451 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  452 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  453 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  454 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  455 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  456 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  457 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  458 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  144 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  459 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  460 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  461 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  462 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  463 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  145 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  464 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  465 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  466 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  467 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  468 / 1500 [ 31%]  (Warmup)  #> Chain 2 Iteration:  146 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  469 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  470 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  471 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  472 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  473 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  474 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  475 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  476 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  477 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  478 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  479 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  480 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  147 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  481 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  482 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  483 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  484 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  485 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  486 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  487 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  488 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  489 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  490 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  491 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  492 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  493 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  494 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  495 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  496 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  497 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  498 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  499 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  500 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  501 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  502 / 1500 [ 33%]  (Sampling)  #> Chain 2 Iteration:  148 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  503 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  504 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  505 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  506 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  507 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  508 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  509 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  510 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  511 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  512 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  513 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  514 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  515 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  516 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  517 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  518 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  519 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  520 / 1500 [ 34%]  (Sampling)  #> Chain 2 Iteration:  149 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  521 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  522 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  523 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  524 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  525 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  526 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  527 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  528 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  529 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  530 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  531 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  532 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  533 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  534 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  535 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  536 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  537 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  538 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  539 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  150 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  540 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  541 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  542 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  543 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  544 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  545 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  546 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  547 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  548 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  549 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  550 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  551 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  552 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  553 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  554 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  555 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  556 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  557 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  558 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  559 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  151 / 1500 [ 10%]  (Warmup)  #> Chain 2 Iteration:  152 / 1500 [ 10%]  (Warmup)  #> Chain 2 Iteration:  153 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  560 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  561 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  562 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  563 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  564 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  565 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  566 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  567 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  154 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  568 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  569 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  570 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  571 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  572 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  573 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  574 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  575 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  155 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  576 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  577 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  578 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  579 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  580 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  581 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  582 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  583 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  584 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  585 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  586 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  587 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  588 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  589 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  590 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  591 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  592 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  156 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  593 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  594 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  595 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  596 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  597 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  598 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  599 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  600 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  601 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  602 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  603 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  604 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  605 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  606 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  607 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  608 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  157 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  609 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  610 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  611 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  612 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  613 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  614 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  615 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  616 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  617 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  618 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  619 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  620 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  621 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  622 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  623 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  624 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  158 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  625 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  626 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  627 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  628 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  629 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  630 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  631 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  632 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  633 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  634 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  635 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  636 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  637 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  638 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  639 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  159 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  640 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  641 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  642 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  643 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  644 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  645 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  646 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  647 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  648 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  649 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  650 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  651 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  652 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  653 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  654 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  655 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  160 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  656 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  657 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  658 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  659 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  660 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  661 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  662 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  663 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  664 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  665 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  666 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  667 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  668 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  669 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  670 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  671 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  672 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  673 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  674 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  161 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  675 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  676 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  677 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  678 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  679 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  680 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  681 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  682 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  683 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  684 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  685 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  686 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  687 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  688 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  689 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  690 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  162 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  691 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  692 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  693 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  694 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  695 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  696 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  697 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  698 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  699 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  700 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  701 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  702 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  703 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  704 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  705 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  706 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  163 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  707 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  708 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  709 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  710 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  711 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  712 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  713 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  714 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  715 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  716 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  717 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  718 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  719 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  720 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  721 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  722 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  164 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  723 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  724 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  725 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  726 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  727 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  728 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  729 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  730 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  731 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  732 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  733 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  734 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  735 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  736 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  737 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  738 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  739 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  740 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  165 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  741 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  742 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  743 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  744 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  745 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  746 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  747 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  748 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  749 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  750 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  751 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  752 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  753 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  754 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  755 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  756 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  166 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  757 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  758 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  759 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  760 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  761 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  762 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  763 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  764 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  765 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  766 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  767 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  768 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  769 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  770 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  771 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  772 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  773 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  167 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  774 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  775 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  776 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  777 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  778 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  779 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  780 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  781 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  782 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  783 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  784 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  785 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  786 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  787 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  788 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  789 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  790 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  168 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  791 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  792 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  793 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  794 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  795 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  796 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  797 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  798 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  799 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  800 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  801 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  802 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  803 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  804 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  805 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  806 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  169 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  807 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  808 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  809 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  810 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  811 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  812 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  813 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  814 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  815 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  816 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  817 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  818 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  819 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  820 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  821 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  822 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  823 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  170 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  824 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  825 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  826 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  827 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  828 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  829 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  830 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  831 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  832 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  833 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  834 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  835 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  836 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  837 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  838 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  171 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  839 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  840 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  841 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  842 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  843 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  844 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  845 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  846 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  847 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  848 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  849 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  850 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  851 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  852 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  853 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  854 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  855 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  856 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  172 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  857 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  858 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  859 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  860 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  861 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  862 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  863 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  864 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  865 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  866 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  867 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  868 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  869 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  870 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  871 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  872 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  173 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  873 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  874 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  875 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  876 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  877 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  878 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  879 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  880 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  174 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  881 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  882 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  883 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  884 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  885 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  886 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  887 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  888 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  889 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  890 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  891 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  892 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  893 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  894 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  895 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  896 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  175 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  897 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  898 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  899 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  900 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  901 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  902 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  903 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  904 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  905 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  176 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  906 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  907 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  908 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  909 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  910 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  911 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  912 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  913 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  177 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  914 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  915 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  916 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  917 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  918 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  919 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  920 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  921 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  922 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  923 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  924 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  925 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  926 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  927 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  928 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  929 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  178 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  930 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  931 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  932 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  933 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  934 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  935 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  936 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  937 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  179 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  938 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  939 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  940 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  180 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  941 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  942 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  943 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  944 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  945 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  946 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  947 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  948 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  949 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  950 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  181 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  951 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  952 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  953 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  954 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  955 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  956 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  957 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  958 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  182 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  959 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  960 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  961 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  962 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  183 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  963 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  964 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  965 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  966 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  967 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  968 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  969 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  970 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  971 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  184 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  972 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  973 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  974 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  975 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  976 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  977 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  978 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  979 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  185 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  980 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  981 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  982 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  983 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  984 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  186 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  985 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  986 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  987 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  988 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  989 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  990 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  991 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  992 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  187 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  993 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  994 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  995 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  996 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  188 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  997 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  998 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  999 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration: 1000 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  189 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration: 1001 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration: 1002 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration: 1003 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration: 1004 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  190 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration: 1005 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1006 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1007 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1008 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration:  191 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration: 1009 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1010 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1011 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1012 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1013 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1014 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1015 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1016 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1017 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration:  192 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration: 1018 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1019 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1020 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1021 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1022 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1023 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1024 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1025 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration:  193 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration: 1026 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1027 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1028 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1029 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration:  194 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration: 1030 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1031 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1032 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1033 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1034 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1035 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1036 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1037 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1038 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration:  195 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1039 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1040 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1041 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1042 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration:  196 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1043 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1044 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1045 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration:  197 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1046 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1047 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1048 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1049 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1050 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1051 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1052 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1053 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration:  198 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1054 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1055 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1056 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1057 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1058 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1059 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration:  199 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1060 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1061 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1062 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1063 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1064 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration:  200 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1065 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1066 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1067 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1068 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration:  201 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1069 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1070 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1071 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1072 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1073 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1074 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1075 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1076 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration:  202 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1077 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1078 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1079 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1080 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration:  203 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1081 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1082 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1083 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1084 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration:  204 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1085 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1086 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1087 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1088 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1089 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration:  205 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1090 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1091 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1092 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1093 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration:  206 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1094 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1095 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1096 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1097 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  207 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1098 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1099 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  208 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1100 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1101 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1102 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1103 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  209 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration: 1104 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1105 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1106 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1107 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  210 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1108 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1109 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  211 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1110 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1111 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1112 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1113 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  212 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1114 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1115 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1116 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1117 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  213 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1118 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1119 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  214 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1120 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1121 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1122 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1123 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  215 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1124 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1125 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  216 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1126 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1127 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1128 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1129 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  217 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1130 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1131 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1132 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1133 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1134 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  218 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1135 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1136 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1137 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1138 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1139 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  219 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1140 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1141 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1142 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1143 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  220 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1144 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1145 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1146 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1147 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  221 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1148 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1149 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1150 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  222 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1151 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1152 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1153 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1154 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  223 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1155 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1156 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1157 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  224 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration: 1158 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1159 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  225 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1160 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1161 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1162 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  226 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1163 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  227 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1164 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1165 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1166 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  228 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1167 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1168 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  229 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1169 / 1500 [ 77%]  (Sampling)  #> Chain 1 Iteration: 1170 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1171 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1172 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1173 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  230 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1174 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1175 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  231 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1176 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1177 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1178 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1179 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1180 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1181 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1182 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1183 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1184 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  232 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1185 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1186 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1187 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1188 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  233 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1189 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1190 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1191 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1192 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1193 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  234 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1194 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1195 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1196 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1197 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1198 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  235 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1199 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1200 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1201 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1202 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  236 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1203 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1204 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1205 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1206 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  237 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1207 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1208 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1209 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1210 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  238 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1211 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1212 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1213 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  239 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration: 1214 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  240 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1215 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1216 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1217 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1218 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1219 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  241 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1220 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1221 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  242 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1222 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1223 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1224 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  243 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1225 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1226 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1227 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1228 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  244 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1229 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1230 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1231 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1232 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  245 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1233 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1234 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1235 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1236 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  246 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1237 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1238 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1239 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1240 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1241 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  247 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1242 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1243 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  248 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1244 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1245 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  249 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1246 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1247 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  250 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1248 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1249 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  251 / 1500 [ 16%]  (Warmup)  #> Chain 2 Iteration:  252 / 1500 [ 16%]  (Warmup)  #> Chain 2 Iteration:  253 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1250 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  254 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1251 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1252 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  255 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1253 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1254 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  256 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1255 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1256 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  257 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1257 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1258 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1259 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1260 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  258 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1261 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1262 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  259 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1263 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1264 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  260 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1265 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1266 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  261 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1267 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1268 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1269 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1270 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1271 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  262 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1272 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1273 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1274 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1275 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1276 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  263 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1277 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  264 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1278 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1279 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  265 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1280 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1281 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  266 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1282 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1283 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1284 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  267 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1285 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1286 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  268 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1287 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1288 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1289 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  269 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1290 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  270 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1291 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  271 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1292 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1293 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  272 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1294 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1295 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  273 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1296 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1297 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  274 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1298 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1299 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  275 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1300 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  276 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1301 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1302 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  277 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1303 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  278 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1304 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  279 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1305 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  280 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1306 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  281 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1307 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  282 / 1500 [ 18%]  (Warmup)  #> Chain 2 Iteration:  283 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1308 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  284 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1309 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  285 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1310 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  286 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1311 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  287 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  288 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1312 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  289 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  290 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1313 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  291 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  292 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1314 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  293 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  294 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1315 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  295 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  296 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1316 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  297 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  298 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1317 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  299 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  300 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1318 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  301 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  302 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1319 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  303 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  304 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1320 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  305 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  306 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1321 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  307 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  308 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1322 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  309 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1323 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  310 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1324 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  311 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  312 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  313 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1325 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  314 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  315 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  316 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  317 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1326 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  318 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1327 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  319 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  320 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1328 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  321 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  322 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1329 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  323 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1330 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  324 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1331 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  325 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  326 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1332 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  327 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  328 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1333 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  329 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  330 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1334 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  331 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1335 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  332 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  333 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1336 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  334 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  335 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1337 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  336 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  337 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1338 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  338 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  339 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1339 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  340 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  341 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1340 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1341 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  342 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  343 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  344 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1342 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  345 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  346 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1343 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  347 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  348 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  349 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1344 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  350 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  351 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1345 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  352 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  353 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1346 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  354 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  355 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1347 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  356 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  357 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1348 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  358 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1349 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  359 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  360 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1350 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  361 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  362 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1351 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  363 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  364 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1352 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  365 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1353 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  366 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1354 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  367 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1355 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  368 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1356 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  369 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1357 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  370 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  371 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1358 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  372 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1359 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  373 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1360 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  374 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1361 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  375 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  376 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1362 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  377 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1363 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  378 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  379 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  380 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1364 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  381 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  382 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1365 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  383 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  384 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1366 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  385 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1367 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  386 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  387 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  388 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1368 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  389 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  390 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  391 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  392 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1369 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  393 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  394 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1370 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  395 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  396 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1371 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  397 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  398 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  399 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  400 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1372 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  401 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1373 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  402 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1374 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  403 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1375 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  404 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  405 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1376 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  406 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  407 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1377 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  408 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  409 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1378 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  410 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1379 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  411 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  412 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  413 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1380 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  414 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1381 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  415 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  416 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1382 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  417 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  418 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1383 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  419 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  420 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1384 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  421 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  422 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1385 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  423 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1386 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  424 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  425 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1387 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  426 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1388 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  427 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  428 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1389 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  429 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  430 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1390 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  431 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1391 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  432 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1392 / 1500 [ 92%]  (Sampling)  #> Chain 1 Iteration: 1393 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  433 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1394 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  434 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1395 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  435 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1396 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  436 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1397 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  437 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1398 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  438 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1399 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  439 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  440 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1400 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  441 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1401 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  442 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  443 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1402 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  444 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  445 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1403 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  446 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  447 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  448 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1404 / 1500 [ 93%]  (Sampling)  #> Chain 1 Iteration: 1405 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  449 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1406 / 1500 [ 93%]  (Sampling)  #> Chain 1 Iteration: 1407 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  450 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1408 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  451 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  452 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  453 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1409 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  454 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1410 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1411 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  455 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  456 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1412 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  457 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1413 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1414 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1415 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  458 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1416 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1417 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  459 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1418 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  460 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1419 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1420 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  461 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1421 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1422 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  462 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1423 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1424 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  463 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1425 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  464 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1426 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1427 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  465 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1428 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1429 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1430 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  466 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1431 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1432 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  467 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1433 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  468 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1434 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  469 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1435 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  470 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1436 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  471 / 1500 [ 31%]  (Warmup)  #> Chain 2 Iteration:  472 / 1500 [ 31%]  (Warmup)  #> Chain 2 Iteration:  473 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1437 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  474 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1438 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  475 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1439 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  476 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1440 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  477 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1441 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1442 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  478 / 1500 [ 31%]  (Warmup)  #> Chain 2 Iteration:  479 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1443 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  480 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  481 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1444 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  482 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  483 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1445 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1446 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  484 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  485 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  486 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1447 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  487 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  488 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1448 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  489 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  490 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1449 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  491 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  492 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1450 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  493 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  494 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  495 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration: 1451 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  496 / 1500 [ 33%]  (Warmup)  #> Chain 2 Iteration:  497 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration: 1452 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  498 / 1500 [ 33%]  (Warmup)  #> Chain 2 Iteration:  499 / 1500 [ 33%]  (Warmup)  #> Chain 2 Iteration:  500 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration: 1453 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  501 / 1500 [ 33%]  (Sampling)  #> Chain 2 Iteration:  502 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1454 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  503 / 1500 [ 33%]  (Sampling)  #> Chain 2 Iteration:  504 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1455 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  505 / 1500 [ 33%]  (Sampling)  #> Chain 2 Iteration:  506 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1456 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  507 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1457 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  508 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1458 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  509 / 1500 [ 33%]  (Sampling)  #> Chain 2 Iteration:  510 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1459 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  511 / 1500 [ 34%]  (Sampling)  #> Chain 2 Iteration:  512 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1460 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  513 / 1500 [ 34%]  (Sampling)  #> Chain 2 Iteration:  514 / 1500 [ 34%]  (Sampling)  #> Chain 2 Iteration:  515 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1461 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  516 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1462 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  517 / 1500 [ 34%]  (Sampling)  #> Chain 2 Iteration:  518 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1463 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  519 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1464 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  520 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1465 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  521 / 1500 [ 34%]  (Sampling)  #> Chain 2 Iteration:  522 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1466 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  523 / 1500 [ 34%]  (Sampling)  #> Chain 2 Iteration:  524 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1467 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  525 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  526 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1468 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  527 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  528 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1469 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  529 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  530 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  531 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1470 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  532 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  533 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1471 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  534 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  535 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1472 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  536 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  537 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1473 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  538 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  539 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1474 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  540 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1475 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  541 / 1500 [ 36%]  (Sampling)  #> Chain 2 Iteration:  542 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1476 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  543 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1477 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  544 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1478 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  545 / 1500 [ 36%]  (Sampling)  #> Chain 2 Iteration:  546 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1479 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  547 / 1500 [ 36%]  (Sampling)  #> Chain 2 Iteration:  548 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1480 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  549 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1481 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  550 / 1500 [ 36%]  (Sampling)  #> Chain 2 Iteration:  551 / 1500 [ 36%]  (Sampling)  #> Chain 2 Iteration:  552 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1482 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  553 / 1500 [ 36%]  (Sampling)  #> Chain 2 Iteration:  554 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1483 / 1500 [ 98%]  (Sampling)  #> Chain 1 Iteration: 1484 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  555 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  556 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1485 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  557 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  558 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1486 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  559 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  560 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1487 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  561 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1488 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  562 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1489 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  563 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1490 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  564 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  565 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1491 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  566 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1492 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  567 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  568 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration: 1493 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  569 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  570 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration: 1494 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  571 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  572 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  573 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration: 1495 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  574 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  575 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration: 1496 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  576 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  577 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration: 1497 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  578 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  579 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration: 1498 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  580 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  581 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration: 1499 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  582 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration: 1500 / 1500 [100%]  (Sampling)  #> Chain 2 Iteration:  583 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  584 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  585 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  586 / 1500 [ 39%]  (Sampling)  #> Chain 1 finished in 452.6 seconds. #> Chain 2 Iteration:  587 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  588 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  589 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  590 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  591 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  592 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  593 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  594 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  595 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  596 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  597 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  598 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  599 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  600 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  601 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  602 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  603 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  604 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  605 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  606 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  607 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  608 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  609 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  610 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  611 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  612 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  613 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  614 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  615 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  616 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  617 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  618 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  619 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  620 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  621 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  622 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  623 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  624 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  625 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  626 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  627 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  628 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  629 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  630 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  631 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  632 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  633 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  634 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  635 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  636 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  637 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  638 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  639 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  640 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  641 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  642 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  643 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  644 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  645 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  646 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  647 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  648 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  649 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  650 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  651 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  652 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  653 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  654 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  655 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  656 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  657 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  658 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  659 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  660 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  661 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  662 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  663 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  664 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  665 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  666 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  667 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  668 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  669 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  670 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  671 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  672 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  673 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  674 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  675 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  676 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  677 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  678 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  679 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  680 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  681 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  682 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  683 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  684 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  685 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  686 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  687 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  688 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  689 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  690 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  691 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  692 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  693 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  694 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  695 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  696 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  697 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  698 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  699 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  700 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  701 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  702 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  703 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  704 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  705 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  706 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  707 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  708 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  709 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  710 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  711 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  712 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  713 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  714 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  715 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  716 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  717 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  718 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  719 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  720 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  721 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  722 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  723 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  724 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  725 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  726 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  727 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  728 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  729 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  730 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  731 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  732 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  733 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  734 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  735 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  736 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  737 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  738 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  739 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  740 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  741 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  742 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  743 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  744 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  745 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  746 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  747 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  748 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  749 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  750 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  751 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  752 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  753 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  754 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  755 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  756 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  757 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  758 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  759 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  760 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  761 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  762 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  763 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  764 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  765 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  766 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  767 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  768 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  769 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  770 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  771 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  772 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  773 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  774 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  775 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  776 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  777 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  778 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  779 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  780 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  781 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  782 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  783 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  784 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  785 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  786 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  787 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  788 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  789 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  790 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  791 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  792 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  793 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  794 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  795 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  796 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  797 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  798 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  799 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  800 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  801 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  802 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  803 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  804 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  805 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  806 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  807 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  808 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  809 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  810 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  811 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  812 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  813 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  814 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  815 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  816 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  817 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  818 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  819 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  820 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  821 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  822 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  823 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  824 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  825 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  826 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  827 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  828 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  829 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  830 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  831 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  832 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  833 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  834 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  835 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  836 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  837 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  838 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  839 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  840 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  841 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  842 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  843 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  844 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  845 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  846 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  847 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  848 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  849 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  850 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  851 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  852 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  853 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  854 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  855 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  856 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  857 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  858 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  859 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  860 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  861 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  862 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  863 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  864 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  865 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  866 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  867 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  868 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  869 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  870 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  871 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  872 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  873 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  874 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  875 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  876 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  877 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  878 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  879 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  880 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  881 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  882 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  883 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  884 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  885 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  886 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  887 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  888 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  889 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  890 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  891 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  892 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  893 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  894 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  895 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  896 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  897 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  898 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  899 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  900 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  901 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  902 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  903 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  904 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  905 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  906 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  907 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  908 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  909 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  910 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  911 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  912 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  913 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  914 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  915 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  916 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  917 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  918 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  919 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  920 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  921 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  922 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  923 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  924 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  925 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  926 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  927 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  928 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  929 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  930 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  931 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  932 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  933 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  934 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  935 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  936 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  937 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  938 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  939 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  940 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  941 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  942 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  943 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  944 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  945 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  946 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  947 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  948 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  949 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  950 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  951 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  952 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  953 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  954 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  955 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  956 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  957 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  958 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  959 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  960 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  961 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  962 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  963 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  964 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  965 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  966 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  967 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  968 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  969 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  970 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  971 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  972 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  973 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  974 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  975 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  976 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  977 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  978 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  979 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  980 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  981 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  982 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  983 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  984 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  985 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  986 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  987 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  988 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  989 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  990 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  991 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  992 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  993 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  994 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  995 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  996 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  997 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  998 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  999 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1000 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1001 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1002 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1003 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1004 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1005 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1006 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1007 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1008 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1009 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1010 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1011 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1012 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1013 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1014 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1015 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1016 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1017 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1018 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1019 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1020 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1021 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1022 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1023 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1024 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1025 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1026 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1027 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1028 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1029 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1030 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1031 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1032 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1033 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1034 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1035 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1036 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1037 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1038 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1039 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1040 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1041 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1042 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1043 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1044 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1045 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1046 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1047 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1048 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1049 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1050 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1051 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1052 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1053 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1054 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1055 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1056 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1057 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1058 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1059 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1060 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1061 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1062 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1063 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1064 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1065 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1066 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1067 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1068 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1069 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1070 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1071 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1072 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1073 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1074 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1075 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1076 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1077 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1078 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1079 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1080 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1081 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1082 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1083 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1084 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1085 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1086 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1087 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1088 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1089 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1090 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1091 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1092 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1093 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1094 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1095 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1096 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1097 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1098 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1099 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1100 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1101 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1102 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1103 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1104 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1105 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1106 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1107 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1108 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1109 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1110 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1111 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1112 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1113 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1114 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1115 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1116 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1117 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1118 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1119 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1120 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1121 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1122 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1123 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1124 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1125 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1126 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1127 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1128 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1129 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1130 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1131 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1132 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1133 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1134 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1135 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1136 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1137 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1138 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1139 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1140 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1141 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1142 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1143 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1144 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1145 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1146 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1147 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1148 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1149 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1150 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1151 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1152 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1153 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1154 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1155 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1156 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1157 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1158 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1159 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1160 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1161 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1162 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1163 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1164 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1165 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1166 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1167 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1168 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1169 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1170 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1171 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1172 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1173 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1174 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1175 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1176 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1177 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1178 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1179 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1180 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1181 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1182 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1183 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1184 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1185 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1186 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1187 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1188 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1189 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1190 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1191 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1192 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1193 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1194 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1195 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1196 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1197 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1198 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1199 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1200 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1201 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1202 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1203 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1204 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1205 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1206 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1207 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1208 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1209 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1210 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1211 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1212 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1213 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1214 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1215 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1216 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1217 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1218 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1219 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1220 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1221 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1222 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1223 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1224 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1225 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1226 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1227 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1228 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1229 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1230 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1231 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1232 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1233 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1234 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1235 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1236 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1237 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1238 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1239 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1240 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1241 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1242 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1243 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1244 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1245 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1246 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1247 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1248 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1249 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1250 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1251 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1252 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1253 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1254 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1255 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1256 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1257 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1258 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1259 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1260 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1261 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1262 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1263 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1264 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1265 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1266 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1267 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1268 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1269 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1270 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1271 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1272 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1273 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1274 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1275 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1276 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1277 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1278 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1279 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1280 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1281 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1282 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1283 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1284 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1285 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1286 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1287 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1288 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1289 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1290 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1291 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1292 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1293 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1294 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1295 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1296 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1297 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1298 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1299 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1300 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1301 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1302 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1303 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1304 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1305 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1306 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1307 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1308 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1309 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1310 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1311 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1312 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1313 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1314 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1315 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1316 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1317 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1318 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1319 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1320 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1321 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1322 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1323 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1324 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1325 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1326 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1327 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1328 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1329 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1330 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1331 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1332 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1333 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1334 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1335 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1336 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1337 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1338 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1339 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1340 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1341 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1342 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1343 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1344 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1345 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1346 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1347 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1348 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1349 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1350 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1351 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1352 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1353 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1354 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1355 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1356 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1357 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1358 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1359 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1360 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1361 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1362 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1363 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1364 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1365 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1366 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1367 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1368 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1369 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1370 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1371 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1372 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1373 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1374 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1375 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1376 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1377 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1378 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1379 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1380 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1381 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1382 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1383 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1384 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1385 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1386 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1387 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1388 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1389 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1390 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1391 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1392 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1393 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1394 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1395 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1396 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1397 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1398 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1399 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1400 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1401 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1402 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1403 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1404 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1405 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1406 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1407 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1408 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1409 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1410 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1411 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1412 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1413 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1414 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1415 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1416 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1417 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1418 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1419 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1420 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1421 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1422 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1423 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1424 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1425 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1426 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1427 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1428 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1429 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1430 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1431 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1432 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1433 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1434 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1435 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1436 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1437 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1438 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1439 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1440 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1441 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1442 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1443 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1444 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1445 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1446 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1447 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1448 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1449 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1450 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1451 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1452 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1453 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1454 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1455 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1456 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1457 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1458 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1459 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1460 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1461 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1462 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1463 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1464 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1465 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1466 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1467 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1468 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1469 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1470 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1471 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1472 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1473 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1474 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1475 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1476 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1477 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1478 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1479 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1480 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1481 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1482 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1483 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1484 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1485 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1486 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1487 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1488 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1489 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1490 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1491 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1492 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1493 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1494 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1495 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1496 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1497 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1498 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1499 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1500 / 1500 [100%]  (Sampling)  #> Chain 2 finished in 604.7 seconds. #>  #> Both chains finished successfully. #> Mean chain execution time: 528.6 seconds. #> Total execution time: 605.1 seconds. retro_germany_nowcast <- epinowcast(   data = retro_germany_pobs,   expectation = expectation_module(data = retro_germany_pobs),   reference = reference_module(data = retro_germany_pobs),   obs = obs_module(data = retro_germany_pobs),   fit = fit_module(),   model = epinowcast_model ) #> Running MCMC with 2 parallel chains, with 2 thread(s) per chain... #>  #> Chain 1 Iteration:    1 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    2 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    3 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    4 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    5 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    6 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    7 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    8 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:    9 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   10 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   11 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   12 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   13 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   14 / 1500 [  0%]  (Warmup)  #> Chain 1 Iteration:   15 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   16 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   17 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   18 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   19 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   20 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   21 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   22 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   23 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   24 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   25 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   26 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   27 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   28 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   29 / 1500 [  1%]  (Warmup)  #> Chain 1 Iteration:   30 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   31 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   32 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   33 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   34 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   35 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   36 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   37 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   38 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   39 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   40 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   41 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   42 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:    1 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    2 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    3 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    4 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    5 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    6 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    7 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    8 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:    9 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   10 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   11 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   12 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   13 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   14 / 1500 [  0%]  (Warmup)  #> Chain 2 Iteration:   15 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   16 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   17 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   18 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   19 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   20 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   21 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   22 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   23 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   24 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   25 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   26 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   27 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   28 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   29 / 1500 [  1%]  (Warmup)  #> Chain 2 Iteration:   30 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   31 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   32 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   33 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   34 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   35 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   36 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   37 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   38 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   39 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   40 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   41 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   42 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   43 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   44 / 1500 [  2%]  (Warmup)  #> Chain 2 Iteration:   45 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   46 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   47 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   48 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   49 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   50 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   51 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   52 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   53 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   54 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   55 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   43 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   44 / 1500 [  2%]  (Warmup)  #> Chain 1 Iteration:   45 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   46 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   47 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   48 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   56 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   57 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   58 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   59 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   60 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   61 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   62 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   63 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   64 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   65 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   66 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   67 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   68 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   69 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   70 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   71 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   72 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   73 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   74 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:   75 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   76 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   77 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   78 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   49 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   79 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   80 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   81 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   82 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   83 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   84 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   85 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   86 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   87 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   88 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   89 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:   90 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   91 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   92 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   93 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   94 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   50 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   95 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:   96 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   51 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   52 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   97 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   53 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   98 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   54 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   55 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:   99 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   56 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:  100 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   57 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:  101 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  102 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  103 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   58 / 1500 [  3%]  (Warmup)  #> Chain 1 Iteration:   59 / 1500 [  3%]  (Warmup)  #> Chain 2 Iteration:  104 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  105 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   60 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   61 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  106 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   62 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   63 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  107 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   64 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   65 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  108 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   66 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  109 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  110 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   67 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   68 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   69 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  111 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   70 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  112 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   71 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  113 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   72 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  114 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   73 / 1500 [  4%]  (Warmup)  #> Chain 1 Iteration:   74 / 1500 [  4%]  (Warmup)  #> Chain 2 Iteration:  115 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   75 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   76 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   77 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   78 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  116 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   79 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   80 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  117 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   81 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  118 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   82 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   83 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  119 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:   84 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   85 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  120 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:   86 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   87 / 1500 [  5%]  (Warmup)  #> Chain 2 Iteration:  121 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:   88 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   89 / 1500 [  5%]  (Warmup)  #> Chain 1 Iteration:   90 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   91 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  122 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:   92 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  123 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:   93 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  124 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:   94 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   95 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   96 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  125 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:   97 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   98 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:   99 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  100 / 1500 [  6%]  (Warmup)  #> Chain 2 Iteration:  126 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  101 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  102 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  103 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  104 / 1500 [  6%]  (Warmup)  #> Chain 1 Iteration:  105 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  127 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  106 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  107 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  108 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  128 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  109 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  110 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  111 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  129 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  112 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  113 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  130 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  114 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  115 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  116 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  117 / 1500 [  7%]  (Warmup)  #> Chain 2 Iteration:  131 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  118 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  119 / 1500 [  7%]  (Warmup)  #> Chain 1 Iteration:  120 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  121 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  122 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  123 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  124 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  125 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  126 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  127 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  128 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  129 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  130 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  131 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  132 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  133 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  134 / 1500 [  8%]  (Warmup)  #> Chain 2 Iteration:  132 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  135 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  136 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  137 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  138 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  139 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  140 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  141 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  142 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  143 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  144 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  145 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  146 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  147 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  148 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  149 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  150 / 1500 [ 10%]  (Warmup)  #> Chain 2 Iteration:  133 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  151 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  152 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  153 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  154 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  155 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  156 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  157 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  158 / 1500 [ 10%]  (Warmup)  #> Chain 2 Iteration:  134 / 1500 [  8%]  (Warmup)  #> Chain 1 Iteration:  159 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  160 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  161 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  162 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  163 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  164 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  165 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  166 / 1500 [ 11%]  (Warmup)  #> Chain 2 Iteration:  135 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  167 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  168 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  169 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  170 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  171 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  172 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  173 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  174 / 1500 [ 11%]  (Warmup)  #> Chain 2 Iteration:  136 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  175 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  176 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  177 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  178 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  179 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  180 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  181 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  182 / 1500 [ 12%]  (Warmup)  #> Chain 2 Iteration:  137 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  183 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  184 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  185 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  186 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  187 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  188 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  189 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  190 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  191 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  192 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  193 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  194 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  195 / 1500 [ 13%]  (Warmup)  #> Chain 2 Iteration:  138 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  196 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  197 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  198 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  199 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  200 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  201 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  202 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  203 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  204 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  205 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  206 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  207 / 1500 [ 13%]  (Warmup)  #> Chain 2 Iteration:  139 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  208 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  209 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  210 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  211 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  212 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  213 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  214 / 1500 [ 14%]  (Warmup)  #> Chain 2 Iteration:  140 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  215 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  216 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  217 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  218 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  219 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  220 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  221 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  222 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  223 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  224 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  225 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  226 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  227 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  228 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  229 / 1500 [ 15%]  (Warmup)  #> Chain 2 Iteration:  141 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  230 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  231 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  232 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  233 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  234 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  235 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  236 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  237 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  238 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  239 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  240 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  241 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  242 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  243 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  244 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  245 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  246 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  247 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  248 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  249 / 1500 [ 16%]  (Warmup)  #> Chain 2 Iteration:  142 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  250 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  251 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  252 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  253 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  254 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration:  255 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  256 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  257 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  258 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  259 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  260 / 1500 [ 17%]  (Warmup)  #> Chain 2 Iteration:  143 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  261 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  262 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  263 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  264 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  265 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  266 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  267 / 1500 [ 17%]  (Warmup)  #> Chain 2 Iteration:  144 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  268 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  269 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration:  270 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  271 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  272 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  273 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  274 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  275 / 1500 [ 18%]  (Warmup)  #> Chain 2 Iteration:  145 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  276 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  277 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  278 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  279 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  280 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  281 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  282 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  283 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  284 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration:  285 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  286 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  287 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  146 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  288 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  289 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  290 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  291 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  292 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  293 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  294 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  147 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  295 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  296 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  297 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  298 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  299 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration:  300 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  301 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  302 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  303 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  304 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  305 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  306 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  307 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  308 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  148 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  309 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  310 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  311 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  312 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  313 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  314 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration:  315 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  316 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  317 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  318 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  319 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  320 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  321 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  322 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  323 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  149 / 1500 [  9%]  (Warmup)  #> Chain 1 Iteration:  324 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  325 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  326 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  327 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  328 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  329 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration:  330 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  331 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  332 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  333 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  334 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  335 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  336 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  337 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  338 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  339 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  340 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  150 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  341 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  342 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  343 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  344 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration:  345 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  346 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  347 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  348 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  349 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  151 / 1500 [ 10%]  (Warmup)  #> Chain 2 Iteration:  152 / 1500 [ 10%]  (Warmup)  #> Chain 2 Iteration:  153 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  350 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  351 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  352 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  353 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  354 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  355 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  356 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  357 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  154 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  358 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  359 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration:  360 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  361 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  362 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  363 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  364 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  365 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  366 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  367 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  368 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  369 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  370 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  371 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  372 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  373 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  155 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  374 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration:  375 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  376 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  377 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  378 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  379 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  380 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  381 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  382 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  383 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  384 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  385 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  386 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  387 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  388 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  389 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration:  390 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  391 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  392 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  393 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  394 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  395 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  396 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  397 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  398 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  399 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  400 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  401 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  156 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  402 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  403 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  404 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration:  405 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  406 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  407 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  408 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  409 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  410 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  411 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  412 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  413 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  414 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  415 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  416 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  417 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  418 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  419 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration:  420 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  421 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  422 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  423 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  424 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  425 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  426 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  427 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  428 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  429 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  430 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  157 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  431 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  432 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  433 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  434 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration:  435 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  436 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  437 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  438 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  439 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  440 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  441 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  442 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  443 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  444 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  445 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  446 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  447 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  448 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  449 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration:  450 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  451 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  452 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  453 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  454 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  455 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  456 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  158 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  457 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  458 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  459 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  460 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  159 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  461 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  462 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  463 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  464 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration:  465 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  466 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  467 / 1500 [ 31%]  (Warmup)  #> Chain 2 Iteration:  160 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  468 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  469 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  470 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  471 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  472 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  473 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  474 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  475 / 1500 [ 31%]  (Warmup)  #> Chain 2 Iteration:  161 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  476 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  477 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  478 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  479 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration:  480 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  481 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  482 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  483 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  484 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  485 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  486 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  487 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  488 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  489 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  490 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  491 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  492 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  493 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  162 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  494 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration:  495 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  496 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  497 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  498 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  499 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  500 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration:  501 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  502 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  503 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  504 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  505 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  506 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  507 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  508 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  509 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration:  510 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  511 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  512 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  513 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  514 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  515 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  516 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  517 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  518 / 1500 [ 34%]  (Sampling)  #> Chain 2 Iteration:  163 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  519 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  520 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  521 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  522 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  523 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  524 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration:  525 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  526 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  527 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  528 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  529 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  530 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  531 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  532 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  533 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  534 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  535 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  536 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  537 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  538 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  164 / 1500 [ 10%]  (Warmup)  #> Chain 1 Iteration:  539 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration:  540 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  541 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  542 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  543 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  544 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  545 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  546 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  547 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  548 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  549 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  550 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  551 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  552 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  553 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  554 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration:  555 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  556 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  557 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  558 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  165 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  559 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  560 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  561 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  562 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  563 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  564 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  565 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  566 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  567 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  568 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  569 / 1500 [ 37%]  (Sampling)  #> Chain 1 Iteration:  570 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  571 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  572 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  573 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  574 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  575 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  576 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  577 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  578 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  579 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  166 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  580 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  581 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  582 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  583 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  584 / 1500 [ 38%]  (Sampling)  #> Chain 1 Iteration:  585 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  586 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  587 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  588 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  589 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  590 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  591 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  592 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  593 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  594 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  595 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  596 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  597 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  598 / 1500 [ 39%]  (Sampling)  #> Chain 1 Iteration:  599 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  167 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  600 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  601 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  602 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  603 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  604 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  605 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  606 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  607 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  608 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  609 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  610 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  611 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  612 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  613 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  614 / 1500 [ 40%]  (Sampling)  #> Chain 1 Iteration:  615 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  616 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  617 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  618 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  619 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  620 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  168 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  621 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  622 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  623 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  624 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  625 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  626 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  627 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  628 / 1500 [ 41%]  (Sampling)  #> Chain 1 Iteration:  629 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  169 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  630 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  631 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  632 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  633 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  634 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  635 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  636 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  637 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  638 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  639 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  170 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  640 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  641 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  642 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  643 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  644 / 1500 [ 42%]  (Sampling)  #> Chain 1 Iteration:  645 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  646 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  647 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  648 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  171 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  649 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  650 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  651 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  652 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  653 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  654 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  655 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  656 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  657 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  172 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  658 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  659 / 1500 [ 43%]  (Sampling)  #> Chain 1 Iteration:  660 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  661 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  662 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  663 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  664 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  665 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  666 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  667 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  668 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  173 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  669 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  670 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  671 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  672 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  673 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  674 / 1500 [ 44%]  (Sampling)  #> Chain 1 Iteration:  675 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  676 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  677 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  678 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  679 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  174 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  680 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  681 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  682 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  683 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  684 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  685 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  686 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  687 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  688 / 1500 [ 45%]  (Sampling)  #> Chain 1 Iteration:  689 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  175 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  690 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  691 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  692 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  693 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  694 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  695 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  696 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  697 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  698 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  699 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  700 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  176 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  701 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  702 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  703 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  704 / 1500 [ 46%]  (Sampling)  #> Chain 1 Iteration:  705 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  706 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  707 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  708 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  709 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  710 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  711 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  712 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  713 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  177 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  714 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  715 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  716 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  717 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  718 / 1500 [ 47%]  (Sampling)  #> Chain 1 Iteration:  719 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  178 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  720 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  721 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  722 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  723 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  724 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  725 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  726 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  727 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  728 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  179 / 1500 [ 11%]  (Warmup)  #> Chain 1 Iteration:  729 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  730 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  731 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  732 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  733 / 1500 [ 48%]  (Sampling)  #> Chain 1 Iteration:  734 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  180 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  735 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  736 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  737 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  738 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  739 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  740 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  741 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  742 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  743 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  744 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  745 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  746 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  747 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  181 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  748 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  749 / 1500 [ 49%]  (Sampling)  #> Chain 1 Iteration:  750 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  751 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  752 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  753 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  754 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  182 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  755 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  756 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  757 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  758 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  759 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  183 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  760 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  761 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  762 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  763 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  184 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  764 / 1500 [ 50%]  (Sampling)  #> Chain 1 Iteration:  765 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  766 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  767 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  185 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  768 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  769 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  770 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  186 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  771 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  772 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  773 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  774 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  775 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  776 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  187 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  777 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  778 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  779 / 1500 [ 51%]  (Sampling)  #> Chain 1 Iteration:  780 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  188 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  781 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  782 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  783 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  784 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  785 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  786 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  189 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  787 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  788 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  789 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  790 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  190 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  791 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  792 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  793 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  191 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  794 / 1500 [ 52%]  (Sampling)  #> Chain 1 Iteration:  795 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  796 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  797 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  798 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  799 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  192 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  800 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  801 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  802 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  803 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  804 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  805 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  193 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  806 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  807 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  808 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  809 / 1500 [ 53%]  (Sampling)  #> Chain 1 Iteration:  810 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  194 / 1500 [ 12%]  (Warmup)  #> Chain 1 Iteration:  811 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  812 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  813 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  814 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  195 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  815 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  816 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  817 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  818 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  819 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  820 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  196 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  821 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  822 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  823 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  824 / 1500 [ 54%]  (Sampling)  #> Chain 1 Iteration:  825 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  826 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  197 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  827 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  828 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  829 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  830 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  831 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  832 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  833 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  198 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  834 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  835 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  836 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  199 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  837 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  838 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  839 / 1500 [ 55%]  (Sampling)  #> Chain 1 Iteration:  840 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  841 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  200 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  842 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  843 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  844 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  845 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  846 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  847 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  848 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  201 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  849 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  850 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  851 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  852 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  853 / 1500 [ 56%]  (Sampling)  #> Chain 1 Iteration:  854 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  202 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  855 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  856 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  857 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  203 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  858 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  859 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  860 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  861 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  862 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  204 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  863 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  864 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  865 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  866 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  867 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  205 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  868 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  869 / 1500 [ 57%]  (Sampling)  #> Chain 1 Iteration:  870 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  871 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  872 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  206 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  873 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  874 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  875 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  876 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  877 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  207 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  878 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  879 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  880 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  881 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  882 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  883 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  208 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  884 / 1500 [ 58%]  (Sampling)  #> Chain 1 Iteration:  885 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  886 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  887 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  888 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  209 / 1500 [ 13%]  (Warmup)  #> Chain 1 Iteration:  889 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  890 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  891 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  210 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  892 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  893 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  894 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  211 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  895 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  896 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  897 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  898 / 1500 [ 59%]  (Sampling)  #> Chain 1 Iteration:  899 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  212 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  900 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  213 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  901 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  902 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  903 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  904 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  905 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  906 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  907 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  214 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  908 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  909 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  910 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  911 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  215 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  912 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  913 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  914 / 1500 [ 60%]  (Sampling)  #> Chain 1 Iteration:  915 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  916 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  917 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  216 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  918 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  919 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  920 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  217 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  921 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  922 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  218 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  923 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  924 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  925 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  219 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  926 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  927 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  928 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  220 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  929 / 1500 [ 61%]  (Sampling)  #> Chain 1 Iteration:  930 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  221 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  931 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  932 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  933 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  222 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  934 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  935 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  936 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  223 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  937 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  938 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  224 / 1500 [ 14%]  (Warmup)  #> Chain 1 Iteration:  939 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  940 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  941 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  942 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  943 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  225 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  944 / 1500 [ 62%]  (Sampling)  #> Chain 1 Iteration:  945 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  946 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  947 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  226 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  948 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  949 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  950 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  227 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  951 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  952 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  228 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  953 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  954 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  955 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  229 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  956 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  957 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  230 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  958 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  959 / 1500 [ 63%]  (Sampling)  #> Chain 1 Iteration:  960 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  961 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  231 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  962 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  963 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  964 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  965 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  232 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  966 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  967 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  968 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  969 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  970 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  971 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  233 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  972 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  973 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  974 / 1500 [ 64%]  (Sampling)  #> Chain 1 Iteration:  975 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  234 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  976 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  977 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  978 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  235 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  979 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  980 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  236 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  981 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  982 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  983 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  984 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  985 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  237 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  986 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  987 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  988 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  238 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  989 / 1500 [ 65%]  (Sampling)  #> Chain 1 Iteration:  990 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  991 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  992 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  239 / 1500 [ 15%]  (Warmup)  #> Chain 1 Iteration:  993 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  994 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  995 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  996 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  997 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  998 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration:  999 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  240 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1000 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration: 1001 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  241 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1002 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration: 1003 / 1500 [ 66%]  (Sampling)  #> Chain 1 Iteration: 1004 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  242 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1005 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1006 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1007 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1008 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration:  243 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1009 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1010 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1011 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration:  244 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1012 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1013 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1014 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1015 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1016 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration:  245 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1017 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1018 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1019 / 1500 [ 67%]  (Sampling)  #> Chain 1 Iteration: 1020 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration:  246 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1021 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1022 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1023 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1024 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1025 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration:  247 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1026 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1027 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1028 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1029 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1030 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1031 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1032 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration:  248 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1033 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1034 / 1500 [ 68%]  (Sampling)  #> Chain 1 Iteration: 1035 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1036 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration:  249 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1037 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1038 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1039 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1040 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1041 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration:  250 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1042 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1043 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1044 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1045 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1046 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1047 / 1500 [ 69%]  (Sampling)  #> Chain 1 Iteration: 1048 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration:  251 / 1500 [ 16%]  (Warmup)  #> Chain 2 Iteration:  252 / 1500 [ 16%]  (Warmup)  #> Chain 2 Iteration:  253 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1049 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration:  254 / 1500 [ 16%]  (Warmup)  #> Chain 1 Iteration: 1050 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1051 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration:  255 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1052 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1053 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration:  256 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1054 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1055 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1056 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1057 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1058 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration:  257 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1059 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1060 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1061 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1062 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1063 / 1500 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1064 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration:  258 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1065 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1066 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1067 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1068 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration:  259 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1069 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1070 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1071 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1072 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1073 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1074 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration:  260 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1075 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1076 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1077 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1078 / 1500 [ 71%]  (Sampling)  #> Chain 1 Iteration: 1079 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration:  261 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1080 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1081 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1082 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1083 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1084 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration:  262 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1085 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1086 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1087 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1088 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1089 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration:  263 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1090 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1091 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1092 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1093 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration:  264 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1094 / 1500 [ 72%]  (Sampling)  #> Chain 1 Iteration: 1095 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1096 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1097 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1098 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  265 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1099 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1100 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1101 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1102 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1103 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  266 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1104 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1105 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  267 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1106 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1107 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration:  268 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1108 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1109 / 1500 [ 73%]  (Sampling)  #> Chain 1 Iteration: 1110 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1111 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  269 / 1500 [ 17%]  (Warmup)  #> Chain 1 Iteration: 1112 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1113 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1114 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1115 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  270 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1116 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1117 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1118 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  271 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1119 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1120 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  272 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1121 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1122 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1123 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration:  273 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1124 / 1500 [ 74%]  (Sampling)  #> Chain 1 Iteration: 1125 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  274 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1126 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  275 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1127 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1128 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1129 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  276 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1130 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1131 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  277 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1132 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  278 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1133 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  279 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1134 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  280 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1135 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  281 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1136 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  282 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1137 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  283 / 1500 [ 18%]  (Warmup)  #> Chain 1 Iteration: 1138 / 1500 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1139 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration:  284 / 1500 [ 18%]  (Warmup)  #> Chain 2 Iteration:  285 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1140 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  286 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  287 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1141 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  288 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1142 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1143 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  289 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1144 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1145 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  290 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  291 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1146 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  292 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1147 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1148 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  293 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1149 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  294 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1150 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1151 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  295 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  296 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1152 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  297 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1153 / 1500 [ 76%]  (Sampling)  #> Chain 1 Iteration: 1154 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration:  298 / 1500 [ 19%]  (Warmup)  #> Chain 1 Iteration: 1155 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  299 / 1500 [ 19%]  (Warmup)  #> Chain 2 Iteration:  300 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1156 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  301 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  302 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1157 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  303 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1158 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  304 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  305 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1159 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  306 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  307 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1160 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  308 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1161 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  309 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1162 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  310 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1163 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  311 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  312 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1164 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  313 / 1500 [ 20%]  (Warmup)  #> Chain 2 Iteration:  314 / 1500 [ 20%]  (Warmup)  #> Chain 1 Iteration: 1165 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  315 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1166 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  316 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  317 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1167 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  318 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  319 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1168 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  320 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  321 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1169 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration:  322 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  323 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1170 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  324 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1171 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  325 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1172 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  326 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  327 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1173 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  328 / 1500 [ 21%]  (Warmup)  #> Chain 2 Iteration:  329 / 1500 [ 21%]  (Warmup)  #> Chain 1 Iteration: 1174 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  330 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1175 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  331 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  332 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1176 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  333 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  334 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1177 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  335 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  336 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1178 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  337 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  338 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1179 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  339 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1180 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  340 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1181 / 1500 [ 78%]  (Sampling)  #> Chain 1 Iteration: 1182 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  341 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1183 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  342 / 1500 [ 22%]  (Warmup)  #> Chain 2 Iteration:  343 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1184 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration:  344 / 1500 [ 22%]  (Warmup)  #> Chain 1 Iteration: 1185 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  345 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  346 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  347 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  348 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1186 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  349 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  350 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  351 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1187 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1188 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  352 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  353 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1189 / 1500 [ 79%]  (Sampling)  #> Chain 1 Iteration: 1190 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  354 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1191 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  355 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  356 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1192 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  357 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1193 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  358 / 1500 [ 23%]  (Warmup)  #> Chain 2 Iteration:  359 / 1500 [ 23%]  (Warmup)  #> Chain 1 Iteration: 1194 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  360 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  361 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1195 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  362 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  363 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1196 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  364 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  365 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1197 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  366 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1198 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  367 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1199 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration:  368 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1200 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  369 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1201 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  370 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  371 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1202 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  372 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  373 / 1500 [ 24%]  (Warmup)  #> Chain 1 Iteration: 1203 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  374 / 1500 [ 24%]  (Warmup)  #> Chain 2 Iteration:  375 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1204 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  376 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  377 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1205 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  378 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  379 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1206 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  380 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1207 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1208 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  381 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  382 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1209 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  383 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  384 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1210 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  385 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1211 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  386 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  387 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1212 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  388 / 1500 [ 25%]  (Warmup)  #> Chain 2 Iteration:  389 / 1500 [ 25%]  (Warmup)  #> Chain 1 Iteration: 1213 / 1500 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1214 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration:  390 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  391 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1215 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  392 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  393 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1216 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  394 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1217 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  395 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1218 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  396 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1219 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  397 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1220 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1221 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  398 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1222 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  399 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1223 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  400 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1224 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  401 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1225 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  402 / 1500 [ 26%]  (Warmup)  #> Chain 2 Iteration:  403 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1226 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  404 / 1500 [ 26%]  (Warmup)  #> Chain 1 Iteration: 1227 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  405 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  406 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1228 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration:  407 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  408 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1229 / 1500 [ 81%]  (Sampling)  #> Chain 1 Iteration: 1230 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  409 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1231 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  410 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  411 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1232 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  412 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1233 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  413 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1234 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  414 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  415 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1235 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1236 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  416 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  417 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1237 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  418 / 1500 [ 27%]  (Warmup)  #> Chain 2 Iteration:  419 / 1500 [ 27%]  (Warmup)  #> Chain 1 Iteration: 1238 / 1500 [ 82%]  (Sampling)  #> Chain 1 Iteration: 1239 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  420 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  421 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1240 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  422 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1241 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  423 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  424 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1242 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  425 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  426 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1243 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  427 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  428 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1244 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration:  429 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  430 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1245 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  431 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1246 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  432 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1247 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  433 / 1500 [ 28%]  (Warmup)  #> Chain 1 Iteration: 1248 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  434 / 1500 [ 28%]  (Warmup)  #> Chain 2 Iteration:  435 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1249 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  436 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  437 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1250 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  438 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  439 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1251 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  440 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  441 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1252 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  442 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  443 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1253 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  444 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1254 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  445 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1255 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  446 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1256 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  447 / 1500 [ 29%]  (Warmup)  #> Chain 2 Iteration:  448 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1257 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  449 / 1500 [ 29%]  (Warmup)  #> Chain 1 Iteration: 1258 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration:  450 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  451 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  452 / 1500 [ 30%]  (Warmup)  #> Chain 2 Iteration:  453 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1259 / 1500 [ 83%]  (Sampling)  #> Chain 1 Iteration: 1260 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1261 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1262 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  454 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1263 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1264 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  455 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1265 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1266 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1267 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1268 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1269 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  456 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1270 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1271 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1272 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1273 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration:  457 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1274 / 1500 [ 84%]  (Sampling)  #> Chain 1 Iteration: 1275 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1276 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1277 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  458 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1278 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1279 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1280 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1281 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1282 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1283 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1284 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1285 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1286 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration:  459 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1287 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1288 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1289 / 1500 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1290 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1291 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  460 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1292 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1293 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1294 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1295 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1296 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1297 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1298 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  461 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1299 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1300 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1301 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1302 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1303 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration:  462 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1304 / 1500 [ 86%]  (Sampling)  #> Chain 1 Iteration: 1305 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1306 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1307 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1308 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  463 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1309 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1310 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1311 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1312 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  464 / 1500 [ 30%]  (Warmup)  #> Chain 1 Iteration: 1313 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1314 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1315 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1316 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1317 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration:  465 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1318 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1319 / 1500 [ 87%]  (Sampling)  #> Chain 1 Iteration: 1320 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1321 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1322 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1323 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  466 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1324 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1325 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1326 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1327 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1328 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1329 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  467 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1330 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1331 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1332 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1333 / 1500 [ 88%]  (Sampling)  #> Chain 1 Iteration: 1334 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration:  468 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1335 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1336 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1337 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1338 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1339 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  469 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1340 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1341 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1342 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1343 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1344 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration:  470 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1345 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1346 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1347 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1348 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1349 / 1500 [ 89%]  (Sampling)  #> Chain 1 Iteration: 1350 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  471 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1351 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1352 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1353 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1354 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  472 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1355 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1356 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1357 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1358 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  473 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1359 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1360 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1361 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1362 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1363 / 1500 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1364 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration:  474 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1365 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1366 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1367 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  475 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1368 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1369 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  476 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1370 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1371 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1372 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1373 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1374 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1375 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1376 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration:  477 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1377 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1378 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1379 / 1500 [ 91%]  (Sampling)  #> Chain 1 Iteration: 1380 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  478 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1381 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  479 / 1500 [ 31%]  (Warmup)  #> Chain 1 Iteration: 1382 / 1500 [ 92%]  (Sampling)  #> Chain 1 Iteration: 1383 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  480 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1384 / 1500 [ 92%]  (Sampling)  #> Chain 1 Iteration: 1385 / 1500 [ 92%]  (Sampling)  #> Chain 1 Iteration: 1386 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  481 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1387 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  482 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1388 / 1500 [ 92%]  (Sampling)  #> Chain 1 Iteration: 1389 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  483 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1390 / 1500 [ 92%]  (Sampling)  #> Chain 1 Iteration: 1391 / 1500 [ 92%]  (Sampling)  #> Chain 1 Iteration: 1392 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  484 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1393 / 1500 [ 92%]  (Sampling)  #> Chain 1 Iteration: 1394 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration:  485 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1395 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  486 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1396 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  487 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1397 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  488 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1398 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  489 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1399 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  490 / 1500 [ 32%]  (Warmup)  #> Chain 2 Iteration:  491 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1400 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  492 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1401 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  493 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1402 / 1500 [ 93%]  (Sampling)  #> Chain 1 Iteration: 1403 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  494 / 1500 [ 32%]  (Warmup)  #> Chain 1 Iteration: 1404 / 1500 [ 93%]  (Sampling)  #> Chain 1 Iteration: 1405 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  495 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration: 1406 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  496 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration: 1407 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  497 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration: 1408 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  498 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration: 1409 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration:  499 / 1500 [ 33%]  (Warmup)  #> Chain 2 Iteration:  500 / 1500 [ 33%]  (Warmup)  #> Chain 1 Iteration: 1410 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1411 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  501 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1412 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  502 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1413 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  503 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1414 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  504 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1415 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  505 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1416 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1417 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  506 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1418 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1419 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1420 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  507 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1421 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  508 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1422 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  509 / 1500 [ 33%]  (Sampling)  #> Chain 1 Iteration: 1423 / 1500 [ 94%]  (Sampling)  #> Chain 1 Iteration: 1424 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration:  510 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1425 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1426 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1427 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  511 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1428 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  512 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1429 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1430 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  513 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1431 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1432 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  514 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1433 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1434 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  515 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1435 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1436 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1437 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  516 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1438 / 1500 [ 95%]  (Sampling)  #> Chain 1 Iteration: 1439 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration:  517 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1440 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1441 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1442 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  518 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1443 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  519 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1444 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1445 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  520 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1446 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1447 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  521 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1448 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1449 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1450 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  522 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1451 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  523 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1452 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration:  524 / 1500 [ 34%]  (Sampling)  #> Chain 1 Iteration: 1453 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1454 / 1500 [ 96%]  (Sampling)  #> Chain 1 Iteration: 1455 / 1500 [ 97%]  (Sampling)  #> Chain 1 Iteration: 1456 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  525 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1457 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  526 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1458 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  527 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1459 / 1500 [ 97%]  (Sampling)  #> Chain 1 Iteration: 1460 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  528 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1461 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  529 / 1500 [ 35%]  (Sampling)  #> Chain 2 Iteration:  530 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1462 / 1500 [ 97%]  (Sampling)  #> Chain 1 Iteration: 1463 / 1500 [ 97%]  (Sampling)  #> Chain 1 Iteration: 1464 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  531 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1465 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  532 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1466 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  533 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1467 / 1500 [ 97%]  (Sampling)  #> Chain 1 Iteration: 1468 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  534 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1469 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration:  535 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1470 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  536 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1471 / 1500 [ 98%]  (Sampling)  #> Chain 1 Iteration: 1472 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  537 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1473 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  538 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1474 / 1500 [ 98%]  (Sampling)  #> Chain 1 Iteration: 1475 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  539 / 1500 [ 35%]  (Sampling)  #> Chain 1 Iteration: 1476 / 1500 [ 98%]  (Sampling)  #> Chain 1 Iteration: 1477 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  540 / 1500 [ 36%]  (Sampling)  #> Chain 2 Iteration:  541 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1478 / 1500 [ 98%]  (Sampling)  #> Chain 1 Iteration: 1479 / 1500 [ 98%]  (Sampling)  #> Chain 1 Iteration: 1480 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  542 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1481 / 1500 [ 98%]  (Sampling)  #> Chain 1 Iteration: 1482 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  543 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1483 / 1500 [ 98%]  (Sampling)  #> Chain 1 Iteration: 1484 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration:  544 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1485 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  545 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1486 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  546 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1487 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  547 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1488 / 1500 [ 99%]  (Sampling)  #> Chain 1 Iteration: 1489 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  548 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1490 / 1500 [ 99%]  (Sampling)  #> Chain 1 Iteration: 1491 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  549 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1492 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  550 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1493 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  551 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1494 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  552 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1495 / 1500 [ 99%]  (Sampling)  #> Chain 1 Iteration: 1496 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  553 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1497 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration:  554 / 1500 [ 36%]  (Sampling)  #> Chain 1 Iteration: 1498 / 1500 [ 99%]  (Sampling)  #> Chain 1 Iteration: 1499 / 1500 [ 99%]  (Sampling)  #> Chain 1 Iteration: 1500 / 1500 [100%]  (Sampling)  #> Chain 2 Iteration:  555 / 1500 [ 37%]  (Sampling)  #> Chain 1 finished in 382.3 seconds. #> Chain 2 Iteration:  556 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  557 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  558 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  559 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  560 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  561 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  562 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  563 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  564 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  565 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  566 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  567 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  568 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  569 / 1500 [ 37%]  (Sampling)  #> Chain 2 Iteration:  570 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  571 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  572 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  573 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  574 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  575 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  576 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  577 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  578 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  579 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  580 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  581 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  582 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  583 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  584 / 1500 [ 38%]  (Sampling)  #> Chain 2 Iteration:  585 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  586 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  587 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  588 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  589 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  590 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  591 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  592 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  593 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  594 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  595 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  596 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  597 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  598 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  599 / 1500 [ 39%]  (Sampling)  #> Chain 2 Iteration:  600 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  601 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  602 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  603 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  604 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  605 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  606 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  607 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  608 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  609 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  610 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  611 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  612 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  613 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  614 / 1500 [ 40%]  (Sampling)  #> Chain 2 Iteration:  615 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  616 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  617 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  618 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  619 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  620 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  621 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  622 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  623 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  624 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  625 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  626 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  627 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  628 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  629 / 1500 [ 41%]  (Sampling)  #> Chain 2 Iteration:  630 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  631 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  632 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  633 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  634 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  635 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  636 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  637 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  638 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  639 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  640 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  641 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  642 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  643 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  644 / 1500 [ 42%]  (Sampling)  #> Chain 2 Iteration:  645 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  646 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  647 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  648 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  649 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  650 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  651 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  652 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  653 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  654 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  655 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  656 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  657 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  658 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  659 / 1500 [ 43%]  (Sampling)  #> Chain 2 Iteration:  660 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  661 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  662 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  663 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  664 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  665 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  666 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  667 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  668 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  669 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  670 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  671 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  672 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  673 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  674 / 1500 [ 44%]  (Sampling)  #> Chain 2 Iteration:  675 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  676 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  677 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  678 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  679 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  680 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  681 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  682 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  683 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  684 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  685 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  686 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  687 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  688 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  689 / 1500 [ 45%]  (Sampling)  #> Chain 2 Iteration:  690 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  691 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  692 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  693 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  694 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  695 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  696 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  697 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  698 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  699 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  700 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  701 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  702 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  703 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  704 / 1500 [ 46%]  (Sampling)  #> Chain 2 Iteration:  705 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  706 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  707 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  708 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  709 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  710 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  711 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  712 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  713 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  714 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  715 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  716 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  717 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  718 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  719 / 1500 [ 47%]  (Sampling)  #> Chain 2 Iteration:  720 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  721 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  722 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  723 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  724 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  725 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  726 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  727 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  728 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  729 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  730 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  731 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  732 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  733 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  734 / 1500 [ 48%]  (Sampling)  #> Chain 2 Iteration:  735 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  736 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  737 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  738 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  739 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  740 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  741 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  742 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  743 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  744 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  745 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  746 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  747 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  748 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  749 / 1500 [ 49%]  (Sampling)  #> Chain 2 Iteration:  750 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  751 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  752 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  753 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  754 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  755 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  756 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  757 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  758 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  759 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  760 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  761 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  762 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  763 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  764 / 1500 [ 50%]  (Sampling)  #> Chain 2 Iteration:  765 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  766 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  767 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  768 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  769 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  770 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  771 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  772 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  773 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  774 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  775 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  776 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  777 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  778 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  779 / 1500 [ 51%]  (Sampling)  #> Chain 2 Iteration:  780 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  781 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  782 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  783 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  784 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  785 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  786 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  787 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  788 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  789 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  790 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  791 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  792 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  793 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  794 / 1500 [ 52%]  (Sampling)  #> Chain 2 Iteration:  795 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  796 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  797 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  798 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  799 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  800 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  801 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  802 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  803 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  804 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  805 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  806 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  807 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  808 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  809 / 1500 [ 53%]  (Sampling)  #> Chain 2 Iteration:  810 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  811 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  812 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  813 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  814 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  815 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  816 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  817 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  818 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  819 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  820 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  821 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  822 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  823 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  824 / 1500 [ 54%]  (Sampling)  #> Chain 2 Iteration:  825 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  826 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  827 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  828 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  829 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  830 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  831 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  832 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  833 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  834 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  835 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  836 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  837 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  838 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  839 / 1500 [ 55%]  (Sampling)  #> Chain 2 Iteration:  840 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  841 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  842 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  843 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  844 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  845 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  846 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  847 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  848 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  849 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  850 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  851 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  852 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  853 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  854 / 1500 [ 56%]  (Sampling)  #> Chain 2 Iteration:  855 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  856 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  857 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  858 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  859 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  860 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  861 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  862 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  863 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  864 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  865 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  866 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  867 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  868 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  869 / 1500 [ 57%]  (Sampling)  #> Chain 2 Iteration:  870 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  871 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  872 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  873 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  874 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  875 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  876 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  877 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  878 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  879 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  880 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  881 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  882 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  883 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  884 / 1500 [ 58%]  (Sampling)  #> Chain 2 Iteration:  885 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  886 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  887 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  888 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  889 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  890 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  891 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  892 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  893 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  894 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  895 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  896 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  897 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  898 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  899 / 1500 [ 59%]  (Sampling)  #> Chain 2 Iteration:  900 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  901 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  902 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  903 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  904 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  905 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  906 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  907 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  908 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  909 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  910 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  911 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  912 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  913 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  914 / 1500 [ 60%]  (Sampling)  #> Chain 2 Iteration:  915 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  916 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  917 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  918 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  919 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  920 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  921 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  922 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  923 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  924 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  925 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  926 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  927 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  928 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  929 / 1500 [ 61%]  (Sampling)  #> Chain 2 Iteration:  930 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  931 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  932 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  933 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  934 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  935 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  936 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  937 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  938 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  939 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  940 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  941 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  942 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  943 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  944 / 1500 [ 62%]  (Sampling)  #> Chain 2 Iteration:  945 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  946 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  947 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  948 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  949 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  950 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  951 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  952 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  953 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  954 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  955 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  956 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  957 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  958 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  959 / 1500 [ 63%]  (Sampling)  #> Chain 2 Iteration:  960 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  961 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  962 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  963 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  964 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  965 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  966 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  967 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  968 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  969 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  970 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  971 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  972 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  973 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  974 / 1500 [ 64%]  (Sampling)  #> Chain 2 Iteration:  975 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  976 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  977 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  978 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  979 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  980 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  981 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  982 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  983 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  984 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  985 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  986 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  987 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  988 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  989 / 1500 [ 65%]  (Sampling)  #> Chain 2 Iteration:  990 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  991 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  992 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  993 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  994 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  995 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  996 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  997 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  998 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration:  999 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1000 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1001 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1002 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1003 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1004 / 1500 [ 66%]  (Sampling)  #> Chain 2 Iteration: 1005 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1006 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1007 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1008 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1009 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1010 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1011 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1012 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1013 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1014 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1015 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1016 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1017 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1018 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1019 / 1500 [ 67%]  (Sampling)  #> Chain 2 Iteration: 1020 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1021 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1022 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1023 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1024 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1025 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1026 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1027 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1028 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1029 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1030 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1031 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1032 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1033 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1034 / 1500 [ 68%]  (Sampling)  #> Chain 2 Iteration: 1035 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1036 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1037 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1038 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1039 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1040 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1041 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1042 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1043 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1044 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1045 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1046 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1047 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1048 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1049 / 1500 [ 69%]  (Sampling)  #> Chain 2 Iteration: 1050 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1051 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1052 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1053 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1054 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1055 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1056 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1057 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1058 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1059 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1060 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1061 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1062 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1063 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1064 / 1500 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1065 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1066 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1067 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1068 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1069 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1070 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1071 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1072 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1073 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1074 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1075 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1076 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1077 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1078 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1079 / 1500 [ 71%]  (Sampling)  #> Chain 2 Iteration: 1080 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1081 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1082 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1083 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1084 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1085 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1086 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1087 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1088 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1089 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1090 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1091 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1092 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1093 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1094 / 1500 [ 72%]  (Sampling)  #> Chain 2 Iteration: 1095 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1096 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1097 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1098 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1099 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1100 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1101 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1102 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1103 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1104 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1105 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1106 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1107 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1108 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1109 / 1500 [ 73%]  (Sampling)  #> Chain 2 Iteration: 1110 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1111 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1112 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1113 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1114 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1115 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1116 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1117 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1118 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1119 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1120 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1121 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1122 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1123 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1124 / 1500 [ 74%]  (Sampling)  #> Chain 2 Iteration: 1125 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1126 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1127 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1128 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1129 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1130 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1131 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1132 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1133 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1134 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1135 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1136 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1137 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1138 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1139 / 1500 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1140 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1141 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1142 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1143 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1144 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1145 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1146 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1147 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1148 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1149 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1150 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1151 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1152 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1153 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1154 / 1500 [ 76%]  (Sampling)  #> Chain 2 Iteration: 1155 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1156 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1157 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1158 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1159 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1160 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1161 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1162 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1163 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1164 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1165 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1166 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1167 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1168 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1169 / 1500 [ 77%]  (Sampling)  #> Chain 2 Iteration: 1170 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1171 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1172 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1173 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1174 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1175 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1176 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1177 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1178 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1179 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1180 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1181 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1182 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1183 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1184 / 1500 [ 78%]  (Sampling)  #> Chain 2 Iteration: 1185 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1186 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1187 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1188 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1189 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1190 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1191 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1192 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1193 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1194 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1195 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1196 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1197 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1198 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1199 / 1500 [ 79%]  (Sampling)  #> Chain 2 Iteration: 1200 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1201 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1202 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1203 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1204 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1205 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1206 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1207 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1208 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1209 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1210 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1211 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1212 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1213 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1214 / 1500 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1215 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1216 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1217 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1218 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1219 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1220 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1221 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1222 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1223 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1224 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1225 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1226 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1227 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1228 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1229 / 1500 [ 81%]  (Sampling)  #> Chain 2 Iteration: 1230 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1231 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1232 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1233 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1234 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1235 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1236 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1237 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1238 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1239 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1240 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1241 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1242 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1243 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1244 / 1500 [ 82%]  (Sampling)  #> Chain 2 Iteration: 1245 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1246 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1247 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1248 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1249 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1250 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1251 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1252 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1253 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1254 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1255 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1256 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1257 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1258 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1259 / 1500 [ 83%]  (Sampling)  #> Chain 2 Iteration: 1260 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1261 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1262 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1263 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1264 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1265 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1266 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1267 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1268 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1269 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1270 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1271 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1272 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1273 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1274 / 1500 [ 84%]  (Sampling)  #> Chain 2 Iteration: 1275 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1276 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1277 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1278 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1279 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1280 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1281 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1282 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1283 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1284 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1285 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1286 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1287 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1288 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1289 / 1500 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1290 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1291 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1292 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1293 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1294 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1295 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1296 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1297 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1298 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1299 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1300 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1301 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1302 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1303 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1304 / 1500 [ 86%]  (Sampling)  #> Chain 2 Iteration: 1305 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1306 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1307 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1308 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1309 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1310 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1311 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1312 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1313 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1314 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1315 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1316 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1317 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1318 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1319 / 1500 [ 87%]  (Sampling)  #> Chain 2 Iteration: 1320 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1321 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1322 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1323 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1324 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1325 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1326 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1327 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1328 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1329 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1330 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1331 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1332 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1333 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1334 / 1500 [ 88%]  (Sampling)  #> Chain 2 Iteration: 1335 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1336 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1337 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1338 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1339 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1340 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1341 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1342 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1343 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1344 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1345 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1346 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1347 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1348 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1349 / 1500 [ 89%]  (Sampling)  #> Chain 2 Iteration: 1350 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1351 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1352 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1353 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1354 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1355 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1356 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1357 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1358 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1359 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1360 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1361 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1362 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1363 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1364 / 1500 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1365 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1366 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1367 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1368 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1369 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1370 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1371 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1372 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1373 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1374 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1375 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1376 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1377 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1378 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1379 / 1500 [ 91%]  (Sampling)  #> Chain 2 Iteration: 1380 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1381 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1382 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1383 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1384 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1385 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1386 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1387 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1388 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1389 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1390 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1391 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1392 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1393 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1394 / 1500 [ 92%]  (Sampling)  #> Chain 2 Iteration: 1395 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1396 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1397 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1398 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1399 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1400 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1401 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1402 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1403 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1404 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1405 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1406 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1407 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1408 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1409 / 1500 [ 93%]  (Sampling)  #> Chain 2 Iteration: 1410 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1411 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1412 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1413 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1414 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1415 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1416 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1417 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1418 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1419 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1420 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1421 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1422 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1423 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1424 / 1500 [ 94%]  (Sampling)  #> Chain 2 Iteration: 1425 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1426 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1427 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1428 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1429 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1430 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1431 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1432 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1433 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1434 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1435 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1436 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1437 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1438 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1439 / 1500 [ 95%]  (Sampling)  #> Chain 2 Iteration: 1440 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1441 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1442 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1443 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1444 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1445 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1446 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1447 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1448 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1449 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1450 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1451 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1452 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1453 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1454 / 1500 [ 96%]  (Sampling)  #> Chain 2 Iteration: 1455 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1456 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1457 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1458 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1459 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1460 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1461 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1462 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1463 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1464 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1465 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1466 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1467 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1468 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1469 / 1500 [ 97%]  (Sampling)  #> Chain 2 Iteration: 1470 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1471 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1472 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1473 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1474 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1475 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1476 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1477 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1478 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1479 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1480 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1481 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1482 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1483 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1484 / 1500 [ 98%]  (Sampling)  #> Chain 2 Iteration: 1485 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1486 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1487 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1488 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1489 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1490 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1491 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1492 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1493 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1494 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1495 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1496 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1497 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1498 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1499 / 1500 [ 99%]  (Sampling)  #> Chain 2 Iteration: 1500 / 1500 [100%]  (Sampling)  #> Chain 2 finished in 720.3 seconds. #>  #> Both chains finished successfully. #> Mean chain execution time: 551.3 seconds. #> Total execution time: 720.5 seconds."},{"path":[]},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"plotting-the-nowcast-based-on-real-time-data","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany > Visualising the Nowcast","what":"Plotting the nowcast based on real-time data","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"first plot nowcast based real-time data. Effectively trying use model estimate hospitalisations ultimately reported based data currently available. can compare recent observations see well model . Nowcast hospitalisations Germany based real-time data Internally, plotting function (see ?plot.epinowcast()) sums observed data posterior estimates unobserved data produce nowcast number hospitalisations ultimately reported. instance, model done good job estimating number hospitalisations ultimately reported based data currently available. always case, model can sometimes estimate number hospitalisations ultimately reported. important thing note model clearly perfect complete data less well estimated model. likely indicates misspecification reporting delay model fixed making complex even making entirely non-parametric (vs based LogNormal).","code":"plot(   germany_nowcast, latest_germany_hosp[reference_date > as.Date(\"2021-06-01\")] )"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"plotting-the-nowcast-based-on-retrospective-data","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany > Visualising the Nowcast","what":"Plotting the nowcast based on retrospective data","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"can also plot nowcast based retrospective data. plot uses observed data available effectively plotting observed data 30 day delay (maximum specified) compared data ultimately observed. can used get feel well specified maximum delay . see small number hospitalisations reported 30 days. impact performance even ideal model able predict hospitalisations accounted model evaluation. Nowcast hospitalisations Germany based retrospective data","code":"plot(   retro_germany_nowcast,   latest_germany_hosp[reference_date > as.Date(\"2021-06-01\")] )"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"posterior-predictions-for-cases-by-date-of-postive-test-and-report","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany","what":"Posterior predictions for cases by date of postive test and report","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"better understand fit model data can instead plot posterior predictions observed data. effectively plot instead plotting posterior predictions unobserved data plot posterior predictions observed data. can used get feel well model able predict observed data. Rather using build plot function (changing type = \"posterior_prediction\") instead use enw_plot_pp_quantiles() can control number references dates plot (otherwise plot quite overwhelming!). Posterior predictions hospitalisations Germany based retrospective data clear plot example dates model main able predict observed data well. However, also aspects data model less well able predict, particular apparent periodicity reporting delay. likely due model able account day week reporting periodicity. fixed adding day week random effect reporting delay model demonstrate package README.","code":"plot_select_pp_dates <- function(nowcast, dates) {   nowcast |>     summary(type = \"posterior_prediction\") |>     (\\(x) x[reference_date %in% dates])() |>     enw_plot_pp_quantiles() +     facet_wrap(vars(reference_date), scales = \"free\") } plot_select_pp_dates(   retro_germany_nowcast,   as.Date(c(\"2021-05-01\", \"2021-05-14\", \"2021-06-01\", \"2021-07-01\")) )"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"real-time-and-retrospective-estimates-of-the-effective-reproduction-number","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany","what":"Real-time and retrospective estimates of the effective reproduction number","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"key output model posterior distribution effective reproduction number. can plot real-time retrospective data see estimates change data becomes available. Ideally, hope real-time estimates overlap retrospective estimates. indicate model able accurately estimate hospitalisations ultimately reported based already reported. Real-time retrospective estimates effective reproduction number Germany see good agreement real-time retrospective estimates effective reproduction number dates earlier time expect given data near complete models. Closer date estimation see real-time model good job estimating trend shown retrospective model tendency overpredict. caused changes reporting delay time, model able account day week reporting periodicity, model able account change underlying process time.","code":"get_rt_posterior <- function(nowcast, expectation = expectation_module) {   rt <- enw_posterior(nowcast$fit[[1]], variables = \"r\")   cols <- c(\"mean\", \"median\", \"q5\", \"q20\", \"q80\", \"q95\")   rt[, (cols) := lapply(.SD, exp), .SDcols = cols]   rt <- cbind(     expectation(data = nowcast)$data_raw$r[, .(date)], rt   )   return(rt) }  rt <- rbind(   get_rt_posterior(germany_nowcast)[, Data := \"Real-time\"],   get_rt_posterior(retro_germany_nowcast)[, Data := \"Retrospective\"] )  ggplot(rt) +   aes(x = date, col = Data, fill = Data) +   geom_line(aes(y = median), linewidth = 1, alpha = 0.6) +   geom_line(aes(y = mean), linetype = 2) +   geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2, linewidth = 0.2) +   geom_ribbon(aes(ymin = q20, ymax = q80, col = NULL), alpha = 0.2) +   geom_hline(yintercept = 1, linetype = 2) +   scale_y_continuous(trans = \"log\") +   scale_fill_brewer(palette = \"Dark2\", aesthetics = c(\"color\", \"fill\")) +   theme_bw() +   labs(     x = \"Date of infection\",     y = \"Effective reproduction number\"   ) +   theme(legend.position = \"bottom\")"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"estimates-of-the-delay-from-testing-postive-to-hospitalisation-both-in-real-time-and-retrospectively","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany","what":"Estimates of the delay from testing postive to hospitalisation both in real-time and retrospectively","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"can also plot posterior distribution delay testing positive hospitalisation. delay used estimate number hospitalisations ultimately reported based number positive tests reported. can plot real-time retrospective data see estimates change data becomes available. Ideally, hope real-time estimates overlap retrospective estimates. indicate model able accurately estimate hospitalisations ultimately reported based already reported. Real-time retrospective estimates delay testing positive hospitalisation Germany estimates fairly good match indicating delay well estimated real-time model compared retrospective model delay unlikely changing rapidly time exampel (otherwise expect estimated delays diverge time).","code":"extract_epinowcast_cdf <- function(nowcast) {   draws <- nowcast |>     (\\(x)       x$fit[[1]]$draws(variables = c(\"refp_mean\", \"refp_sd\"), format = \"df\")     )() |>     as.data.table()    draws[     ,     cdf := purrr::map2(       `refp_mean[1]`, `refp_sd[1]`,       ~ data.table(         delay = 1:30, cdf = plnorm(1:30, .x, .y) / plnorm(30, .x, .y)       )     )   ]   draws <- draws[, rbindlist(cdf)]   draws <- draws[,     .(       mean = mean(cdf),       lower_90 = quantile(cdf, probs = 0.05),       upper_90 = quantile(cdf, probs = 0.95)     ),     by = \"delay\"   ] }  nowcast_cdf <- list(   \"Real-time\" = germany_nowcast,   \"Retrospective\" = retro_germany_nowcast ) |>   map(extract_epinowcast_cdf) |>   rbindlist(idcol = \"Data\")  ggplot(nowcast_cdf) +   aes(x = delay, y = mean, col = Data, fill = Data) +   geom_line(size = 1.1, alpha = 0.7) +   geom_ribbon(     aes(ymin = lower_90, ymax = upper_90),     alpha = 0.25   ) +   theme_bw() +   theme(legend.position = \"bottom\") +   scale_fill_brewer(palette = \"Dark2\", aesthetics = c(\"color\", \"fill\")) +   guides(     fill = guide_legend(nrow = 1),     col = guide_legend(nrow = 1)   ) +   labs(     x = \"Delay between positive test and hospitalisation\",     y = \"Cumulative density function of the reporting distribution\"   )"},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"estimates-of-the-number-of-expected-hospitalisations-both-in-real-time-and-retrospectively","dir":"Articles","previous_headings":"Fitting the model to COVID-19 hospitalisations in Germany","what":"Estimates of the number of expected hospitalisations both in real-time and retrospectively","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"can also plot posterior predictions number expected hospitalisations. number hospitalisations reported observation error. can compare number hospitalisations ultimately reported see well model . Retrospectively, expect model fit well data differences due observation error. case indicates may neeed revisit expected hospitalisation model specification make closer generative process data . real-time, expect model fit less well data trying estimate number hospitalisations ultimately reported based data currently available (.e. also account reporting delay now partiall unobserved). Real-time retrospective estimates number expected hospitalisations Germany expected retrospective estimates fit well data. real-time estimates slightly less good, still capture recent change trend data possible without nowcast (estimates biased towards underpredicting due delay reporting leading right truncation).","code":"get_expected_infections <- function(nowcast, expectation = expectation_module) {   exp_cases <- enw_posterior(     nowcast$fit[[1]],     variables = \"exp_lobs\"   )   cols <- c(\"mean\", \"median\", \"q5\", \"q20\", \"q80\", \"q95\")   exp_cases[, (cols) := lapply(.SD, exp), .SDcols = cols]   exp_cases <- cbind(     expectation(data = nowcast)$data_raw$observation,     exp_cases   )   return(exp_cases) }  exp_cases <- rbind(   get_expected_infections(germany_nowcast)[, Data := \"Real-time\"],   get_expected_infections(retro_germany_nowcast)[, Data := \"Retrospective\"] )  exp_cases <- enw_latest_data(germany_hosp)[, date := reference_date][   exp_cases,   on = \"date\" ]  ggplot(exp_cases) +   aes(x = date, fill = Data, col = Data) +   geom_point(aes(y = confirm), col = \"Black\") +   geom_line(aes(y = median), linewidth = 1, alpha = 0.6) +   geom_line(aes(y = mean), linetype = 2) +   geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2, linewidth = 0.2) +   geom_ribbon(aes(ymin = q20, ymax = q80, col = NULL), alpha = 0.2) +   theme_bw() +   labs(     x = \"Date of positive test\",     y = \"Expected hospitalisations\"   ) +   scale_fill_brewer(palette = \"Dark2\", aesthetics = c(\"color\", \"fill\")) +   theme(legend.position = \"bottom\")"},{"path":[]},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"summary","dir":"Articles","previous_headings":"Wrapping up","what":"Summary","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"case study shown use epinowcast estimate effective reproduction number expected number latent reported cases right truncated data. also shown use package perform retrospective real-time nowcasts can useful way understanding real-time performance model.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"strengths","dir":"Articles","previous_headings":"Wrapping up","what":"Strengths","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"used single model estimate effective reproduction number expected number latent reported cases right truncated data. means propogated uncertainty estimation effective reproduction number estimation expected number latent reported cases difficult using mulit-stage approach. used flexible model effective reproduction number allows us estimate effective reproduction number time incorporate uncertainty estimation effective reproduction number estimation expected number latent reported cases. accounted delay infection hospitalisation delay hospitalisation reporting estimation expected number reported cases. means reproduction number estimates currently indexed date infection.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"limitations","dir":"Articles","previous_headings":"Wrapping up","what":"Limitations","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"Assumed known static generation time distribution latent reporting delay distribution. reality need estimated data, uncertainty, liable change time. Used fixed parametric reporting delay distribution. reality likely vary time depend things like day week reporting effects. addressed using flexible reporting delay distribution supported epinowcast. Used observation model account overdispersion number reported cases. addressed using flexible observation model supported epinowcast.","code":""},{"path":"package.epinowcast.org/dev/articles/single-timeseries-rt-estimation.html","id":"alternative-packages","dir":"Articles","previous_headings":"Wrapping up","what":"Alternative packages","title":"Estimating the effective reproduction number in real-time for a single timeseries with reporting delays","text":"EpiNow2: precursor epinowcast developed members epinowcast community. flexible toolset real-time analysis infectious diseases. less complex epinowcast focus robust default settings also less flexible. time functionality incorporated epinowcast. epidemia: another flexible package estimating effective reproduction number forecasting. designed flexible EpiNow2, similar way epinowcast, potentially difficult use. also generally less functionality dealing delays epinowcast. However, extension rstanarm comes number useful features famliar interface users rstanarm EpiEstim: mature package estimating effective reproduction number. exploits mathematically relationship fit renewal equation uncertainty quickly currently able handle reporting delays aspects real-world data discussed case study. also able perform nowcasts. However, useful package estimating effective reproduction number settings aspects important can handled means.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Sam Abbott. Author, maintainer. Adrian Lison. Author. Sebastian Funk. Author. Carl Pearson. Author. Hugo Gruson. Author. Felix Guenther. Author. Michael DeWitt. Contributor. Hannah Choi. Contributor. Pratik Gupte. Contributor. Joel Hellewell. Contributor. Luis Rivas. Contributor. Sang Woo Park. Contributor.","code":""},{"path":"package.epinowcast.org/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Abbott S, Lison , Funk S, Pearson C, Gruson H, Guenther F (2021). “epinowcast: Flexible hierarchical nowcasting.” Zenodo. doi:10.5281/zenodo.5637165, https://github.com/epinowcast/epinowcast.","code":"@Article{,   title = {epinowcast: Flexible hierarchical nowcasting},   author = {Sam Abbott and Adrian Lison and Sebastian Funk and Carl Pearson and Hugo Gruson and Felix Guenther},   year = {2021},   journal = {Zenodo},   doi = {10.5281/zenodo.5637165},   url = {https://github.com/epinowcast/epinowcast}, }"},{"path":"package.epinowcast.org/dev/index.html","id":"flexible-hierarchical-nowcasting-","dir":"","previous_headings":"","what":"Flexible Hierarchical Nowcasting","title":"Flexible Hierarchical Nowcasting","text":"Tools enable flexible efficient hierarchical nowcasting right-truncated epidemiological time-series using semi-mechanistic Bayesian model support range reporting generative processes. Nowcasting, context, gaining situational awareness using currently available observations reporting patterns historical observations. can useful tracking spread infectious disease real-time: without nowcasting, changes trends can obfuscated partial reporting detection may delayed due use simpler methods like truncation. package designed epidemiological applications mind, applied set right-truncated time-series count data.","code":""},{"path":"package.epinowcast.org/dev/index.html","id":"getting-started-and-learning-more","dir":"","previous_headings":"","what":"Getting started and learning more","title":"Flexible Hierarchical Nowcasting","text":"README good place get started epinowcast, particular following installation quick start sections. make use package, problem requires richer feature set presented , also provide range documentation, case studies, spaces community interact . short list current resources. Package website: includes function reference, model outline, case studies making use package. site refers release version package can installed Universe latest GitHub release (see installation instructions). development version documentation (corresponding main branch GitHub) available . Organisation website: includes links resources well guest posts community members schedules related seminars run community members. Directory example scripts: fleshed complete case studies scripts used package development showcase subset package functionality. Often newly introduced features explored surfacing areas documentation. Community forum: community forum development methods tools discussed, along related research members discussions users. interested real-time analysis infectious disease likely good place start regardless end making use epinowcast.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/index.html","id":"installing-the-package","dir":"","previous_headings":"Installation","what":"Installing the package","title":"Flexible Hierarchical Nowcasting","text":"Install latest released version package : Alternatively, install development version (whilst strive limit breaking changes introduction bugs development version may contain ) GitHub using following, Historical package releases can installed GitHub using remotes adding release tag following example (installs 0.2.0), Note: similar method can used install particular commit package may useful users unable use fixed release concerned stability dependencies.","code":"install.packages(\"epinowcast\", repos = \"https://epinowcast.r-universe.dev\") remotes::install_github(\"epinowcast/epinowcast\", dependencies = TRUE) remotes::install_github(\"epinowcast/epinowcast\", dependencies = TRUE, ref = \"v0.2.0\")"},{"path":"package.epinowcast.org/dev/index.html","id":"installing-cmdstan","dir":"","previous_headings":"Installation","what":"Installing CmdStan","title":"Flexible Hierarchical Nowcasting","text":"don’t already CmdStan installed , addition installing epinowcast, also necessary install CmdStan using cmdstanr’s install_cmdstan() function enable model fitting epinowcast. suitable C++ toolchain also required. Instructions provided Getting started cmdstanr vignette. See cmdstanr documentation details support. Note: install process can sped using cores argument past versions can installed using version argument (may useful install historical package releases).","code":"cmdstanr::install_cmdstan()"},{"path":"package.epinowcast.org/dev/index.html","id":"docker","dir":"","previous_headings":"Installation","what":"Docker","title":"Flexible Hierarchical Nowcasting","text":"alternative local installation provide Docker image epinowcast dependencies installed. can used run epinowcast without installing dependencies locally. image available .","code":""},{"path":"package.epinowcast.org/dev/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Flexible Hierarchical Nowcasting","text":"quick start, use example COVID-19 hospitalisations Germany demonstrate specification fitting simple nowcasting model using epinowcast. Examples using complex models available package vignettes papers referenced literature vignette.","code":""},{"path":"package.epinowcast.org/dev/index.html","id":"package","dir":"","previous_headings":"Quick start","what":"Package","title":"Flexible Hierarchical Nowcasting","text":"addition epinowcast, quick start makes use data.table ggplot2, installed epinowcast installed.","code":"library(epinowcast) library(data.table) library(ggplot2)"},{"path":"package.epinowcast.org/dev/index.html","id":"data","dir":"","previous_headings":"Quick start","what":"Data","title":"Flexible Hierarchical Nowcasting","text":"Nowcasting right-truncated case counts involves estimation reporting delays recently reported data. , need count cases occurred (often called “reference date”) reported (often called “report date”). , difference reference date report date reporting delay. quick start, use data sourced Robert Koch Institute via Germany Nowcasting hub. data represent hospitalisation counts date positive test date test report Germany October 1, 2021. first filter snapshot retrospective data available 40 days October 1, 2021 contains 40 days data. , create nowcast target latest available hospitalisations date positive test. allow us visualise nowcast made time compares ultimately reported. data already format can used epinowcast, contains reference date (column reference_date): date observation, example date positive test report date (column report_date): date report given set observations reference date count (column confirm): total (.e. cumulative) number hospitalisations reference date report date. package also provides range tools convert data line list, incidence, common formats required format (see Data converters).","code":"nat_germany_hosp <-   germany_covid19_hosp[location == \"DE\"][age_group %in% \"00+\"] |>   enw_filter_report_dates(latest_date = \"2021-10-01\")  retro_nat_germany <- nat_germany_hosp |>   enw_filter_report_dates(remove_days = 40) |>   enw_filter_reference_dates(include_days = 40) retro_nat_germany #>      reference_date location age_group confirm report_date #>   1:     2021-07-13       DE       00+      21  2021-07-13 #>   2:     2021-07-14       DE       00+      22  2021-07-14 #>   3:     2021-07-15       DE       00+      28  2021-07-15 #>   4:     2021-07-16       DE       00+      19  2021-07-16 #>   5:     2021-07-17       DE       00+      20  2021-07-17 #>  ---                                                       #> 857:     2021-07-14       DE       00+      72  2021-08-21 #> 858:     2021-07-15       DE       00+      69  2021-08-22 #> 859:     2021-07-13       DE       00+      59  2021-08-21 #> 860:     2021-07-14       DE       00+      72  2021-08-22 #> 861:     2021-07-13       DE       00+      59  2021-08-22 latest_germany_hosp <- nat_germany_hosp |>   enw_latest_data() |>   enw_filter_reference_dates(remove_days = 40, include_days = 40) head(latest_germany_hosp, n = 10) #>     reference_date location age_group confirm report_date #>  1:     2021-07-13       DE       00+      60  2021-10-01 #>  2:     2021-07-14       DE       00+      74  2021-10-01 #>  3:     2021-07-15       DE       00+      69  2021-10-01 #>  4:     2021-07-16       DE       00+      49  2021-10-01 #>  5:     2021-07-17       DE       00+      67  2021-10-01 #>  6:     2021-07-18       DE       00+      51  2021-10-01 #>  7:     2021-07-19       DE       00+      36  2021-10-01 #>  8:     2021-07-20       DE       00+      96  2021-10-01 #>  9:     2021-07-21       DE       00+      94  2021-10-01 #> 10:     2021-07-22       DE       00+      99  2021-10-01"},{"path":"package.epinowcast.org/dev/index.html","id":"data-preprocessing","dir":"","previous_headings":"Quick start","what":"Data preprocessing","title":"Flexible Hierarchical Nowcasting","text":"modelling, input data needs converted “reporting triangle” format (see model description details). also need determine metadata facilitate model specification. includes number days data use reference report modules, maximum delay consider, , optionally, grouping (.e. age group, location, ) observations. process reported data format required epinowcast return data.table. stage, need specify grouping (.e age, location) . returned output form data.table metadata stored variables. can useful check output specifying model, just make sure everything expected.","code":"pobs <- enw_preprocess_data(retro_nat_germany, max_delay = 40) pobs #>                    obs          new_confirm              latest #> 1: <data.table[860x9]> <data.table[860x11]> <data.table[41x10]> #>    missing_reference  reporting_triangle      metareference          metareport #> 1: <data.table[0x6]> <data.table[41x42]> <data.table[41x9]> <data.table[80x12]> #>             metadelay time snapshots by groups max_delay   max_date timestep #> 1: <data.table[40x4]>   41        41         1        40 2021-08-22      day"},{"path":"package.epinowcast.org/dev/index.html","id":"model-specification","dir":"","previous_headings":"Quick start","what":"Model specification","title":"Flexible Hierarchical Nowcasting","text":"epinowcast package designed provide users flexible customizable modelling framework. package comes equipped several modules users can utilize construct models, also allows users create modules. ensures models can tailored user’s specific data context.","code":""},{"path":"package.epinowcast.org/dev/index.html","id":"default-nowcasting-model","dir":"","previous_headings":"Quick start > Model specification","what":"Default nowcasting model","title":"Flexible Hierarchical Nowcasting","text":"default nowcasting model epinowcast consists three modules: process (expectation) module models expected counts date reference (reference_date) parametric reference reporting model models reporting delay distribution date reference non-parametric reporting model models differences reporting delay distribution date report (report_date), example, day---week effects reporting delay. following sections, specify simple models modules. appropriateness specifications vary depending context. See vignettes details model specification examples complex models.","code":""},{"path":"package.epinowcast.org/dev/index.html","id":"process-model","dir":"","previous_headings":"Quick start > Model specification","what":"Process model","title":"Flexible Hierarchical Nowcasting","text":"commonly used process model nowcasting model expected counts date reference via geometric random walk acts minimally informed smoothing prior thus gives lot weight observed data. default process model epinowcast. Users may also specify model using enw_expectation() function. , day refers number days start data. underlying process model exponential growth rate model (Ct = Ct − 1exprt), specifying random effect (.e. (1 | day)) growth rate equivalent geometric random walk expected counts reference date. defining random effect ,","code":"expectation_module <- enw_expectation(   ~ 0 + (1 | day), data = pobs )"},{"path":"package.epinowcast.org/dev/index.html","id":"reporting-model-by-reference-date","dir":"","previous_headings":"Quick start > Model specification","what":"Reporting model by reference date","title":"Flexible Hierarchical Nowcasting","text":"baseline assumption reporting delay log-normally distributed, static time strata. can specify model using enw_reference() function, Note default distribution log-normal, hence distribution argument omitted .","code":"reference_module <- enw_reference(~1, distribution = \"lognormal\", data = pobs)"},{"path":"package.epinowcast.org/dev/index.html","id":"reporting-effects-by-report-date","dir":"","previous_headings":"Quick start > Model specification","what":"Reporting effects by report date","title":"Flexible Hierarchical Nowcasting","text":"Even evidence reporting processes can approximated single distribution, may additional reporting effects captured reference model. example, reporting may lower weekends holidays. can specify model effects using hazard formulation (captures conditional relationship different reporting delays, see model description details) using enw_report() function. specify model random effect day week capture weekly seasonality reporting delay.","code":"report_module <- enw_report(~ (1 | day_of_week), data = pobs)"},{"path":"package.epinowcast.org/dev/index.html","id":"precompiling-the-model","dir":"","previous_headings":"Quick start","what":"Precompiling the model","title":"Flexible Hierarchical Nowcasting","text":"epinowcast uses cmdstan fit models, necessary first compile model. can done using enw_model() function. Note step can left epinowcast, want use multiple cores per chain speed model fitting therefore compile model feature turned .","code":"model <- enw_model(threads = TRUE)"},{"path":"package.epinowcast.org/dev/index.html","id":"bringing-it-all-together-fitting-the-model","dir":"","previous_headings":"Quick start","what":"Bringing it all together: Fitting the model","title":"Flexible Hierarchical Nowcasting","text":"can now fit model using “-U-Turn Sampler Markov chain Monte Carlo” method. type Hamiltonian Monte Carlo (HMC) algorithm core fitting method used cmdstan. NUTS MCMC method efficient, automatically tunes parameters robust correlations parameters, making fast effective generating samples posterior distribution. specify fitting options using enw_fit_opts() (note settings shown tuned speed may appropriate many real world use cases). also pass preprocessed data (pobs), pre-compiled model (model), model modules (expectation_module, reference_module, report_module) epinowcast, combined used fit model.","code":"options(mc.cores = 2) nowcast <- epinowcast(data = pobs,   expectation = expectation_module,   reference = reference_module,   report = report_module,   fit = enw_fit_opts(     save_warmup = FALSE, pp = TRUE,     chains = 2, threads_per_chain = 2,     iter_sampling = 500, iter_warmup = 500,     show_messages = FALSE   ),   model = model )"},{"path":"package.epinowcast.org/dev/index.html","id":"the-epinowcast-object","dir":"","previous_headings":"Quick start","what":"The epinowcast object","title":"Flexible Hierarchical Nowcasting","text":"epinowcast() function returns epinowcast object includes diagnostic information, data used fitting, underlying CmdStanModel object.","code":"nowcast #>                    obs          new_confirm              latest #> 1: <data.table[860x9]> <data.table[860x11]> <data.table[41x10]> #>    missing_reference  reporting_triangle      metareference          metareport #> 1: <data.table[0x6]> <data.table[41x42]> <data.table[41x9]> <data.table[80x12]> #>             metadelay time snapshots by groups max_delay   max_date timestep #> 1: <data.table[40x4]>   41        41         1        40 2021-08-22      day #>                  fit       data  fit_args samples max_rhat #> 1: <CmdStanMCMC[42]> <list[99]> <list[7]>    1000     1.01 #>    divergent_transitions per_divergent_transitions max_treedepth #> 1:                     0                         0             8 #>    no_at_max_treedepth per_at_max_treedepth run_time #> 1:                 212                0.212     77.1"},{"path":"package.epinowcast.org/dev/index.html","id":"summarising-and-plotting-the-nowcast","dir":"","previous_headings":"Quick start","what":"Summarising and plotting the nowcast","title":"Flexible Hierarchical Nowcasting","text":"nowcast (combination currently observed predicted unobserved data) can summarised using Similarly, summarised nowcast can plotted latest observed data using","code":"nowcast |>   summary(probs = c(0.05, 0.95)) |>   head(n = 10) #>     reference_date report_date .group max_confirm location age_group confirm #>  1:     2021-07-14  2021-08-22      1          72       DE       00+      72 #>  2:     2021-07-15  2021-08-22      1          69       DE       00+      69 #>  3:     2021-07-16  2021-08-22      1          47       DE       00+      47 #>  4:     2021-07-17  2021-08-22      1          65       DE       00+      65 #>  5:     2021-07-18  2021-08-22      1          50       DE       00+      50 #>  6:     2021-07-19  2021-08-22      1          36       DE       00+      36 #>  7:     2021-07-20  2021-08-22      1          94       DE       00+      94 #>  8:     2021-07-21  2021-08-22      1          91       DE       00+      91 #>  9:     2021-07-22  2021-08-22      1          99       DE       00+      99 #> 10:     2021-07-23  2021-08-22      1          86       DE       00+      86 #>     cum_prop_reported delay prop_reported    mean median        sd    mad q5 #>  1:                 1    39             0  72.000     72 0.0000000 0.0000 72 #>  2:                 1    38             0  69.036     69 0.1916787 0.0000 69 #>  3:                 1    37             0  47.074     47 0.2694376 0.0000 47 #>  4:                 1    36             0  65.204     65 0.4739289 0.0000 65 #>  5:                 1    35             0  50.286     50 0.5371150 0.0000 50 #>  6:                 1    34             0  36.216     36 0.4955700 0.0000 36 #>  7:                 1    33             0  94.531     94 0.7221915 0.0000 94 #>  8:                 1    32             0  91.802     92 0.9206756 1.4826 91 #>  9:                 1    31             0 100.127    100 1.0936485 1.4826 99 #> 10:                 1    30             0  87.314     87 1.1801681 1.4826 86 #>     q95      rhat  ess_bulk  ess_tail #>  1:  72        NA        NA        NA #>  2:  69 0.9997723 1085.1287 1085.9625 #>  3:  48 1.0046094 1005.4825  997.1800 #>  4:  66 0.9985918  997.9345  949.9590 #>  5:  51 1.0011434 1008.8150  948.5230 #>  6:  37 0.9998773 1063.0420 1060.1157 #>  7:  96 0.9985993 1048.9064  947.8989 #>  8:  94 1.0024911  909.2898 1029.5347 #>  9: 102 0.9994335  936.8367  815.5520 #> 10:  90 1.0013150  854.4371 1004.8509 plot(nowcast, latest_obs = latest_germany_hosp)"},{"path":"package.epinowcast.org/dev/index.html","id":"plotting-posterior-predictions","dir":"","previous_headings":"Quick start","what":"Plotting posterior predictions","title":"Flexible Hierarchical Nowcasting","text":"Plotting posterior predictions can useful way assessing performance checking model capturing underlying data generation process adequately. can directly output epinowcast() using","code":"plot(nowcast, type = \"posterior\") +   facet_wrap(vars(reference_date), scale = \"free\")"},{"path":"package.epinowcast.org/dev/index.html","id":"using-package-functions-rather-than-s3-methods","dir":"","previous_headings":"Quick start","what":"Using package functions rather than S3 methods","title":"Flexible Hierarchical Nowcasting","text":"Rather using S3 methods supplied epinowcast() directly, package functions can also used extract nowcast posterior samples, summarise , plot . demonstrated plotting 7 day incidence hospitalisations.  see model underestimating incidence hospitalisations ultimately reported. range potential reasons , first process model fully capture trend day week periodicity present data. See case study vignettes ideas deal issues.","code":"# extract samples samples <- summary(nowcast, type = \"nowcast_samples\")  # Take a 7 day rolling sum of both samples and observations cols <- c(\"confirm\", \"sample\") samples[, (cols) := lapply(.SD, frollsum, n = 7),   .SDcols = cols, by = \".draw\" ][!is.na(sample)] #>        reference_date report_date .group max_confirm location age_group confirm #>     1:     2021-07-20  2021-08-22      1          94       DE       00+     433 #>     2:     2021-07-20  2021-08-22      1          94       DE       00+     433 #>     3:     2021-07-20  2021-08-22      1          94       DE       00+     433 #>     4:     2021-07-20  2021-08-22      1          94       DE       00+     433 #>     5:     2021-07-20  2021-08-22      1          94       DE       00+     433 #>    ---                                                                          #> 33996:     2021-08-22  2021-08-22      1          45       DE       00+    1093 #> 33997:     2021-08-22  2021-08-22      1          45       DE       00+    1093 #> 33998:     2021-08-22  2021-08-22      1          45       DE       00+    1093 #> 33999:     2021-08-22  2021-08-22      1          45       DE       00+    1093 #> 34000:     2021-08-22  2021-08-22      1          45       DE       00+    1093 #>        cum_prop_reported delay prop_reported .chain .iteration .draw sample #>     1:                 1    33             0      1          1     1    434 #>     2:                 1    33             0      1          2     2    436 #>     3:                 1    33             0      1          3     3    433 #>     4:                 1    33             0      1          4     4    433 #>     5:                 1    33             0      1          5     5    434 #>    ---                                                                      #> 33996:                 1     0             1      2        496   996   1973 #> 33997:                 1     0             1      2        497   997   2211 #> 33998:                 1     0             1      2        498   998   1985 #> 33999:                 1     0             1      2        499   999   2246 #> 34000:                 1     0             1      2        500  1000   1895 latest_germany_hosp_7day <- copy(latest_germany_hosp)[   ,   confirm := frollsum(confirm, n = 7) ][!is.na(confirm)]  # Summarise samples sum_across_last_7_days <- enw_summarise_samples(samples)  # Plot samples enw_plot_nowcast_quantiles(sum_across_last_7_days, latest_germany_hosp_7day)"},{"path":"package.epinowcast.org/dev/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Flexible Hierarchical Nowcasting","text":"use epinowcast work, please consider citing using following, cite package ‘epinowcast’ publications use: Abbott S, Lison , Funk S, Pearson C, Gruson H, Guenther F (2021). “epinowcast: Flexible hierarchical nowcasting.” Zenodo. doi:10.5281/zenodo.5637165 https://doi.org/10.5281/zenodo.5637165, https://github.com/epinowcast/epinowcast. BibTeX entry LaTeX users @Article{, title = {epinowcast: Flexible hierarchical nowcasting}, author = {Sam Abbott Adrian Lison Sebastian Funk Carl Pearson Hugo Gruson Felix Guenther}, year = {2021}, journal = {Zenodo}, doi = {10.5281/zenodo.5637165}, url = {https://github.com/epinowcast/epinowcast}, } making use methodology methodology based, please cite relevant papers model outline.","code":"citation(\"epinowcast\")"},{"path":"package.epinowcast.org/dev/index.html","id":"how-to-make-a-bug-report-or-feature-request","dir":"","previous_headings":"","what":"How to make a bug report or feature request","title":"Flexible Hierarchical Nowcasting","text":"Please briefly describe problem output expect issue. question, please don’t open issue. Instead, ask Q page. See contributing guide information.","code":""},{"path":"package.epinowcast.org/dev/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Flexible Hierarchical Nowcasting","text":"welcome contributions new contributors! particularly appreciate help priority problems issues. Please check add issues, /add pull request. See contributing guide information. interested expanding functionality underlying model note epinowcast allows users pass models meaning alternative parameterisations, example altering forecast model used inferring expected observations, may easily tested within package infrastructure. testing done alterations increase flexibility package model improves defaults welcome via pull request communication package authors. Even wanting add updated model package please reach love hear use case.","code":""},{"path":"package.epinowcast.org/dev/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Flexible Hierarchical Nowcasting","text":"Please note epinowcast project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"package.epinowcast.org/dev/reference/add_pmfs.html","id":null,"dir":"Reference","previous_headings":"","what":"Add probability mass functions — add_pmfs","title":"Add probability mass functions — add_pmfs","text":"function allows addition probability mass functions (PMFs) produce new PMF. useful example context reporting delays PMF sum two Poisson distributions convolution PMFs.","code":""},{"path":"package.epinowcast.org/dev/reference/add_pmfs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add probability mass functions — add_pmfs","text":"","code":"add_pmfs(pmfs)"},{"path":"package.epinowcast.org/dev/reference/add_pmfs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add probability mass functions — add_pmfs","text":"pmfs list vectors describing probability mass functions ","code":""},{"path":"package.epinowcast.org/dev/reference/add_pmfs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add probability mass functions — add_pmfs","text":"vector describing probability mass function sum ","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/add_pmfs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add probability mass functions — add_pmfs","text":"","code":"# Sample and analytical PMFs for two Poisson distributions x <- rpois(10000, 5) xpmf <- dpois(0:20, 5) y <- rpois(10000, 7) ypmf <- dpois(0:20, 7) # Add sampled Poisson distributions up to get combined distribution z <- x + y # Analytical convolution of PMFs conv_pmf <- add_pmfs(list(xpmf, ypmf)) conv_cdf <- cumsum(conv_pmf) # Empirical convolution of PMFs cdf <- ecdf(z)(0:42) # Compare sampled and analytical CDFs plot(conv_cdf) lines(cdf, col = \"black\")"},{"path":"package.epinowcast.org/dev/reference/aggregate_rolling_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to perform rolling sum aggregation — aggregate_rolling_sum","title":"Internal function to perform rolling sum aggregation — aggregate_rolling_sum","text":"function takes data.table applies rolling sum given timestep, aggregating specified columns. particularly useful aggregating observations certain periods.","code":""},{"path":"package.epinowcast.org/dev/reference/aggregate_rolling_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to perform rolling sum aggregation — aggregate_rolling_sum","text":"","code":"aggregate_rolling_sum(dt, internal_timestep, by = NULL)"},{"path":"package.epinowcast.org/dev/reference/aggregate_rolling_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to perform rolling sum aggregation — aggregate_rolling_sum","text":"dt data.table aggregated. internal_timestep integer indicating period aggregate. character vector specifying columns aggregate .","code":""},{"path":"package.epinowcast.org/dev/reference/aggregate_rolling_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to perform rolling sum aggregation — aggregate_rolling_sum","text":"modified data.table aggregated observations.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/as_string_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts formulas to strings — as_string_formula","title":"Converts formulas to strings — as_string_formula","text":"Converts formulas strings","code":""},{"path":"package.epinowcast.org/dev/reference/as_string_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts formulas to strings — as_string_formula","text":"","code":"as_string_formula(formula)"},{"path":"package.epinowcast.org/dev/reference/as_string_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts formulas to strings — as_string_formula","text":"formula model formula may use standard fixed effects, random effects using lme4 syntax (see re()), random walks defined using rw() helper function.","code":""},{"path":"package.epinowcast.org/dev/reference/as_string_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts formulas to strings — as_string_formula","text":"character string supplied formula","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/as_string_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts formulas to strings — as_string_formula","text":"","code":"epinowcast:::as_string_formula(~ 1 + age_group) #> [1] \"~1 + age_group\""},{"path":"package.epinowcast.org/dev/reference/check_calendar_timestep.html","id":null,"dir":"Reference","previous_headings":"","what":"Check calendar timestep — check_calendar_timestep","title":"Check calendar timestep — check_calendar_timestep","text":"function verifies difference calendar dates provided observations corresponds provided timestep \"month\".","code":""},{"path":"package.epinowcast.org/dev/reference/check_calendar_timestep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check calendar timestep — check_calendar_timestep","text":"","code":"check_calendar_timestep(dates, date_var, exact = TRUE)"},{"path":"package.epinowcast.org/dev/reference/check_calendar_timestep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check calendar timestep — check_calendar_timestep","text":"dates Vector Date class representing dates. date_var variable obs representing dates. exact Logical, TRUE``, checks differences exactly match timestep. FALSE``, checks sum differences modulo timestep equals zero. Default TRUE.","code":""},{"path":"package.epinowcast.org/dev/reference/check_calendar_timestep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check calendar timestep — check_calendar_timestep","text":"function used side effect stopping check fails. check passes, function returns invisibly.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Check observations for reserved grouping variables — check_group","title":"Check observations for reserved grouping variables — check_group","text":"Check observations reserved grouping variables","code":""},{"path":"package.epinowcast.org/dev/reference/check_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check observations for reserved grouping variables — check_group","text":"","code":"check_group(obs)"},{"path":"package.epinowcast.org/dev/reference/check_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check observations for reserved grouping variables — check_group","text":"obs object coerce_dtd place, contain .group, .old_group, .new_group. reserved names.","code":""},{"path":"package.epinowcast.org/dev/reference/check_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check observations for reserved grouping variables — check_group","text":"obs object, modifiable place.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_group_date_unique.html","id":null,"dir":"Reference","previous_headings":"","what":"Check observations for uniqueness of grouping variables with respect to reference_date and report_date — check_group_date_unique","title":"Check observations for uniqueness of grouping variables with respect to reference_date and report_date — check_group_date_unique","text":"function checks input data stratified reference_date, report_date, .group. counting number observations combination variables, throwing warning combination one observation.","code":""},{"path":"package.epinowcast.org/dev/reference/check_group_date_unique.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check observations for uniqueness of grouping variables with respect to reference_date and report_date — check_group_date_unique","text":"","code":"check_group_date_unique(obs)"},{"path":"package.epinowcast.org/dev/reference/check_group_date_unique.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check observations for uniqueness of grouping variables with respect to reference_date and report_date — check_group_date_unique","text":"obs object coerce_dtd place, contains .group, reference_date, report_date columns.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_module.html","id":null,"dir":"Reference","previous_headings":"","what":"Check a model module contains the required components — check_module","title":"Check a model module contains the required components — check_module","text":"Check model module contains required components","code":""},{"path":"package.epinowcast.org/dev/reference/check_module.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check a model module contains the required components — check_module","text":"","code":"check_module(module)"},{"path":"package.epinowcast.org/dev/reference/check_module.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check a model module contains the required components — check_module","text":"module model module. example enw_expectation().","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_modules_compatible.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that model modules have compatible specifications — check_modules_compatible","title":"Check that model modules have compatible specifications — check_modules_compatible","text":"Check model modules compatible specifications","code":""},{"path":"package.epinowcast.org/dev/reference/check_modules_compatible.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that model modules have compatible specifications — check_modules_compatible","text":"","code":"check_modules_compatible(modules)"},{"path":"package.epinowcast.org/dev/reference/check_modules_compatible.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that model modules have compatible specifications — check_modules_compatible","text":"modules list model modules.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_numeric_timestep.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Numeric Timestep — check_numeric_timestep","title":"Check Numeric Timestep — check_numeric_timestep","text":"function verifies difference numeric dates provided observations corresponds provided timestep.","code":""},{"path":"package.epinowcast.org/dev/reference/check_numeric_timestep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Numeric Timestep — check_numeric_timestep","text":"","code":"check_numeric_timestep(dates, date_var, timestep, exact = TRUE)"},{"path":"package.epinowcast.org/dev/reference/check_numeric_timestep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Numeric Timestep — check_numeric_timestep","text":"dates Vector Date class representing dates. date_var variable obs representing dates. timestep Numeric timestep date difference. exact Logical, TRUE``, checks differences exactly match timestep. FALSE``, checks sum differences modulo timestep equals zero. Default TRUE.","code":""},{"path":"package.epinowcast.org/dev/reference/check_numeric_timestep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Numeric Timestep — check_numeric_timestep","text":"function used side effect stopping check fails. check passes, function returns invisibly.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Check required quantiles are present — check_quantiles","title":"Check required quantiles are present — check_quantiles","text":"Check required quantiles present","code":""},{"path":"package.epinowcast.org/dev/reference/check_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check required quantiles are present — check_quantiles","text":"","code":"check_quantiles(posterior, req_probs = c(0.5, 0.95, 0.2, 0.8))"},{"path":"package.epinowcast.org/dev/reference/check_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check required quantiles are present — check_quantiles","text":"posterior data.table coerce_dt()d place; must contain quantiles identified using q5 naming scheme. req_probs numeric vector required probabilities. Default: c(0.5, 0.95, 0.2, 0.8).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_timestep.html","id":null,"dir":"Reference","previous_headings":"","what":"Check timestep — check_timestep","title":"Check timestep — check_timestep","text":"function verifies difference dates provided observations corresponds provided timestep. exact argument set TRUE, function checks differences exactly match timestep; otherwise, checks sum differences modulo timestep equals zero. check fails, function stops returns error message.","code":""},{"path":"package.epinowcast.org/dev/reference/check_timestep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check timestep — check_timestep","text":"","code":"check_timestep(   obs,   date_var,   timestep = \"day\",   exact = TRUE,   check_nrow = TRUE )"},{"path":"package.epinowcast.org/dev/reference/check_timestep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check timestep — check_timestep","text":"obs types supported data.table::.data.table(). date_var variable obs representing dates. timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days. exact Logical, TRUE``, checks differences exactly match timestep. FALSE``, checks sum differences modulo timestep equals zero. Default TRUE. check_nrow Logical, TRUE, checks least two observations. Default TRUE. FALSE, function returns invisibly one observation.","code":""},{"path":"package.epinowcast.org/dev/reference/check_timestep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check timestep — check_timestep","text":"function used side effect stopping check fails. check passes, function returns invisibly.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_timestep_by_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Check timestep by date — check_timestep_by_date","title":"Check timestep by date — check_timestep_by_date","text":"function verifies difference dates within date provided observations corresponds provided timestep. check performed report_date reference_date group obs.","code":""},{"path":"package.epinowcast.org/dev/reference/check_timestep_by_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check timestep by date — check_timestep_by_date","text":"","code":"check_timestep_by_date(obs, timestep = \"day\", exact = TRUE)"},{"path":"package.epinowcast.org/dev/reference/check_timestep_by_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check timestep by date — check_timestep_by_date","text":"obs types supported data.table::.data.table(). timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days. exact Logical, TRUE``, checks differences exactly match timestep. FALSE``, checks sum differences modulo timestep equals zero. Default TRUE.","code":""},{"path":"package.epinowcast.org/dev/reference/check_timestep_by_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check timestep by date — check_timestep_by_date","text":"function used side effect checking timestep date obs. check passes dates, function returns invisibly. Otherwise, stops returns error message.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/check_timestep_by_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Check timestep by group — check_timestep_by_group","title":"Check timestep by group — check_timestep_by_group","text":"function verifies difference dates within group provided observations corresponds provided timestep. check performed specified date_var group obs.","code":""},{"path":"package.epinowcast.org/dev/reference/check_timestep_by_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check timestep by group — check_timestep_by_group","text":"","code":"check_timestep_by_group(obs, date_var, timestep = \"day\", exact = TRUE)"},{"path":"package.epinowcast.org/dev/reference/check_timestep_by_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check timestep by group — check_timestep_by_group","text":"obs types supported data.table::.data.table(). date_var variable obs representing dates. timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days. exact Logical, TRUE``, checks differences exactly match timestep. FALSE``, checks sum differences modulo timestep equals zero. Default TRUE.","code":""},{"path":"package.epinowcast.org/dev/reference/check_timestep_by_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check timestep by group — check_timestep_by_group","text":"function used side effect checking timestep group obs. check passes groups, function returns invisibly. Otherwise, stops returns error message.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/coerce_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce Dates — coerce_date","title":"Coerce Dates — coerce_date","text":"Provides consistent coercion inputs IDate error handling","code":""},{"path":"package.epinowcast.org/dev/reference/coerce_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce Dates — coerce_date","text":"","code":"coerce_date(dates)"},{"path":"package.epinowcast.org/dev/reference/coerce_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce Dates — coerce_date","text":"dates vector-like input, function attempts coerce via data.table::.IDate().","code":""},{"path":"package.epinowcast.org/dev/reference/coerce_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce Dates — coerce_date","text":"IDate vector.","code":""},{"path":"package.epinowcast.org/dev/reference/coerce_date.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coerce Dates — coerce_date","text":"elements dates coerced, function result error, indicating indices coerced IDate. Internal methods epinowcast assume dates represented IDate.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/coerce_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce Dates — coerce_date","text":"","code":"# works coerce_date(c(\"2020-05-28\", \"2020-05-29\")) #> [1] \"2020-05-28\" \"2020-05-29\" # does not, indicates index 2 is problem tryCatch(   coerce_date(c(\"2020-05-28\", \"2020-o5-29\")),   error = function(e) {     print(e)   } ) #> <simpleError in coerce_date(c(\"2020-05-28\", \"2020-o5-29\")): Failed to parse with `as.IDate`: {2020-o5-29} (indices {2}).>"},{"path":"package.epinowcast.org/dev/reference/coerce_dt.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce data.tables — coerce_dt","title":"Coerce data.tables — coerce_dt","text":"Provides consistent coercion inputs data.table error handling, column checking, optional selection.","code":""},{"path":"package.epinowcast.org/dev/reference/coerce_dt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce data.tables — coerce_dt","text":"","code":"coerce_dt(   data,   select = NULL,   required_cols = select,   forbidden_cols = NULL,   group = FALSE,   dates = FALSE,   copy = TRUE,   msg_required = \"The following columns are required: \",   msg_forbidden = \"The following columns are forbidden: \" )"},{"path":"package.epinowcast.org/dev/reference/coerce_dt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce data.tables — coerce_dt","text":"data types supported data.table::.data.table() select optional character vector columns return; unchecked n.b. error include \".group\"; use group argument required_cols optional character vector required columns forbidden_cols optional character vector forbidden columns group logical; ensure presence .group column? dates logical; ensure presence report_date reference_date? TRUE (default), columns coerced data.table::.IDate(). copy logical; TRUE (default), new data.table returned msg_required character string; required_cols-related error message msg_forbidden character string; forbidden_cols-related error message","code":""},{"path":"package.epinowcast.org/dev/reference/coerce_dt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce data.tables — coerce_dt","text":"data.table; returned object copy, unless copy = FALSE, case modifications made -place","code":""},{"path":"package.epinowcast.org/dev/reference/coerce_dt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coerce data.tables — coerce_dt","text":"function provides single-point function getting \"local\" version data provided user, internally used data.table format. also enables selectively copying versus , well checking presence /absence various columns. intended address garbage user, generally attempt address garbage developer - e.g. asking overlapping required forbidden columns (though lead always-error condition).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/construct_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructs random effect terms — construct_re","title":"Constructs random effect terms — construct_re","text":"Constructs random effect terms","code":""},{"path":"package.epinowcast.org/dev/reference/construct_re.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructs random effect terms — construct_re","text":"","code":"construct_re(re, data)"},{"path":"package.epinowcast.org/dev/reference/construct_re.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructs random effect terms — construct_re","text":"re random effect defined using re() takes random effects specified model formula using lme4 syntax. data data.frame observations used define random effects. Must contain variables specified re() term.","code":""},{"path":"package.epinowcast.org/dev/reference/construct_re.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructs random effect terms — construct_re","text":"list containing transformed data (\"data\"), fixed effects terms (\"terms\")  data.frame specifying random effect structure terms (effects). Note specified random effect factor converted one.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/construct_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructs random effect terms — construct_re","text":"","code":"# Simple examples form <- epinowcast:::parse_formula(~ 1 + (1 | day_of_week)) data <- enw_example(\"prepr\")$metareference[[1]] random_effect <- re(form$random[[1]]) epinowcast:::construct_re(random_effect, data) #> $data #>           date .group location age_group delay day_of_week day week month #>  1: 2021-07-13      1       DE       00+     0     Tuesday   0    0     0 #>  2: 2021-07-14      1       DE       00+     0   Wednesday   1    0     0 #>  3: 2021-07-15      1       DE       00+     0    Thursday   2    0     0 #>  4: 2021-07-16      1       DE       00+     0      Friday   3    0     0 #>  5: 2021-07-17      1       DE       00+     0    Saturday   4    0     0 #>  6: 2021-07-18      1       DE       00+     0      Sunday   5    0     0 #>  7: 2021-07-19      1       DE       00+     0      Monday   6    0     0 #>  8: 2021-07-20      1       DE       00+     0     Tuesday   7    1     0 #>  9: 2021-07-21      1       DE       00+     0   Wednesday   8    1     0 #> 10: 2021-07-22      1       DE       00+     0    Thursday   9    1     0 #> 11: 2021-07-23      1       DE       00+     0      Friday  10    1     0 #> 12: 2021-07-24      1       DE       00+     0    Saturday  11    1     0 #> 13: 2021-07-25      1       DE       00+     0      Sunday  12    1     0 #> 14: 2021-07-26      1       DE       00+     0      Monday  13    1     0 #> 15: 2021-07-27      1       DE       00+     0     Tuesday  14    2     0 #> 16: 2021-07-28      1       DE       00+     0   Wednesday  15    2     0 #> 17: 2021-07-29      1       DE       00+     0    Thursday  16    2     0 #> 18: 2021-07-30      1       DE       00+     0      Friday  17    2     0 #> 19: 2021-07-31      1       DE       00+     0    Saturday  18    2     0 #> 20: 2021-08-01      1       DE       00+     0      Sunday  19    2     1 #> 21: 2021-08-02      1       DE       00+     0      Monday  20    2     1 #> 22: 2021-08-03      1       DE       00+     0     Tuesday  21    3     1 #> 23: 2021-08-04      1       DE       00+     0   Wednesday  22    3     1 #> 24: 2021-08-05      1       DE       00+     0    Thursday  23    3     1 #> 25: 2021-08-06      1       DE       00+     0      Friday  24    3     1 #> 26: 2021-08-07      1       DE       00+     0    Saturday  25    3     1 #> 27: 2021-08-08      1       DE       00+     0      Sunday  26    3     1 #> 28: 2021-08-09      1       DE       00+     0      Monday  27    3     1 #> 29: 2021-08-10      1       DE       00+     0     Tuesday  28    4     1 #> 30: 2021-08-11      1       DE       00+     0   Wednesday  29    4     1 #> 31: 2021-08-12      1       DE       00+     0    Thursday  30    4     1 #> 32: 2021-08-13      1       DE       00+     0      Friday  31    4     1 #> 33: 2021-08-14      1       DE       00+     0    Saturday  32    4     1 #> 34: 2021-08-15      1       DE       00+     0      Sunday  33    4     1 #> 35: 2021-08-16      1       DE       00+     0      Monday  34    4     1 #> 36: 2021-08-17      1       DE       00+     0     Tuesday  35    5     1 #> 37: 2021-08-18      1       DE       00+     0   Wednesday  36    5     1 #> 38: 2021-08-19      1       DE       00+     0    Thursday  37    5     1 #> 39: 2021-08-20      1       DE       00+     0      Friday  38    5     1 #> 40: 2021-08-21      1       DE       00+     0    Saturday  39    5     1 #> 41: 2021-08-22      1       DE       00+     0      Sunday  40    5     1 #>           date .group location age_group delay day_of_week day week month #>  #> $terms #> [1] \"day_of_week\" #>  #> $effects #>                 effects fixed day_of_week #> 1:    day_of_weekFriday     0           1 #> 2:    day_of_weekMonday     0           1 #> 3:  day_of_weekSaturday     0           1 #> 4:    day_of_weekSunday     0           1 #> 5:  day_of_weekThursday     0           1 #> 6:   day_of_weekTuesday     0           1 #> 7: day_of_weekWednesday     0           1 #>   # A more complex example form <- epinowcast:::parse_formula(   ~ 1 + disp + (1 + gear | cyl) + (0 + wt | am) ) random_effect <- re(form$random[[1]]) epinowcast:::construct_re(random_effect, mtcars) #> $data #>      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #>  1: 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #>  2: 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #>  3: 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #>  4: 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #>  5: 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #>  6: 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #>  7: 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #>  8: 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #>  9: 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> 10: 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> 11: 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> 12: 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> 13: 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> 14: 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> 15: 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> 16: 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> 17: 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> 18: 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> 19: 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> 20: 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> 21: 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> 22: 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> 23: 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> 24: 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> 25: 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> 26: 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> 27: 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> 28: 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> 29: 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> 30: 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> 31: 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> 32: 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 #>      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #>  #> $terms #> [1] \"cyl\"      \"gear:cyl\" #>  #> $effects #>      effects fixed cyl gear__cyl #> 1:      cyl4     0   1         0 #> 2:      cyl6     0   1         0 #> 3:      cyl8     0   1         0 #> 4: cyl4:gear     0   0         1 #> 5: cyl6:gear     0   0         1 #> 6: cyl8:gear     0   0         1 #>   random_effect2 <- re(form$random[[2]]) epinowcast:::construct_re(random_effect2, mtcars) #> $data #>      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #>  1: 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #>  2: 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #>  3: 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #>  4: 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #>  5: 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #>  6: 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #>  7: 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #>  8: 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #>  9: 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> 10: 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> 11: 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> 12: 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> 13: 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> 14: 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> 15: 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> 16: 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> 17: 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> 18: 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> 19: 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> 20: 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> 21: 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> 22: 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> 23: 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> 24: 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> 25: 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> 26: 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> 27: 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> 28: 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> 29: 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> 30: 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> 31: 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> 32: 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 #>      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #>  #> $terms #> [1] \"wt:am\" #>  #> $effects #>    effects fixed wt__am #> 1:  wt:am0     0      1 #> 2:  wt:am1     0      1 #>"},{"path":"package.epinowcast.org/dev/reference/construct_rw.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructs random walk terms — construct_rw","title":"Constructs random walk terms — construct_rw","text":"function takes random walks defined rw(), produces required additional variables (denoted using \"c\" prefix constructed using enw_add_cumulative_membership()), returns extended data.frame along new fixed effects random effect structure.","code":""},{"path":"package.epinowcast.org/dev/reference/construct_rw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructs random walk terms — construct_rw","text":"","code":"construct_rw(rw, data)"},{"path":"package.epinowcast.org/dev/reference/construct_rw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructs random walk terms — construct_rw","text":"rw random walk term defined rw(). data data.frame observations used define random walk term. Must contain time grouping variables defined rw() term specified.","code":""},{"path":"package.epinowcast.org/dev/reference/construct_rw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructs random walk terms — construct_rw","text":"list containing following: data: input data.frame addition new variables required specified random walk. added using enw_add_cumulative_membership(). -terms: character vector new fixed effects terms add model formula. effects: data.frame describing random effect structure new effects.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/construct_rw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructs random walk terms — construct_rw","text":"","code":"data <- enw_example(\"preproc\")$metareference[[1]]  epinowcast:::construct_rw(rw(week), data) #> $data #>           date .group location age_group delay day_of_week day week month #>  1: 2021-07-13      1       DE       00+     0     Tuesday   0    0     0 #>  2: 2021-07-14      1       DE       00+     0   Wednesday   1    0     0 #>  3: 2021-07-15      1       DE       00+     0    Thursday   2    0     0 #>  4: 2021-07-16      1       DE       00+     0      Friday   3    0     0 #>  5: 2021-07-17      1       DE       00+     0    Saturday   4    0     0 #>  6: 2021-07-18      1       DE       00+     0      Sunday   5    0     0 #>  7: 2021-07-19      1       DE       00+     0      Monday   6    0     0 #>  8: 2021-07-20      1       DE       00+     0     Tuesday   7    1     0 #>  9: 2021-07-21      1       DE       00+     0   Wednesday   8    1     0 #> 10: 2021-07-22      1       DE       00+     0    Thursday   9    1     0 #> 11: 2021-07-23      1       DE       00+     0      Friday  10    1     0 #> 12: 2021-07-24      1       DE       00+     0    Saturday  11    1     0 #> 13: 2021-07-25      1       DE       00+     0      Sunday  12    1     0 #> 14: 2021-07-26      1       DE       00+     0      Monday  13    1     0 #> 15: 2021-07-27      1       DE       00+     0     Tuesday  14    2     0 #> 16: 2021-07-28      1       DE       00+     0   Wednesday  15    2     0 #> 17: 2021-07-29      1       DE       00+     0    Thursday  16    2     0 #> 18: 2021-07-30      1       DE       00+     0      Friday  17    2     0 #> 19: 2021-07-31      1       DE       00+     0    Saturday  18    2     0 #> 20: 2021-08-01      1       DE       00+     0      Sunday  19    2     1 #> 21: 2021-08-02      1       DE       00+     0      Monday  20    2     1 #> 22: 2021-08-03      1       DE       00+     0     Tuesday  21    3     1 #> 23: 2021-08-04      1       DE       00+     0   Wednesday  22    3     1 #> 24: 2021-08-05      1       DE       00+     0    Thursday  23    3     1 #> 25: 2021-08-06      1       DE       00+     0      Friday  24    3     1 #> 26: 2021-08-07      1       DE       00+     0    Saturday  25    3     1 #> 27: 2021-08-08      1       DE       00+     0      Sunday  26    3     1 #> 28: 2021-08-09      1       DE       00+     0      Monday  27    3     1 #> 29: 2021-08-10      1       DE       00+     0     Tuesday  28    4     1 #> 30: 2021-08-11      1       DE       00+     0   Wednesday  29    4     1 #> 31: 2021-08-12      1       DE       00+     0    Thursday  30    4     1 #> 32: 2021-08-13      1       DE       00+     0      Friday  31    4     1 #> 33: 2021-08-14      1       DE       00+     0    Saturday  32    4     1 #> 34: 2021-08-15      1       DE       00+     0      Sunday  33    4     1 #> 35: 2021-08-16      1       DE       00+     0      Monday  34    4     1 #> 36: 2021-08-17      1       DE       00+     0     Tuesday  35    5     1 #> 37: 2021-08-18      1       DE       00+     0   Wednesday  36    5     1 #> 38: 2021-08-19      1       DE       00+     0    Thursday  37    5     1 #> 39: 2021-08-20      1       DE       00+     0      Friday  38    5     1 #> 40: 2021-08-21      1       DE       00+     0    Saturday  39    5     1 #> 41: 2021-08-22      1       DE       00+     0      Sunday  40    5     1 #>           date .group location age_group delay day_of_week day week month #>     cweek1 cweek2 cweek3 cweek4 cweek5 #>  1:      0      0      0      0      0 #>  2:      0      0      0      0      0 #>  3:      0      0      0      0      0 #>  4:      0      0      0      0      0 #>  5:      0      0      0      0      0 #>  6:      0      0      0      0      0 #>  7:      0      0      0      0      0 #>  8:      1      0      0      0      0 #>  9:      1      0      0      0      0 #> 10:      1      0      0      0      0 #> 11:      1      0      0      0      0 #> 12:      1      0      0      0      0 #> 13:      1      0      0      0      0 #> 14:      1      0      0      0      0 #> 15:      1      1      0      0      0 #> 16:      1      1      0      0      0 #> 17:      1      1      0      0      0 #> 18:      1      1      0      0      0 #> 19:      1      1      0      0      0 #> 20:      1      1      0      0      0 #> 21:      1      1      0      0      0 #> 22:      1      1      1      0      0 #> 23:      1      1      1      0      0 #> 24:      1      1      1      0      0 #> 25:      1      1      1      0      0 #> 26:      1      1      1      0      0 #> 27:      1      1      1      0      0 #> 28:      1      1      1      0      0 #> 29:      1      1      1      1      0 #> 30:      1      1      1      1      0 #> 31:      1      1      1      1      0 #> 32:      1      1      1      1      0 #> 33:      1      1      1      1      0 #> 34:      1      1      1      1      0 #> 35:      1      1      1      1      0 #> 36:      1      1      1      1      1 #> 37:      1      1      1      1      1 #> 38:      1      1      1      1      1 #> 39:      1      1      1      1      1 #> 40:      1      1      1      1      1 #> 41:      1      1      1      1      1 #>     cweek1 cweek2 cweek3 cweek4 cweek5 #>  #> $terms #> [1] \"cweek1\" \"cweek2\" \"cweek3\" \"cweek4\" \"cweek5\" #>  #> $effects #>    effects fixed rw__week #> 1:  cweek1     0        1 #> 2:  cweek2     0        1 #> 3:  cweek3     0        1 #> 4:  cweek4     0        1 #> 5:  cweek5     0        1 #>   epinowcast:::construct_rw(rw(week, day_of_week), data) #> $data #>           date .group location age_group delay day_of_week day week month #>  1: 2021-07-13      1       DE       00+     0     Tuesday   0    0     0 #>  2: 2021-07-14      1       DE       00+     0   Wednesday   1    0     0 #>  3: 2021-07-15      1       DE       00+     0    Thursday   2    0     0 #>  4: 2021-07-16      1       DE       00+     0      Friday   3    0     0 #>  5: 2021-07-17      1       DE       00+     0    Saturday   4    0     0 #>  6: 2021-07-18      1       DE       00+     0      Sunday   5    0     0 #>  7: 2021-07-19      1       DE       00+     0      Monday   6    0     0 #>  8: 2021-07-20      1       DE       00+     0     Tuesday   7    1     0 #>  9: 2021-07-21      1       DE       00+     0   Wednesday   8    1     0 #> 10: 2021-07-22      1       DE       00+     0    Thursday   9    1     0 #> 11: 2021-07-23      1       DE       00+     0      Friday  10    1     0 #> 12: 2021-07-24      1       DE       00+     0    Saturday  11    1     0 #> 13: 2021-07-25      1       DE       00+     0      Sunday  12    1     0 #> 14: 2021-07-26      1       DE       00+     0      Monday  13    1     0 #> 15: 2021-07-27      1       DE       00+     0     Tuesday  14    2     0 #> 16: 2021-07-28      1       DE       00+     0   Wednesday  15    2     0 #> 17: 2021-07-29      1       DE       00+     0    Thursday  16    2     0 #> 18: 2021-07-30      1       DE       00+     0      Friday  17    2     0 #> 19: 2021-07-31      1       DE       00+     0    Saturday  18    2     0 #> 20: 2021-08-01      1       DE       00+     0      Sunday  19    2     1 #> 21: 2021-08-02      1       DE       00+     0      Monday  20    2     1 #> 22: 2021-08-03      1       DE       00+     0     Tuesday  21    3     1 #> 23: 2021-08-04      1       DE       00+     0   Wednesday  22    3     1 #> 24: 2021-08-05      1       DE       00+     0    Thursday  23    3     1 #> 25: 2021-08-06      1       DE       00+     0      Friday  24    3     1 #> 26: 2021-08-07      1       DE       00+     0    Saturday  25    3     1 #> 27: 2021-08-08      1       DE       00+     0      Sunday  26    3     1 #> 28: 2021-08-09      1       DE       00+     0      Monday  27    3     1 #> 29: 2021-08-10      1       DE       00+     0     Tuesday  28    4     1 #> 30: 2021-08-11      1       DE       00+     0   Wednesday  29    4     1 #> 31: 2021-08-12      1       DE       00+     0    Thursday  30    4     1 #> 32: 2021-08-13      1       DE       00+     0      Friday  31    4     1 #> 33: 2021-08-14      1       DE       00+     0    Saturday  32    4     1 #> 34: 2021-08-15      1       DE       00+     0      Sunday  33    4     1 #> 35: 2021-08-16      1       DE       00+     0      Monday  34    4     1 #> 36: 2021-08-17      1       DE       00+     0     Tuesday  35    5     1 #> 37: 2021-08-18      1       DE       00+     0   Wednesday  36    5     1 #> 38: 2021-08-19      1       DE       00+     0    Thursday  37    5     1 #> 39: 2021-08-20      1       DE       00+     0      Friday  38    5     1 #> 40: 2021-08-21      1       DE       00+     0    Saturday  39    5     1 #> 41: 2021-08-22      1       DE       00+     0      Sunday  40    5     1 #>           date .group location age_group delay day_of_week day week month #>     cweek1 cweek2 cweek3 cweek4 cweek5 #>  1:      0      0      0      0      0 #>  2:      0      0      0      0      0 #>  3:      0      0      0      0      0 #>  4:      0      0      0      0      0 #>  5:      0      0      0      0      0 #>  6:      0      0      0      0      0 #>  7:      0      0      0      0      0 #>  8:      1      0      0      0      0 #>  9:      1      0      0      0      0 #> 10:      1      0      0      0      0 #> 11:      1      0      0      0      0 #> 12:      1      0      0      0      0 #> 13:      1      0      0      0      0 #> 14:      1      0      0      0      0 #> 15:      1      1      0      0      0 #> 16:      1      1      0      0      0 #> 17:      1      1      0      0      0 #> 18:      1      1      0      0      0 #> 19:      1      1      0      0      0 #> 20:      1      1      0      0      0 #> 21:      1      1      0      0      0 #> 22:      1      1      1      0      0 #> 23:      1      1      1      0      0 #> 24:      1      1      1      0      0 #> 25:      1      1      1      0      0 #> 26:      1      1      1      0      0 #> 27:      1      1      1      0      0 #> 28:      1      1      1      0      0 #> 29:      1      1      1      1      0 #> 30:      1      1      1      1      0 #> 31:      1      1      1      1      0 #> 32:      1      1      1      1      0 #> 33:      1      1      1      1      0 #> 34:      1      1      1      1      0 #> 35:      1      1      1      1      0 #> 36:      1      1      1      1      1 #> 37:      1      1      1      1      1 #> 38:      1      1      1      1      1 #> 39:      1      1      1      1      1 #> 40:      1      1      1      1      1 #> 41:      1      1      1      1      1 #>     cweek1 cweek2 cweek3 cweek4 cweek5 #>  #> $terms #> [1] \"day_of_week:cweek1\" \"day_of_week:cweek2\" \"day_of_week:cweek3\" #> [4] \"day_of_week:cweek4\" \"day_of_week:cweek5\" #>  #> $effects #>                         effects fixed rw__day_of_weekTuesday__week #>  1:    day_of_weekFriday:cweek1     0                            0 #>  2:    day_of_weekMonday:cweek1     0                            0 #>  3:  day_of_weekSaturday:cweek1     0                            0 #>  4:    day_of_weekSunday:cweek1     0                            0 #>  5:  day_of_weekThursday:cweek1     0                            0 #>  6:   day_of_weekTuesday:cweek1     0                            1 #>  7: day_of_weekWednesday:cweek1     0                            0 #>  8:    day_of_weekFriday:cweek2     0                            0 #>  9:    day_of_weekMonday:cweek2     0                            0 #> 10:  day_of_weekSaturday:cweek2     0                            0 #> 11:    day_of_weekSunday:cweek2     0                            0 #> 12:  day_of_weekThursday:cweek2     0                            0 #> 13:   day_of_weekTuesday:cweek2     0                            1 #> 14: day_of_weekWednesday:cweek2     0                            0 #> 15:    day_of_weekFriday:cweek3     0                            0 #> 16:    day_of_weekMonday:cweek3     0                            0 #> 17:  day_of_weekSaturday:cweek3     0                            0 #> 18:    day_of_weekSunday:cweek3     0                            0 #> 19:  day_of_weekThursday:cweek3     0                            0 #> 20:   day_of_weekTuesday:cweek3     0                            1 #> 21: day_of_weekWednesday:cweek3     0                            0 #> 22:    day_of_weekFriday:cweek4     0                            0 #> 23:    day_of_weekMonday:cweek4     0                            0 #> 24:  day_of_weekSaturday:cweek4     0                            0 #> 25:    day_of_weekSunday:cweek4     0                            0 #> 26:  day_of_weekThursday:cweek4     0                            0 #> 27:   day_of_weekTuesday:cweek4     0                            1 #> 28: day_of_weekWednesday:cweek4     0                            0 #> 29:    day_of_weekFriday:cweek5     0                            0 #> 30:    day_of_weekMonday:cweek5     0                            0 #> 31:  day_of_weekSaturday:cweek5     0                            0 #> 32:    day_of_weekSunday:cweek5     0                            0 #> 33:  day_of_weekThursday:cweek5     0                            0 #> 34:   day_of_weekTuesday:cweek5     0                            1 #> 35: day_of_weekWednesday:cweek5     0                            0 #>                         effects fixed rw__day_of_weekTuesday__week #>     rw__day_of_weekWednesday__week rw__day_of_weekThursday__week #>  1:                              0                             0 #>  2:                              0                             0 #>  3:                              0                             0 #>  4:                              0                             0 #>  5:                              0                             1 #>  6:                              0                             0 #>  7:                              1                             0 #>  8:                              0                             0 #>  9:                              0                             0 #> 10:                              0                             0 #> 11:                              0                             0 #> 12:                              0                             1 #> 13:                              0                             0 #> 14:                              1                             0 #> 15:                              0                             0 #> 16:                              0                             0 #> 17:                              0                             0 #> 18:                              0                             0 #> 19:                              0                             1 #> 20:                              0                             0 #> 21:                              1                             0 #> 22:                              0                             0 #> 23:                              0                             0 #> 24:                              0                             0 #> 25:                              0                             0 #> 26:                              0                             1 #> 27:                              0                             0 #> 28:                              1                             0 #> 29:                              0                             0 #> 30:                              0                             0 #> 31:                              0                             0 #> 32:                              0                             0 #> 33:                              0                             1 #> 34:                              0                             0 #> 35:                              1                             0 #>     rw__day_of_weekWednesday__week rw__day_of_weekThursday__week #>     rw__day_of_weekFriday__week rw__day_of_weekSaturday__week #>  1:                           1                             0 #>  2:                           0                             0 #>  3:                           0                             1 #>  4:                           0                             0 #>  5:                           0                             0 #>  6:                           0                             0 #>  7:                           0                             0 #>  8:                           1                             0 #>  9:                           0                             0 #> 10:                           0                             1 #> 11:                           0                             0 #> 12:                           0                             0 #> 13:                           0                             0 #> 14:                           0                             0 #> 15:                           1                             0 #> 16:                           0                             0 #> 17:                           0                             1 #> 18:                           0                             0 #> 19:                           0                             0 #> 20:                           0                             0 #> 21:                           0                             0 #> 22:                           1                             0 #> 23:                           0                             0 #> 24:                           0                             1 #> 25:                           0                             0 #> 26:                           0                             0 #> 27:                           0                             0 #> 28:                           0                             0 #> 29:                           1                             0 #> 30:                           0                             0 #> 31:                           0                             1 #> 32:                           0                             0 #> 33:                           0                             0 #> 34:                           0                             0 #> 35:                           0                             0 #>     rw__day_of_weekFriday__week rw__day_of_weekSaturday__week #>     rw__day_of_weekSunday__week rw__day_of_weekMonday__week #>  1:                           0                           0 #>  2:                           0                           1 #>  3:                           0                           0 #>  4:                           1                           0 #>  5:                           0                           0 #>  6:                           0                           0 #>  7:                           0                           0 #>  8:                           0                           0 #>  9:                           0                           1 #> 10:                           0                           0 #> 11:                           1                           0 #> 12:                           0                           0 #> 13:                           0                           0 #> 14:                           0                           0 #> 15:                           0                           0 #> 16:                           0                           1 #> 17:                           0                           0 #> 18:                           1                           0 #> 19:                           0                           0 #> 20:                           0                           0 #> 21:                           0                           0 #> 22:                           0                           0 #> 23:                           0                           1 #> 24:                           0                           0 #> 25:                           1                           0 #> 26:                           0                           0 #> 27:                           0                           0 #> 28:                           0                           0 #> 29:                           0                           0 #> 30:                           0                           1 #> 31:                           0                           0 #> 32:                           1                           0 #> 33:                           0                           0 #> 34:                           0                           0 #> 35:                           0                           0 #>     rw__day_of_weekSunday__week rw__day_of_weekMonday__week #>"},{"path":"package.epinowcast.org/dev/reference/convert_cmdstan_to_rstan.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Cmdstan to Rstan — convert_cmdstan_to_rstan","title":"Convert Cmdstan to Rstan — convert_cmdstan_to_rstan","text":"Convert Cmdstan Rstan","code":""},{"path":"package.epinowcast.org/dev/reference/convert_cmdstan_to_rstan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Cmdstan to Rstan — convert_cmdstan_to_rstan","text":"","code":"convert_cmdstan_to_rstan(functions)"},{"path":"package.epinowcast.org/dev/reference/convert_cmdstan_to_rstan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Cmdstan to Rstan — convert_cmdstan_to_rstan","text":"functions character string stan functions produced using stan_fns_as_string().","code":""},{"path":"package.epinowcast.org/dev/reference/convert_cmdstan_to_rstan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Cmdstan to Rstan — convert_cmdstan_to_rstan","text":"character string stan functions converted use rstan.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/convolution_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a convolution matrix — convolution_matrix","title":"Construct a convolution matrix — convolution_matrix","text":"function allows construction convolution matrices can combined vector primary events produce vector secondary events example form renewal equation simulate reporting delays. Time-varying delays supported well distribution padding (allow use renewal equation like approaches).","code":""},{"path":"package.epinowcast.org/dev/reference/convolution_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a convolution matrix — convolution_matrix","text":"","code":"convolution_matrix(dist, t, include_partial = FALSE)"},{"path":"package.epinowcast.org/dev/reference/convolution_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a convolution matrix — convolution_matrix","text":"dist vector list vectors describing distribution convolved probability mass function. t Integer value indicating number time steps convolve . include_partial Logical, defaults FALSE. TRUE, convolution include partially complete secondary events.","code":""},{"path":"package.epinowcast.org/dev/reference/convolution_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a convolution matrix — convolution_matrix","text":"matrix column indicating primary event row indicating secondary event.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/convolution_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a convolution matrix — convolution_matrix","text":"","code":"# Simple convolution matrix with a static distribution convolution_matrix(c(1, 2, 3), 10) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #>  [1,]    0    0    0    0    0    0    0    0    0     0 #>  [2,]    0    0    0    0    0    0    0    0    0     0 #>  [3,]    3    2    1    0    0    0    0    0    0     0 #>  [4,]    0    3    2    1    0    0    0    0    0     0 #>  [5,]    0    0    3    2    1    0    0    0    0     0 #>  [6,]    0    0    0    3    2    1    0    0    0     0 #>  [7,]    0    0    0    0    3    2    1    0    0     0 #>  [8,]    0    0    0    0    0    3    2    1    0     0 #>  [9,]    0    0    0    0    0    0    3    2    1     0 #> [10,]    0    0    0    0    0    0    0    3    2     1 # Include partially reported convolutions convolution_matrix(c(1, 2, 3), 10, include_partial = TRUE) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #>  [1,]    1    0    0    0    0    0    0    0    0     0 #>  [2,]    2    1    0    0    0    0    0    0    0     0 #>  [3,]    3    2    1    0    0    0    0    0    0     0 #>  [4,]    0    3    2    1    0    0    0    0    0     0 #>  [5,]    0    0    3    2    1    0    0    0    0     0 #>  [6,]    0    0    0    3    2    1    0    0    0     0 #>  [7,]    0    0    0    0    3    2    1    0    0     0 #>  [8,]    0    0    0    0    0    3    2    1    0     0 #>  [9,]    0    0    0    0    0    0    3    2    1     0 #> [10,]    0    0    0    0    0    0    0    3    2     1 # Use a list of distributions convolution_matrix(rep(list(c(1, 2, 3)), 10), 10) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #>  [1,]    0    0    0    0    0    0    0    0    0     0 #>  [2,]    0    0    0    0    0    0    0    0    0     0 #>  [3,]    3    2    1    0    0    0    0    0    0     0 #>  [4,]    0    3    2    1    0    0    0    0    0     0 #>  [5,]    0    0    3    2    1    0    0    0    0     0 #>  [6,]    0    0    0    3    2    1    0    0    0     0 #>  [7,]    0    0    0    0    3    2    1    0    0     0 #>  [8,]    0    0    0    0    0    3    2    1    0     0 #>  [9,]    0    0    0    0    0    0    3    2    1     0 #> [10,]    0    0    0    0    0    0    0    3    2     1 # Use a time-varying list of distributions convolution_matrix(c(rep(list(c(1, 2, 3)), 10), list(c(4, 5, 6))), 11) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] #>  [1,]    0    0    0    0    0    0    0    0    0     0     0 #>  [2,]    0    0    0    0    0    0    0    0    0     0     0 #>  [3,]    3    2    1    0    0    0    0    0    0     0     0 #>  [4,]    0    3    2    1    0    0    0    0    0     0     0 #>  [5,]    0    0    3    2    1    0    0    0    0     0     0 #>  [6,]    0    0    0    3    2    1    0    0    0     0     0 #>  [7,]    0    0    0    0    3    2    1    0    0     0     0 #>  [8,]    0    0    0    0    0    3    2    1    0     0     0 #>  [9,]    0    0    0    0    0    0    3    2    1     0     0 #> [10,]    0    0    0    0    0    0    0    3    2     1     0 #> [11,]    0    0    0    0    0    0    0    0    3     2     4"},{"path":"package.epinowcast.org/dev/reference/date_to_numeric_modulus.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert date column to numeric and calculate its modulus with given timestep. — date_to_numeric_modulus","title":"Convert date column to numeric and calculate its modulus with given timestep. — date_to_numeric_modulus","text":"function processes date column data.table, converting numeric representation computing modulus provided timestep.","code":""},{"path":"package.epinowcast.org/dev/reference/date_to_numeric_modulus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert date column to numeric and calculate its modulus with given timestep. — date_to_numeric_modulus","text":"","code":"date_to_numeric_modulus(dt, date_column, timestep)"},{"path":"package.epinowcast.org/dev/reference/date_to_numeric_modulus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert date column to numeric and calculate its modulus with given timestep. — date_to_numeric_modulus","text":"dt data.table. date_column character string representing name date column dt. timestep integer representing internal timestep.","code":""},{"path":"package.epinowcast.org/dev/reference/date_to_numeric_modulus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert date column to numeric and calculate its modulus with given timestep. — date_to_numeric_modulus","text":"modified data.table two new columns: one numeric representation date minus minimum date another modulus timestep.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate cumulative reported cases from incidence of new reports — enw_add_cumulative","title":"Calculate cumulative reported cases from incidence of new reports — enw_add_cumulative","text":"Calculate cumulative reported cases incidence new reports","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate cumulative reported cases from incidence of new reports — enw_add_cumulative","text":"","code":"enw_add_cumulative(obs, by = NULL, copy = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate cumulative reported cases from incidence of new reports — enw_add_cumulative","text":"obs data.frame containing least following variables: reference date (index date interest), report_date (report date observations), new_confirm (incident observations reference report date). character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling copy obs copied (default) modified place?","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate cumulative reported cases from incidence of new reports — enw_add_cumulative","text":"input data.frame new variable confirm.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate cumulative reported cases from incidence of new reports — enw_add_cumulative","text":"","code":"# Default reconstruct incidence dt <- germany_covid19_hosp[location == \"DE\"][age_group == \"00+\"] dt <- enw_add_incidence(dt) dt <- dt[, confirm := NULL] enw_add_cumulative(dt) #>        reference_date location age_group report_date new_confirm delay confirm #>     1:     2021-04-06       DE       00+  2021-04-06         149     0     149 #>     2:     2021-04-06       DE       00+  2021-04-07         140     1     289 #>     3:     2021-04-06       DE       00+  2021-04-08          61     2     350 #>     4:     2021-04-06       DE       00+  2021-04-09          52     3     402 #>     5:     2021-04-06       DE       00+  2021-04-10          36     4     438 #>    ---                                                                         #> 12911:     2021-10-18       DE       00+  2021-10-19          70     1     113 #> 12912:     2021-10-18       DE       00+  2021-10-20          29     2     142 #> 12913:     2021-10-19       DE       00+  2021-10-19         223     0     223 #> 12914:     2021-10-19       DE       00+  2021-10-20         164     1     387 #> 12915:     2021-10-20       DE       00+  2021-10-20         235     0     235  # Make use of maximum reported to calculate empirical daily reporting enw_add_cumulative(dt) #>        reference_date location age_group report_date new_confirm delay confirm #>     1:     2021-04-06       DE       00+  2021-04-06         149     0     149 #>     2:     2021-04-06       DE       00+  2021-04-07         140     1     289 #>     3:     2021-04-06       DE       00+  2021-04-08          61     2     350 #>     4:     2021-04-06       DE       00+  2021-04-09          52     3     402 #>     5:     2021-04-06       DE       00+  2021-04-10          36     4     438 #>    ---                                                                         #> 12911:     2021-10-18       DE       00+  2021-10-19          70     1     113 #> 12912:     2021-10-18       DE       00+  2021-10-20          29     2     142 #> 12913:     2021-10-19       DE       00+  2021-10-19         223     0     223 #> 12914:     2021-10-19       DE       00+  2021-10-20         164     1     387 #> 12915:     2021-10-20       DE       00+  2021-10-20         235     0     235"},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative_membership.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a cumulative membership effect to a data.frame — enw_add_cumulative_membership","title":"Add a cumulative membership effect to a data.frame — enw_add_cumulative_membership","text":"function adds cumulative membership effect data frame. useful specifying models random walks (using rw()) features can used design matrix appropriate formula. Supports grouping via optional .group column. Note cumulative membership indexed start zero (.e. first observation assigned cumulative membership zero).","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative_membership.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a cumulative membership effect to a data.frame — enw_add_cumulative_membership","text":"","code":"enw_add_cumulative_membership(metaobs, feature, copy = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative_membership.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a cumulative membership effect to a data.frame — enw_add_cumulative_membership","text":"metaobs data.frame column named feature contains numeric vector values. feature name column metaobs contains numeric vector values. copy metaobs copied (default) modified place?","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative_membership.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a cumulative membership effect to a data.frame — enw_add_cumulative_membership","text":"data.frame new columns cfeature$ contain cumulative membership effect value feature. example original feature week (numeric entries 1, 2, 3) new columns cweek1, cweek2, cweek3.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_cumulative_membership.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a cumulative membership effect to a data.frame — enw_add_cumulative_membership","text":"","code":"metaobs <- data.frame(week = 1:3) enw_add_cumulative_membership(metaobs, \"week\") #>    week .group cweek2 cweek3 #> 1:    1      1      0      0 #> 2:    2      1      1      0 #> 3:    3      1      1      1  metaobs <- data.frame(week = 1:3, .group = c(1,1,2)) enw_add_cumulative_membership(metaobs, \"week\") #>    week .group cweek2 cweek3 #> 1:    1      1      0      0 #> 2:    2      1      1      0 #> 3:    3      2      0      1"},{"path":"package.epinowcast.org/dev/reference/enw_add_delay.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a delay variable — enw_add_delay","title":"Add a delay variable — enw_add_delay","text":"Add delay variable based numeric difference report_date reference_date columns.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_delay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a delay variable — enw_add_delay","text":"","code":"enw_add_delay(obs, timestep = \"day\", copy = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_add_delay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a delay variable — enw_add_delay","text":"obs data.frame containing least following variables: reference date (index date interest), report_date (report date observations), confirm (cumulative observations reference report date). timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days. copy obs copied (default) modified place?","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_delay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a delay variable — enw_add_delay","text":"data.table delay column added.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_delay.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a delay variable — enw_add_delay","text":"","code":"obs <- data.frame(report_date = as.Date(\"2021-01-01\") + -2:0) obs$reference_date <- as.Date(\"2021-01-01\") enw_add_delay(obs) #>    report_date reference_date delay #> 1:  2020-12-30     2021-01-01    -2 #> 2:  2020-12-31     2021-01-01    -1 #> 3:  2021-01-01     2021-01-01     0"},{"path":"package.epinowcast.org/dev/reference/enw_add_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate incidence of new reports from cumulative reports — enw_add_incidence","title":"Calculate incidence of new reports from cumulative reports — enw_add_incidence","text":"Calculate incidence new reports cumulative reports","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate incidence of new reports from cumulative reports — enw_add_incidence","text":"","code":"enw_add_incidence(obs, set_negatives_to_zero = TRUE, by = NULL, copy = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_add_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate incidence of new reports from cumulative reports — enw_add_incidence","text":"obs data.frame containing least following variables: reference date (index date interest), report_date (report date observations), confirm (cumulative observations reference report date). set_negatives_to_zero Logical, defaults TRUE. negative counts (calculated incidence observations) set zero. Currently downstream modelling support negative counts setting must TRUE intending use epinowcast(). character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling copy obs copied (default) modified place?","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate incidence of new reports from cumulative reports — enw_add_incidence","text":"input data.frame new variable new_confirm. max_confirm present data.frame proportion reported day (prop_reported) also added.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate incidence of new reports from cumulative reports — enw_add_incidence","text":"","code":"# Default reconstruct incidence dt <- germany_covid19_hosp[location == \"DE\"][age_group == \"00+\"] enw_add_incidence(dt) #>        reference_date location age_group confirm report_date new_confirm delay #>     1:     2021-04-06       DE       00+     149  2021-04-06         149     0 #>     2:     2021-04-06       DE       00+     289  2021-04-07         140     1 #>     3:     2021-04-06       DE       00+     350  2021-04-08          61     2 #>     4:     2021-04-06       DE       00+     402  2021-04-09          52     3 #>     5:     2021-04-06       DE       00+     438  2021-04-10          36     4 #>    ---                                                                         #> 12911:     2021-10-18       DE       00+     113  2021-10-19          70     1 #> 12912:     2021-10-18       DE       00+     142  2021-10-20          29     2 #> 12913:     2021-10-19       DE       00+     223  2021-10-19         223     0 #> 12914:     2021-10-19       DE       00+     387  2021-10-20         164     1 #> 12915:     2021-10-20       DE       00+     235  2021-10-20         235     0  # Make use of maximum reported to calculate empirical daily reporting dt <- enw_add_max_reported(dt) enw_add_incidence(dt) #>        reference_date .group max_confirm location age_group confirm report_date #>     1:     2021-04-06      1         708       DE       00+     149  2021-04-06 #>     2:     2021-04-06      1         708       DE       00+     289  2021-04-07 #>     3:     2021-04-06      1         708       DE       00+     350  2021-04-08 #>     4:     2021-04-06      1         708       DE       00+     402  2021-04-09 #>     5:     2021-04-06      1         708       DE       00+     438  2021-04-10 #>    ---                                                                          #> 12911:     2021-10-18      1         142       DE       00+     113  2021-10-19 #> 12912:     2021-10-18      1         142       DE       00+     142  2021-10-20 #> 12913:     2021-10-19      1         387       DE       00+     223  2021-10-19 #> 12914:     2021-10-19      1         387       DE       00+     387  2021-10-20 #> 12915:     2021-10-20      1         235       DE       00+     235  2021-10-20 #>        cum_prop_reported new_confirm delay prop_reported #>     1:         0.2104520         149     0    0.21045198 #>     2:         0.4081921         140     1    0.19774011 #>     3:         0.4943503          61     2    0.08615819 #>     4:         0.5677966          52     3    0.07344633 #>     5:         0.6186441          36     4    0.05084746 #>    ---                                                   #> 12911:         0.7957746          70     1    0.49295775 #> 12912:         1.0000000          29     2    0.20422535 #> 12913:         0.5762274         223     0    0.57622739 #> 12914:         1.0000000         164     1    0.42377261 #> 12915:         1.0000000         235     0    1.00000000"},{"path":"package.epinowcast.org/dev/reference/enw_add_latest_obs_to_nowcast.html","id":null,"dir":"Reference","previous_headings":"","what":"Add latest observations to nowcast output — enw_add_latest_obs_to_nowcast","title":"Add latest observations to nowcast output — enw_add_latest_obs_to_nowcast","text":"Add latest observations nowcast output. useful plotting nowcast latest observations.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_latest_obs_to_nowcast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add latest observations to nowcast output — enw_add_latest_obs_to_nowcast","text":"","code":"enw_add_latest_obs_to_nowcast(nowcast, obs)"},{"path":"package.epinowcast.org/dev/reference/enw_add_latest_obs_to_nowcast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add latest observations to nowcast output — enw_add_latest_obs_to_nowcast","text":"nowcast data.frame nowcast output enw_nowcast_summary(). obs observation data.frame containing reference_date columns length number rows posterior date observation date. used align posterior observations. easiest source data output latest output enw_preprocess_data() enw_latest_data().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_latest_obs_to_nowcast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add latest observations to nowcast output — enw_add_latest_obs_to_nowcast","text":"data.frame nowcast output latest observations added.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_latest_obs_to_nowcast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add latest observations to nowcast output — enw_add_latest_obs_to_nowcast","text":"","code":"fit <- enw_example(\"nowcast\") obs <- enw_example(\"obs\") nowcast <- summary(fit, type = \"nowcast\") enw_add_latest_obs_to_nowcast(nowcast, obs) #>     reference_date .group latest_confirm confirm report_date max_confirm #>  1:     2021-08-03      1            156     149  2021-08-22         149 #>  2:     2021-08-04      1            183     166  2021-08-22         166 #>  3:     2021-08-05      1            147     133  2021-08-22         133 #>  4:     2021-08-06      1            155     137  2021-08-22         137 #>  5:     2021-08-07      1            159     139  2021-08-22         139 #>  6:     2021-08-08      1            119      97  2021-08-22          97 #>  7:     2021-08-09      1             65      58  2021-08-22          58 #>  8:     2021-08-10      1            204     175  2021-08-22         175 #>  9:     2021-08-11      1            275     233  2021-08-22         233 #> 10:     2021-08-12      1            273     237  2021-08-22         237 #> 11:     2021-08-13      1            270     204  2021-08-22         204 #> 12:     2021-08-14      1            262     189  2021-08-22         189 #> 13:     2021-08-15      1            192     125  2021-08-22         125 #> 14:     2021-08-16      1            140      98  2021-08-22          98 #> 15:     2021-08-17      1            323     242  2021-08-22         242 #> 16:     2021-08-18      1            409     223  2021-08-22         223 #> 17:     2021-08-19      1            370     202  2021-08-22         202 #> 18:     2021-08-20      1            361     171  2021-08-22         171 #> 19:     2021-08-21      1            339     112  2021-08-22         112 #> 20:     2021-08-22      1            258      45  2021-08-22          45 #>     location age_group cum_prop_reported delay prop_reported    mean median #>  1:       DE       00+                 1    19   0.000000000 149.000  149.0 #>  2:       DE       00+                 1    18   0.000000000 167.440  167.0 #>  3:       DE       00+                 1    17   0.000000000 135.804  136.0 #>  4:       DE       00+                 1    16   0.000000000 141.039  141.0 #>  5:       DE       00+                 1    15   0.007194245 145.916  146.0 #>  6:       DE       00+                 1    14   0.000000000 103.674  103.0 #>  7:       DE       00+                 1    13   0.000000000  63.014   63.0 #>  8:       DE       00+                 1    12   0.000000000 185.131  185.0 #>  9:       DE       00+                 1    11   0.000000000 255.938  256.0 #> 10:       DE       00+                 1    10   0.004219409 267.445  267.0 #> 11:       DE       00+                 1     9   0.000000000 236.189  235.5 #> 12:       DE       00+                 1     8   0.015873016 230.969  230.0 #> 13:       DE       00+                 1     7   0.040000000 165.393  165.0 #> 14:       DE       00+                 1     6   0.010204082 129.419  129.0 #> 15:       DE       00+                 1     5   0.012396694 293.442  292.0 #> 16:       DE       00+                 1     4   0.017937220 292.867  292.0 #> 17:       DE       00+                 1     3   0.019801980 292.416  291.0 #> 18:       DE       00+                 1     2   0.070175439 294.685  291.0 #> 19:       DE       00+                 1     1   0.383928571 312.347  307.0 #> 20:       DE       00+                 1     0   1.000000000 377.870  363.0 #>             sd     mad     q5 q20    q35   q50    q65 q80    q95      rhat #>  1:   0.000000  0.0000 149.00 149 149.00 149.0 149.00 149 149.00        NA #>  2:   1.306946  1.4826 166.00 166 167.00 167.0 168.00 168 170.00 0.9984731 #>  3:   1.910297  1.4826 133.00 134 135.00 136.0 136.00 137 139.00 1.0001748 #>  4:   2.336009  1.4826 138.00 139 140.00 141.0 142.00 143 145.00 0.9985918 #>  5:   3.245223  2.9652 141.00 143 145.00 146.0 147.00 148 152.00 1.0014625 #>  6:   3.004455  2.9652  99.00 101 102.00 103.0 105.00 106 109.00 1.0008170 #>  7:   2.633769  2.9652  59.00  61  62.00  63.0  64.00  65  68.00 1.0001596 #>  8:   3.861703  4.4478 179.00 182 183.00 185.0 186.00 188 192.00 1.0016498 #>  9:   6.338796  5.9304 246.00 251 253.00 256.0 258.00 261 267.00 1.0008653 #> 10:   7.795495  7.4130 256.00 261 264.00 267.0 270.00 274 281.00 1.0020121 #> 11:   8.328183  8.1543 224.00 229 233.00 235.5 239.00 243 251.00 0.9993738 #> 12:   9.851248  9.6369 216.00 223 227.00 230.0 234.00 239 247.00 0.9997526 #> 13:  10.147883 10.3782 150.00 157 161.00 165.0 168.00 173 184.00 0.9989137 #> 14:   8.341524  8.8956 116.00 122 126.00 129.0 132.00 136 144.00 1.0002835 #> 15:  12.342730 11.8608 276.00 283 288.00 292.0 297.00 303 316.00 0.9993443 #> 16:  15.235795 14.8260 271.00 279 286.00 292.0 297.00 305 320.05 1.0000165 #> 17:  20.600906 19.2738 263.00 275 283.00 291.0 298.35 309 331.00 1.0007083 #> 18:  29.652944 28.1694 251.95 270 282.00 291.0 302.00 318 347.05 1.0031517 #> 19:  52.500656 50.4084 237.00 269 287.65 307.0 327.00 351 403.15 1.0029817 #> 20: 106.473272 93.4038 239.95 292 327.00 363.0 401.00 451 576.15 1.0034715 #>      ess_bulk  ess_tail #>  1:        NA        NA #>  2: 1072.5191 1068.0041 #>  3: 1040.7197 1025.8570 #>  4: 1021.8261  829.9055 #>  5: 1036.5263  915.7683 #>  6: 1084.2564  888.0770 #>  7: 1170.0810  845.5932 #>  8:  826.3595  989.6300 #>  9:  976.1162  943.8214 #> 10: 1016.2724  988.2011 #> 11: 1119.8109  785.8675 #> 12: 1067.0426  980.9775 #> 13: 1252.9097  836.7735 #> 14: 1111.6597  956.2202 #> 15: 1076.8727  782.2336 #> 16: 1040.5391  767.7477 #> 17:  950.4381  731.4047 #> 18: 1230.4660  982.6347 #> 19: 1076.9075  871.5941 #> 20: 1394.6975  915.4979"},{"path":"package.epinowcast.org/dev/reference/enw_add_max_reported.html","id":null,"dir":"Reference","previous_headings":"","what":"Add the maximum number of cases reported on a given day — enw_add_max_reported","title":"Add the maximum number of cases reported on a given day — enw_add_max_reported","text":"Add maximum number cases reported given day data set. useful calculating proportion cases reported given day also done function.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_max_reported.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add the maximum number of cases reported on a given day — enw_add_max_reported","text":"","code":"enw_add_max_reported(obs, copy = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_add_max_reported.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add the maximum number of cases reported on a given day — enw_add_max_reported","text":"obs data.frame containing least following variables: reference date (index date interest), report_date (report date observations), confirm (cumulative observations reference report date). copy obs copied (default) modified place?","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_max_reported.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add the maximum number of cases reported on a given day — enw_add_max_reported","text":"data.table max_confirm cum_prop_reported columns added. max_confirm maximum number cases reported given day. cum_prop_reported proportion cases reported given day relative maximum number cases reported given day.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_max_reported.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add the maximum number of cases reported on a given day — enw_add_max_reported","text":"","code":"obs <- data.frame(report_date = as.Date(\"2021-01-01\") + 0:2) obs$reference_date <- as.Date(\"2021-01-01\") obs$confirm <- 1:3 enw_add_max_reported(obs) #>    reference_date .group max_confirm report_date confirm cum_prop_reported #> 1:     2021-01-01      1           3  2021-01-01       1         0.3333333 #> 2:     2021-01-01      1           3  2021-01-02       2         0.6666667 #> 3:     2021-01-01      1           3  2021-01-03       3         1.0000000"},{"path":"package.epinowcast.org/dev/reference/enw_add_metaobs_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Add common metadata variables — enw_add_metaobs_features","title":"Add common metadata variables — enw_add_metaobs_features","text":"already present, annotates time series data metadata commonly used models: day week, days, weeks, months since start time series.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_metaobs_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add common metadata variables — enw_add_metaobs_features","text":"","code":"enw_add_metaobs_features(   metaobs,   holidays = NULL,   holidays_to = \"Sunday\",   datecol = \"date\" )"},{"path":"package.epinowcast.org/dev/reference/enw_add_metaobs_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add common metadata variables — enw_add_metaobs_features","text":"metaobs Raw data, coercible via data.table::.data.table(). Coerced object must Dates column corresponding datecol name. holidays (potentially empty) vector dates (input coercible ; see coerce_date()). day_of_week column set holidays_to dates. holidays_to character string assign holidays, holidays argument non-empty. Replaces day_of_week column value datecol column metaobs corresponding pertinent dates.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_metaobs_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add common metadata variables — enw_add_metaobs_features","text":"copy metaobs input, additional columns: day_of_week, factor values output weekdays() possibly holiday_to distinct weekdays values day, numeric, 0 based start time series week, numeric, 0 based start time series month, numeric, 0 based start time series","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_metaobs_features.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add common metadata variables — enw_add_metaobs_features","text":"Effects models often need include covariates time-based features, day week (e.g. reflect different care-seeking /reporting behaviour). function called within enw_preprocess_data() systematically annotate metaobs commonly used metadata, already present. However, can also used directly data.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_metaobs_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add common metadata variables — enw_add_metaobs_features","text":"","code":"# make some example date nat_germany_hosp <- subset(   germany_covid19_hosp,   location == \"DE\" & age_group == \"80+\" )[1:40]  basemeta <- enw_add_metaobs_features(   nat_germany_hosp,   datecol = \"report_date\" ) basemeta #>     reference_date location age_group confirm report_date day_of_week day week #>  1:     2021-04-06       DE       80+      35  2021-04-06     Tuesday   0    0 #>  2:     2021-04-07       DE       80+      81  2021-04-07   Wednesday   1    0 #>  3:     2021-04-08       DE       80+      85  2021-04-08    Thursday   2    0 #>  4:     2021-04-09       DE       80+      62  2021-04-09      Friday   3    0 #>  5:     2021-04-10       DE       80+      45  2021-04-10    Saturday   4    0 #>  6:     2021-04-11       DE       80+      23  2021-04-11      Sunday   5    0 #>  7:     2021-04-12       DE       80+      33  2021-04-12      Monday   6    0 #>  8:     2021-04-13       DE       80+      66  2021-04-13     Tuesday   7    1 #>  9:     2021-04-14       DE       80+      50  2021-04-14   Wednesday   8    1 #> 10:     2021-04-15       DE       80+      66  2021-04-15    Thursday   9    1 #> 11:     2021-04-16       DE       80+      67  2021-04-16      Friday  10    1 #> 12:     2021-04-17       DE       80+      50  2021-04-17    Saturday  11    1 #> 13:     2021-04-18       DE       80+      33  2021-04-18      Sunday  12    1 #> 14:     2021-04-19       DE       80+      25  2021-04-19      Monday  13    1 #> 15:     2021-04-20       DE       80+      53  2021-04-20     Tuesday  14    2 #> 16:     2021-04-21       DE       80+      68  2021-04-21   Wednesday  15    2 #> 17:     2021-04-22       DE       80+      56  2021-04-22    Thursday  16    2 #> 18:     2021-04-23       DE       80+      61  2021-04-23      Friday  17    2 #> 19:     2021-04-24       DE       80+      45  2021-04-24    Saturday  18    2 #> 20:     2021-04-25       DE       80+      35  2021-04-25      Sunday  19    2 #> 21:     2021-04-26       DE       80+      17  2021-04-26      Monday  20    2 #> 22:     2021-04-27       DE       80+      50  2021-04-27     Tuesday  21    3 #> 23:     2021-04-28       DE       80+      56  2021-04-28   Wednesday  22    3 #> 24:     2021-04-29       DE       80+      44  2021-04-29    Thursday  23    3 #> 25:     2021-04-30       DE       80+      54  2021-04-30      Friday  24    3 #> 26:     2021-05-01       DE       80+      48  2021-05-01    Saturday  25    3 #> 27:     2021-05-02       DE       80+      27  2021-05-02      Sunday  26    3 #> 28:     2021-05-03       DE       80+      26  2021-05-03      Monday  27    3 #> 29:     2021-05-04       DE       80+      55  2021-05-04     Tuesday  28    4 #> 30:     2021-05-05       DE       80+      59  2021-05-05   Wednesday  29    4 #> 31:     2021-05-06       DE       80+      58  2021-05-06    Thursday  30    4 #> 32:     2021-05-07       DE       80+      48  2021-05-07      Friday  31    4 #> 33:     2021-05-08       DE       80+      34  2021-05-08    Saturday  32    4 #> 34:     2021-05-09       DE       80+      10  2021-05-09      Sunday  33    4 #> 35:     2021-05-10       DE       80+      24  2021-05-10      Monday  34    4 #> 36:     2021-05-11       DE       80+      49  2021-05-11     Tuesday  35    5 #> 37:     2021-05-12       DE       80+      42  2021-05-12   Wednesday  36    5 #> 38:     2021-05-13       DE       80+      39  2021-05-13    Thursday  37    5 #> 39:     2021-05-14       DE       80+      15  2021-05-14      Friday  38    5 #> 40:     2021-05-15       DE       80+      23  2021-05-15    Saturday  39    5 #>     reference_date location age_group confirm report_date day_of_week day week #>     month #>  1:     0 #>  2:     0 #>  3:     0 #>  4:     0 #>  5:     0 #>  6:     0 #>  7:     0 #>  8:     0 #>  9:     0 #> 10:     0 #> 11:     0 #> 12:     0 #> 13:     0 #> 14:     0 #> 15:     0 #> 16:     0 #> 17:     0 #> 18:     0 #> 19:     0 #> 20:     0 #> 21:     0 #> 22:     0 #> 23:     0 #> 24:     0 #> 25:     0 #> 26:     1 #> 27:     1 #> 28:     1 #> 29:     1 #> 30:     1 #> 31:     1 #> 32:     1 #> 33:     1 #> 34:     1 #> 35:     1 #> 36:     1 #> 37:     1 #> 38:     1 #> 39:     1 #> 40:     1 #>     month  # with holidays - n.b.: holidays not found are silently ignored holidaymeta <- enw_add_metaobs_features(   nat_germany_hosp,   datecol = \"report_date\",   holidays = c(     \"2021-04-04\", \"2021-04-05\",     \"2021-05-01\", \"2021-05-13\",     \"2021-05-24\"   ),   holidays_to = \"Holiday\" ) holidaymeta #>     reference_date location age_group confirm report_date day_of_week day week #>  1:     2021-04-06       DE       80+      35  2021-04-06     Tuesday   0    0 #>  2:     2021-04-07       DE       80+      81  2021-04-07   Wednesday   1    0 #>  3:     2021-04-08       DE       80+      85  2021-04-08    Thursday   2    0 #>  4:     2021-04-09       DE       80+      62  2021-04-09      Friday   3    0 #>  5:     2021-04-10       DE       80+      45  2021-04-10    Saturday   4    0 #>  6:     2021-04-11       DE       80+      23  2021-04-11      Sunday   5    0 #>  7:     2021-04-12       DE       80+      33  2021-04-12      Monday   6    0 #>  8:     2021-04-13       DE       80+      66  2021-04-13     Tuesday   7    1 #>  9:     2021-04-14       DE       80+      50  2021-04-14   Wednesday   8    1 #> 10:     2021-04-15       DE       80+      66  2021-04-15    Thursday   9    1 #> 11:     2021-04-16       DE       80+      67  2021-04-16      Friday  10    1 #> 12:     2021-04-17       DE       80+      50  2021-04-17    Saturday  11    1 #> 13:     2021-04-18       DE       80+      33  2021-04-18      Sunday  12    1 #> 14:     2021-04-19       DE       80+      25  2021-04-19      Monday  13    1 #> 15:     2021-04-20       DE       80+      53  2021-04-20     Tuesday  14    2 #> 16:     2021-04-21       DE       80+      68  2021-04-21   Wednesday  15    2 #> 17:     2021-04-22       DE       80+      56  2021-04-22    Thursday  16    2 #> 18:     2021-04-23       DE       80+      61  2021-04-23      Friday  17    2 #> 19:     2021-04-24       DE       80+      45  2021-04-24    Saturday  18    2 #> 20:     2021-04-25       DE       80+      35  2021-04-25      Sunday  19    2 #> 21:     2021-04-26       DE       80+      17  2021-04-26      Monday  20    2 #> 22:     2021-04-27       DE       80+      50  2021-04-27     Tuesday  21    3 #> 23:     2021-04-28       DE       80+      56  2021-04-28   Wednesday  22    3 #> 24:     2021-04-29       DE       80+      44  2021-04-29    Thursday  23    3 #> 25:     2021-04-30       DE       80+      54  2021-04-30      Friday  24    3 #> 26:     2021-05-01       DE       80+      48  2021-05-01     Holiday  25    3 #> 27:     2021-05-02       DE       80+      27  2021-05-02      Sunday  26    3 #> 28:     2021-05-03       DE       80+      26  2021-05-03      Monday  27    3 #> 29:     2021-05-04       DE       80+      55  2021-05-04     Tuesday  28    4 #> 30:     2021-05-05       DE       80+      59  2021-05-05   Wednesday  29    4 #> 31:     2021-05-06       DE       80+      58  2021-05-06    Thursday  30    4 #> 32:     2021-05-07       DE       80+      48  2021-05-07      Friday  31    4 #> 33:     2021-05-08       DE       80+      34  2021-05-08    Saturday  32    4 #> 34:     2021-05-09       DE       80+      10  2021-05-09      Sunday  33    4 #> 35:     2021-05-10       DE       80+      24  2021-05-10      Monday  34    4 #> 36:     2021-05-11       DE       80+      49  2021-05-11     Tuesday  35    5 #> 37:     2021-05-12       DE       80+      42  2021-05-12   Wednesday  36    5 #> 38:     2021-05-13       DE       80+      39  2021-05-13     Holiday  37    5 #> 39:     2021-05-14       DE       80+      15  2021-05-14      Friday  38    5 #> 40:     2021-05-15       DE       80+      23  2021-05-15    Saturday  39    5 #>     reference_date location age_group confirm report_date day_of_week day week #>     month #>  1:     0 #>  2:     0 #>  3:     0 #>  4:     0 #>  5:     0 #>  6:     0 #>  7:     0 #>  8:     0 #>  9:     0 #> 10:     0 #> 11:     0 #> 12:     0 #> 13:     0 #> 14:     0 #> 15:     0 #> 16:     0 #> 17:     0 #> 18:     0 #> 19:     0 #> 20:     0 #> 21:     0 #> 22:     0 #> 23:     0 #> 24:     0 #> 25:     0 #> 26:     1 #> 27:     1 #> 28:     1 #> 29:     1 #> 30:     1 #> 31:     1 #> 32:     1 #> 33:     1 #> 34:     1 #> 35:     1 #> 36:     1 #> 37:     1 #> 38:     1 #> 39:     1 #> 40:     1 #>     month subset(holidaymeta, day_of_week == \"Holiday\") #>    reference_date location age_group confirm report_date day_of_week day week #> 1:     2021-05-01       DE       80+      48  2021-05-01     Holiday  25    3 #> 2:     2021-05-13       DE       80+      39  2021-05-13     Holiday  37    5 #>    month #> 1:     1 #> 2:     1"},{"path":"package.epinowcast.org/dev/reference/enw_add_pooling_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a pooling effect to model design metadata — enw_add_pooling_effect","title":"Add a pooling effect to model design metadata — enw_add_pooling_effect","text":"function adds pooling effect metadata returned enw_effects_metadata(). updating fixed column 0 effects match string argument adding new column var_name 1 effects match string argument 0 otherwise.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_pooling_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a pooling effect to model design metadata — enw_add_pooling_effect","text":"","code":"enw_add_pooling_effect(effects, var_name = \"sd\", finder_fn = startsWith, ...)"},{"path":"package.epinowcast.org/dev/reference/enw_add_pooling_effect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a pooling effect to model design metadata — enw_add_pooling_effect","text":"effects data.table following columns: effects: name effect fixed: logical indicating whether effect fixed (1) random (0). output enw_effects_metadata(). var_name name new column added effects data.table. column 1 effects match string 0 otherwise. Defaults 'sd'. finder_fn function used find effects match string. Defaults startsWith(). can function takes character first argument (effects$effects column) arguments ... returns logical vector indicating whether effects matched. ... Additional arguments finder_fn. E.g. finder_fn = startsWith default, prefix = \"somestring\".","code":""},{"path":"package.epinowcast.org/dev/reference/enw_add_pooling_effect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a pooling effect to model design metadata — enw_add_pooling_effect","text":"data.table following columns: effects: name effect fixed: logical indicating whether effect fixed (1) random (0). Argument supplied var_name: logical indicating whether effect pooled (1) (0).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_add_pooling_effect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a pooling effect to model design metadata — enw_add_pooling_effect","text":"","code":"data <- data.frame(a = 1:3, b = as.character(1:3), c = c(1,1,2)) design <- enw_design(a ~ b + c, data)$design effects <- enw_effects_metadata(design) enw_add_pooling_effect(effects, prefix = \"b\") #>    effects fixed sd #> 1:      b2     0  1 #> 2:      b3     0  1 #> 3:       c     1  0"},{"path":"package.epinowcast.org/dev/reference/enw_aggregate_cumulative.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate observations over a given timestep for both report and reference dates. — enw_aggregate_cumulative","title":"Aggregate observations over a given timestep for both report and reference dates. — enw_aggregate_cumulative","text":"function aggregates observations specified timestep, ensuring alignment day week report reference dates.  useful aggregating data weekly timestep, example may desirable testing using weekly timestep concerned runtime.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_aggregate_cumulative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate observations over a given timestep for both report and reference dates. — enw_aggregate_cumulative","text":"","code":"enw_aggregate_cumulative(obs, timestep = \"day\", by = NULL, copy = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_aggregate_cumulative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate observations over a given timestep for both report and reference dates. — enw_aggregate_cumulative","text":"obs object coercible data.table (data.frame) must new_confirm numeric column, report_date reference_date date columns. input must timestep day complete. See enw_complete_dates() information. NA values present confirm column set zero aggregation may desirable missingness meaningful. timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days. character vector variables also aggregate (.e. well using reference_date report_date). supplied function aggregate just reference_date report_date. copy obs copied (default) modified place?","code":""},{"path":"package.epinowcast.org/dev/reference/enw_aggregate_cumulative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate observations over a given timestep for both report and reference dates. — enw_aggregate_cumulative","text":"data.table aggregated observations.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_aggregate_cumulative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate observations over a given timestep for both report and reference dates. — enw_aggregate_cumulative","text":"","code":"nat_hosp <- germany_covid19_hosp[location == \"DE\"][age_group %in% \"00+\"] enw_aggregate_cumulative(nat_hosp, timestep = \"week\") #>      reference_date location age_group confirm report_date #>   1:     2021-04-13       DE       00+    3808  2021-04-13 #>   2:     2021-04-13       DE       00+    5588  2021-04-20 #>   3:     2021-04-13       DE       00+    6305  2021-04-27 #>   4:     2021-04-13       DE       00+    6705  2021-05-04 #>   5:     2021-04-13       DE       00+    6909  2021-05-11 #>  ---                                                       #> 266:     2021-10-05       DE       00+    2111  2021-10-12 #> 267:     2021-10-05       DE       00+    2317  2021-10-19 #> 268:     2021-10-12       DE       00+    1417  2021-10-12 #> 269:     2021-10-12       DE       00+    2279  2021-10-19 #> 270:     2021-10-19       DE       00+    1773  2021-10-19"},{"path":"package.epinowcast.org/dev/reference/enw_assign_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign a group to each row of a data.table — enw_assign_group","title":"Assign a group to each row of a data.table — enw_assign_group","text":"Assign group row data.table. specified, unique combination columns assigned unique group. specified, rows assigned group.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_assign_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign a group to each row of a data.table — enw_assign_group","text":"","code":"enw_assign_group(obs, by = NULL, copy = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_assign_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign a group to each row of a data.table — enw_assign_group","text":"obs data.table data.frame without .group column. character vector column names group . Defaults empty vector. copy logical; make copy (default) obs modify place?","code":""},{"path":"package.epinowcast.org/dev/reference/enw_assign_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign a group to each row of a data.table — enw_assign_group","text":"data.table .group column added ordered .group existing key obs.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_assign_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign a group to each row of a data.table — enw_assign_group","text":"","code":"obs <- data.frame(x = 1:3, y = 1:3) enw_assign_group(obs) #>    x y .group #> 1: 1 1      1 #> 2: 2 2      1 #> 3: 3 3      1 enw_assign_group(obs, by = \"x\") #>    x y .group #> 1: 1 1      1 #> 2: 2 2      2 #> 3: 3 3      3"},{"path":"package.epinowcast.org/dev/reference/enw_complete_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Complete missing reference and report dates — enw_complete_dates","title":"Complete missing reference and report dates — enw_complete_dates","text":"Ensures reference report dates present groups based maximum minimum dates found data. function may use users preprocessing data. general features may consider using grouping variables covariates need included variable.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_complete_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Complete missing reference and report dates — enw_complete_dates","text":"","code":"enw_complete_dates(   obs,   by = NULL,   max_delay,   timestep = \"day\",   missing_reference = TRUE,   completion_beyond_max_report = FALSE )"},{"path":"package.epinowcast.org/dev/reference/enw_complete_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Complete missing reference and report dates — enw_complete_dates","text":"obs data.frame containing least following variables: reference_date (index date interest), report_date (report date observations), confirm (cumulative observations reference report date). character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling max_delay Numeric defaults 20 needs greater equal 1 integer (internally coerced one using .integer()). maximum number days include delay distribution. Computation scales non-linearly setting consider maximum makes sense data carefully. Note zero indexed includes reference date max_delay - 1 days (.e. max_delay 1 corresponds delay). timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days. missing_reference Logical, entries cases missing reference date completed well?, Default: TRUE completion_beyond_max_report Logical, entries completed beyond maximum date found data? Default: FALSE","code":""},{"path":"package.epinowcast.org/dev/reference/enw_complete_dates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Complete missing reference and report dates — enw_complete_dates","text":"data.table completed entries combinations reference dates, groups possible report dates.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_complete_dates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Complete missing reference and report dates — enw_complete_dates","text":"","code":"obs <- data.frame(   report_date = c(\"2021-10-01\", \"2021-10-03\"), reference_date = \"2021-10-01\",   confirm = 1 ) enw_complete_dates(obs) #>    report_date reference_date confirm #> 1:  2021-10-01           <NA>       0 #> 2:  2021-10-02           <NA>       0 #> 3:  2021-10-03           <NA>       0 #> 4:  2021-10-01     2021-10-01       1 #> 5:  2021-10-02     2021-10-01       1 #> 6:  2021-10-03     2021-10-01       1 #> 7:  2021-10-02     2021-10-02       0 #> 8:  2021-10-03     2021-10-02       0 #> 9:  2021-10-03     2021-10-03       0  # Allow completion beyond the maximum date found in the data enw_complete_dates(obs, completion_beyond_max_report = TRUE, max_delay = 10) #>     report_date reference_date confirm #>  1:  2021-10-01           <NA>       0 #>  2:  2021-10-02           <NA>       0 #>  3:  2021-10-03           <NA>       0 #>  4:  2021-10-01     2021-10-01       1 #>  5:  2021-10-02     2021-10-01       1 #>  6:  2021-10-03     2021-10-01       1 #>  7:  2021-10-04     2021-10-01       1 #>  8:  2021-10-05     2021-10-01       1 #>  9:  2021-10-06     2021-10-01       1 #> 10:  2021-10-07     2021-10-01       1 #> 11:  2021-10-08     2021-10-01       1 #> 12:  2021-10-09     2021-10-01       1 #> 13:  2021-10-10     2021-10-01       1 #> 14:  2021-10-11     2021-10-01       1 #> 15:  2021-10-02     2021-10-02       0 #> 16:  2021-10-03     2021-10-02       0 #> 17:  2021-10-04     2021-10-02       0 #> 18:  2021-10-05     2021-10-02       0 #> 19:  2021-10-06     2021-10-02       0 #> 20:  2021-10-07     2021-10-02       0 #> 21:  2021-10-08     2021-10-02       0 #> 22:  2021-10-09     2021-10-02       0 #> 23:  2021-10-10     2021-10-02       0 #> 24:  2021-10-11     2021-10-02       0 #> 25:  2021-10-12     2021-10-02       0 #> 26:  2021-10-03     2021-10-03       0 #> 27:  2021-10-04     2021-10-03       0 #> 28:  2021-10-05     2021-10-03       0 #> 29:  2021-10-06     2021-10-03       0 #> 30:  2021-10-07     2021-10-03       0 #> 31:  2021-10-08     2021-10-03       0 #> 32:  2021-10-09     2021-10-03       0 #> 33:  2021-10-10     2021-10-03       0 #> 34:  2021-10-11     2021-10-03       0 #> 35:  2021-10-12     2021-10-03       0 #> 36:  2021-10-13     2021-10-03       0 #>     report_date reference_date confirm"},{"path":"package.epinowcast.org/dev/reference/enw_construct_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct preprocessed data — enw_construct_data","title":"Construct preprocessed data — enw_construct_data","text":"function used internally enw_preprocess_data() combine various pieces processed observed data single object. exposed user order allow modular data preprocessing though currently recommended. See documentation code enw_preprocess_data() expected inputs.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_construct_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct preprocessed data — enw_construct_data","text":"","code":"enw_construct_data(   obs,   new_confirm,   latest,   missing_reference,   reporting_triangle,   metareport,   metareference,   metadelay,   by,   max_delay,   timestep )"},{"path":"package.epinowcast.org/dev/reference/enw_construct_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct preprocessed data — enw_construct_data","text":"obs Observations addition empirical reporting proportions restricted specified maximum delay. new_confirm Incidence notifications reference report date. Empirical reporting distributions also added. latest latest available observations. missing_reference data.frame reported observations missing reference date. reporting_triangle Incident observations report reference date standard reporting triangle matrix format. metareport Metadata report dates. metareference Metadata reference dates derived observations. metadelay Metadata reporting delays produced using enw_delay_metadata(). character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling max_delay Numeric defaults 20 needs greater equal 1 integer (internally coerced one using .integer()). maximum number days include delay distribution. Computation scales non-linearly setting consider maximum makes sense data carefully. Note zero indexed includes reference date max_delay - 1 days (.e. max_delay 1 corresponds delay). timestep timestep used process model (.e. reference date model). can string (\"day\", \"week\", \"month\") numeric whole number representing number days. data timestep may wish make use enw_aggregate_cumulative() aggregate data desired timestep.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_construct_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct preprocessed data — enw_construct_data","text":"data.table containing processed observations series nested data.frames well variables containing metadata. : obs: (observations addition empirical reporting proportions restricted specified maximum delay). new_confirm: Incidence notifications reference report date. Empirical reporting distributions also added. latest: latest available observations. missing_reference: Observations missing reference dates. reporting_triangle: Incident observations report reference date standard reporting triangle matrix format. metareference: Metadata reference dates derived observations. metrareport: Metadata report dates. metadelay: Metadata reporting delays produced using enw_delay_metadata(). time: Numeric, number timepoints data. snapshots: Numeric, number available data snapshots use nowcasting. groups: Numeric, Number groups/strata supplied observations (set using ). max_delay: Numeric, maximum delay processed data max_date: maximum available report date.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_construct_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct preprocessed data — enw_construct_data","text":"","code":"pobs <- enw_example(\"preprocessed\") enw_construct_data(   obs = pobs$obs[[1]],   new_confirm = pobs$new_confirm[[1]],   latest = pobs$latest[[1]],   missing_reference = pobs$missing_reference[[1]],   reporting_triangle = pobs$reporting_triangle[[1]],   metareport = pobs$metareport[[1]],   metareference = pobs$metareference[[1]],   metadelay = enw_delay_metadata(max_delay = 20),   by = c(),   max_delay = pobs$max_delay[[1]],   timestep = pobs$timestep[[1]] ) #>                    obs          new_confirm              latest #> 1: <data.table[671x9]> <data.table[630x11]> <data.table[41x10]> #>     missing_reference  reporting_triangle      metareference #> 1: <data.table[41x6]> <data.table[41x22]> <data.table[41x9]> #>             metareport          metadelay time snapshots by groups max_delay #> 1: <data.table[60x12]> <data.table[20x4]>   41        41         1        20 #>      max_date timestep #> 1: 2021-08-22      day"},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_cumulative_to_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate incidence of new reports from cumulative reports — enw_cumulative_to_incidence","text":"","code":"enw_cumulative_to_incidence(obs, set_negatives_to_zero = TRUE, by = NULL)"},{"path":"package.epinowcast.org/dev/reference/enw_cumulative_to_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate incidence of new reports from cumulative reports — enw_cumulative_to_incidence","text":"obs data.frame containing least following variables: reference date (index date interest), report_date (report date observations), confirm (cumulative observations reference report date). set_negatives_to_zero Logical, defaults TRUE. negative counts (calculated incidence observations) set zero. Currently downstream modelling support negative counts setting must TRUE intending use epinowcast(). character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling","code":""},{"path":"package.epinowcast.org/dev/reference/enw_cumulative_to_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate incidence of new reports from cumulative reports — enw_cumulative_to_incidence","text":"input data.frame new variable new_confirm. max_confirm present data.frame proportion reported day (prop_reported) also added.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_cumulative_to_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate incidence of new reports from cumulative reports — enw_cumulative_to_incidence","text":"","code":"# Default reconstruct incidence dt <- germany_covid19_hosp[location == \"DE\"][age_group == \"00+\"] enw_add_incidence(dt) #>        reference_date location age_group confirm report_date new_confirm delay #>     1:     2021-04-06       DE       00+     149  2021-04-06         149     0 #>     2:     2021-04-06       DE       00+     289  2021-04-07         140     1 #>     3:     2021-04-06       DE       00+     350  2021-04-08          61     2 #>     4:     2021-04-06       DE       00+     402  2021-04-09          52     3 #>     5:     2021-04-06       DE       00+     438  2021-04-10          36     4 #>    ---                                                                         #> 12911:     2021-10-18       DE       00+     113  2021-10-19          70     1 #> 12912:     2021-10-18       DE       00+     142  2021-10-20          29     2 #> 12913:     2021-10-19       DE       00+     223  2021-10-19         223     0 #> 12914:     2021-10-19       DE       00+     387  2021-10-20         164     1 #> 12915:     2021-10-20       DE       00+     235  2021-10-20         235     0  # Make use of maximum reported to calculate empirical daily reporting dt <- enw_add_max_reported(dt) enw_add_incidence(dt) #>        reference_date .group max_confirm location age_group confirm report_date #>     1:     2021-04-06      1         708       DE       00+     149  2021-04-06 #>     2:     2021-04-06      1         708       DE       00+     289  2021-04-07 #>     3:     2021-04-06      1         708       DE       00+     350  2021-04-08 #>     4:     2021-04-06      1         708       DE       00+     402  2021-04-09 #>     5:     2021-04-06      1         708       DE       00+     438  2021-04-10 #>    ---                                                                          #> 12911:     2021-10-18      1         142       DE       00+     113  2021-10-19 #> 12912:     2021-10-18      1         142       DE       00+     142  2021-10-20 #> 12913:     2021-10-19      1         387       DE       00+     223  2021-10-19 #> 12914:     2021-10-19      1         387       DE       00+     387  2021-10-20 #> 12915:     2021-10-20      1         235       DE       00+     235  2021-10-20 #>        cum_prop_reported new_confirm delay prop_reported #>     1:         0.2104520         149     0    0.21045198 #>     2:         0.4081921         140     1    0.19774011 #>     3:         0.4943503          61     2    0.08615819 #>     4:         0.5677966          52     3    0.07344633 #>     5:         0.6186441          36     4    0.05084746 #>    ---                                                   #> 12911:         0.7957746          70     1    0.49295775 #> 12912:         1.0000000          29     2    0.20422535 #> 12913:         0.5762274         223     0    0.57622739 #> 12914:         1.0000000         164     1    0.42377261 #> 12915:         1.0000000         235     0    1.00000000"},{"path":"package.epinowcast.org/dev/reference/enw_delay_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter observations to restrict the maximum reporting delay — enw_delay_filter","title":"Filter observations to restrict the maximum reporting delay — enw_delay_filter","text":"Filter observations restrict maximum reporting delay","code":""},{"path":"package.epinowcast.org/dev/reference/enw_delay_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter observations to restrict the maximum reporting delay — enw_delay_filter","text":"","code":"enw_delay_filter(obs, max_delay, timestep = \"day\")"},{"path":"package.epinowcast.org/dev/reference/enw_delay_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter observations to restrict the maximum reporting delay — enw_delay_filter","text":"obs data.frame containing least following variables: reference date (index date interest), report_date (report date observations), confirm (cumulative observations reference report date). max_delay Numeric defaults 20 needs greater equal 1 integer (internally coerced one using .integer()). maximum number days include delay distribution. Computation scales non-linearly setting consider maximum makes sense data carefully. Note zero indexed includes reference date max_delay - 1 days (.e. max_delay 1 corresponds delay). timestep timestep used process model (.e. reference date model). can string (\"day\", \"week\", \"month\") numeric whole number representing number days. data timestep may wish make use enw_aggregate_cumulative() aggregate data desired timestep.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_delay_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter observations to restrict the maximum reporting delay — enw_delay_filter","text":"data.frame filtered dates report less equal reference date plus maximum delay.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_delay_filter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter observations to restrict the maximum reporting delay — enw_delay_filter","text":"","code":"obs <- enw_example(\"preprocessed\")$obs[[1]] enw_delay_filter(obs, max_delay = 2) #>      reference_date .group report_date max_confirm location age_group confirm #>   1:           <NA>      1  2021-07-13           0       DE       00+       0 #>   2:           <NA>      1  2021-07-14           0       DE       00+       0 #>   3:           <NA>      1  2021-07-15           0       DE       00+       0 #>   4:           <NA>      1  2021-07-16           0       DE       00+       0 #>   5:           <NA>      1  2021-07-17           0       DE       00+       0 #>  ---                                                                          #> 118:     2021-08-20      1  2021-08-20         171       DE       00+      98 #> 119:     2021-08-20      1  2021-08-21         171       DE       00+     159 #> 120:     2021-08-21      1  2021-08-21         112       DE       00+      69 #> 121:     2021-08-21      1  2021-08-22         112       DE       00+     112 #> 122:     2021-08-22      1  2021-08-22          45       DE       00+      45 #>      cum_prop_reported delay #>   1:               NaN    NA #>   2:               NaN    NA #>   3:               NaN    NA #>   4:               NaN    NA #>   5:               NaN    NA #>  ---                         #> 118:         0.5730994     0 #> 119:         0.9298246     1 #> 120:         0.6160714     0 #> 121:         1.0000000     1 #> 122:         1.0000000     0"},{"path":"package.epinowcast.org/dev/reference/enw_delay_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate reporting delay metadata — enw_delay_metadata","title":"Calculate reporting delay metadata — enw_delay_metadata","text":"Calculate delay metadata based supplied maximum delay independent metadata date indexing. data meant used conjunction metadata date reference. Users can build additional features  data.frame  regenerate using function output enw_preprocess_data().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_delay_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate reporting delay metadata — enw_delay_metadata","text":"","code":"enw_delay_metadata(max_delay = 20, breaks = 4, timestep = \"day\")"},{"path":"package.epinowcast.org/dev/reference/enw_delay_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate reporting delay metadata — enw_delay_metadata","text":"max_delay Numeric defaults 20 needs greater equal 1 integer (internally coerced one using .integer()). maximum number days include delay distribution. Computation scales non-linearly setting consider maximum makes sense data carefully. Note zero indexed includes reference date max_delay - 1 days (.e. max_delay 1 corresponds delay). breaks Numeric, defaults 4. number breaks use constructing categorised version numeric delays. timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_delay_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate reporting delay metadata — enw_delay_metadata","text":" data.frame  delay metadata. includes: delay: numeric delay reference date report. delay_cat: categorised delay. may useful model building. delay_week: numeric week since delay reported. may useful model building. delay_tail: logical variable defining delay upper 75% potential delays. may particularly useful building models assume parametric distribution order increase weight tail reporting distribution pragmatic way.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_delay_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate reporting delay metadata — enw_delay_metadata","text":"","code":"enw_delay_metadata(20, breaks = 4) #>     delay delay_cat delay_week delay_tail #>  1:     0     [0,5)          0      FALSE #>  2:     1     [0,5)          0      FALSE #>  3:     2     [0,5)          0      FALSE #>  4:     3     [0,5)          0      FALSE #>  5:     4     [0,5)          0      FALSE #>  6:     5    [5,10)          0      FALSE #>  7:     6    [5,10)          0      FALSE #>  8:     7    [5,10)          1      FALSE #>  9:     8    [5,10)          1      FALSE #> 10:     9    [5,10)          1      FALSE #> 11:    10   [10,15)          1      FALSE #> 12:    11   [10,15)          1      FALSE #> 13:    12   [10,15)          1      FALSE #> 14:    13   [10,15)          1      FALSE #> 15:    14   [10,15)          2      FALSE #> 16:    15   [15,20)          2       TRUE #> 17:    16   [15,20)          2       TRUE #> 18:    17   [15,20)          2       TRUE #> 19:    18   [15,20)          2       TRUE #> 20:    19   [15,20)          2       TRUE"},{"path":"package.epinowcast.org/dev/reference/enw_design.html","id":null,"dir":"Reference","previous_headings":"","what":"A helper function to construct a design matrix from a formula — enw_design","title":"A helper function to construct a design matrix from a formula — enw_design","text":"function wrapper around stats::model.matrix() can optionally return sparse design matrix defined unique number rows design matrix index vector allows full design matrix reconstructed. useful models many repeated rows design matrix computationally expensive fit. function also allows specification contrasts categorical variables.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A helper function to construct a design matrix from a formula — enw_design","text":"","code":"enw_design(formula, data, no_contrasts = FALSE, sparse = TRUE, ...)"},{"path":"package.epinowcast.org/dev/reference/enw_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A helper function to construct a design matrix from a formula — enw_design","text":"formula R formula. data data.frame containing variables formula. no_contrasts vector variable names converted contrasts. no_contrasts = FALSE categorical variables use contrasts. no_contrasts = TRUE categorical variables use contrasts. sparse Logical, TRUE return sparse design matrix. Defaults TRUE. ... Arguments passed stats::model.matrix object object appropriate class.  default     method, model formula terms object.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A helper function to construct a design matrix from a formula — enw_design","text":"list containing formula, design matrix, index.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A helper function to construct a design matrix from a formula — enw_design","text":"","code":"data <- data.frame(a = 1:3, b = as.character(1:3), c = c(1,1,2)) enw_design(a ~ b + c, data) #> $formula #> [1] \"a ~ b + c\" #>  #> $design #>   (Intercept) b2 b3 c #> 1           1  0  0 1 #> 2           1  1  0 1 #> 3           1  0  1 2 #>  #> $index #> [1] 1 2 3 #>  enw_design(a ~ b + c, data, no_contrasts = TRUE) #> $formula #> [1] \"a ~ b + c\" #>  #> $design #>   (Intercept) b1 b2 b3 c #> 1           1  1  0  0 1 #> 2           1  0  1  0 1 #> 3           1  0  0  1 2 #>  #> $index #> [1] 1 2 3 #>  enw_design(a ~ b + c, data, no_contrasts = c(\"b\")) #> $formula #> [1] \"a ~ b + c\" #>  #> $design #>   (Intercept) b1 b2 b3 c #> 1           1  1  0  0 1 #> 2           1  0  1  0 1 #> 3           1  0  0  1 2 #>  #> $index #> [1] 1 2 3 #>  enw_design(a ~ c, data, sparse = TRUE) #> $formula #> [1] \"a ~ c\" #>  #> $design #>   (Intercept) c #> 1           1 1 #> 3           1 2 #>  #> $index #> [1] 1 1 2 #>  enw_design(a ~ c, data, sparse = FALSE) #> $formula #> [1] \"a ~ c\" #>  #> $design #>   (Intercept) c #> 1           1 1 #> 2           1 1 #> 3           1 2 #> attr(,\"assign\") #> [1] 0 1 #>  #> $index #> [1] 1 2 3 #>"},{"path":"package.epinowcast.org/dev/reference/enw_effects_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts metadata from a design matrix — enw_effects_metadata","title":"Extracts metadata from a design matrix — enw_effects_metadata","text":"function extracts metadata design matrix returns data.table following columns: effects: name effect fixed: logical indicating whether effect fixed (1) random (0). automatically drops intercept (defined \"(Intercept)\"). function useful constructing model design object random effects used combination ewn_add_pooling_effect.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_effects_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts metadata from a design matrix — enw_effects_metadata","text":"","code":"enw_effects_metadata(design)"},{"path":"package.epinowcast.org/dev/reference/enw_effects_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts metadata from a design matrix — enw_effects_metadata","text":"design design matrix returned stats::model.matrix().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_effects_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts metadata from a design matrix — enw_effects_metadata","text":"data.table following columns: effects: name effect fixed: logical indicating whether effect fixed (1) random (0)","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_effects_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracts metadata from a design matrix — enw_effects_metadata","text":"","code":"data <- data.frame(a = 1:3, b = as.character(1:3), c = c(1,1,2)) design <- enw_design(a ~ b + c, data)$design enw_effects_metadata(design) #>    effects fixed #> 1:      b2     1 #> 2:      b3     1 #> 3:       c     1"},{"path":"package.epinowcast.org/dev/reference/enw_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a package example — enw_example","title":"Load a package example — enw_example","text":"Loads examples nowcasts produce using example scripts. Used streamline examples, package tests enable users explore package functionality without needing install cmdstanr.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a package example — enw_example","text":"","code":"enw_example(   type = c(\"nowcast\", \"preprocessed_observations\", \"observations\", \"script\") )"},{"path":"package.epinowcast.org/dev/reference/enw_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a package example — enw_example","text":"type character string indicating example load. Supported options \"nowcast\", epinowcast() applied germany_covid19_hosp \"preprocessed_observations\", enw_preprocess_data() applied germany_covid19_hosp \"observations\", enw_latest_data() applied germany_covid19_hosp \"script\", code used generate examples.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a package example — enw_example","text":"Depending type, data.table requested output file name(s) generate outputs (type = \"script\")","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a package example — enw_example","text":"","code":"# Load the nowcast enw_example(type = \"nowcast\") #>                    obs          new_confirm              latest #> 1: <data.table[671x9]> <data.table[630x11]> <data.table[41x10]> #>     missing_reference  reporting_triangle      metareference #> 1: <data.table[41x6]> <data.table[41x22]> <data.table[41x9]> #>             metareport          metadelay time snapshots by groups max_delay #> 1: <data.table[60x12]> <data.table[20x4]>   41        41         1        20 #>      max_date timestep               fit       data  fit_args samples max_rhat #> 1: 2021-08-22      day <CmdStanMCMC[42]> <list[99]> <list[6]>    1000     1.02 #>    divergent_transitions per_divergent_transitions max_treedepth #> 1:                     0                         0             8 #>    no_at_max_treedepth per_at_max_treedepth run_time #> 1:                  20                 0.02     61.3  # Load the preprocessed observations enw_example(type = \"preprocessed_observations\") #>                    obs          new_confirm              latest #> 1: <data.table[671x9]> <data.table[630x11]> <data.table[41x10]> #>     missing_reference  reporting_triangle      metareference #> 1: <data.table[41x6]> <data.table[41x22]> <data.table[41x9]> #>             metareport          metadelay time snapshots by groups max_delay #> 1: <data.table[60x12]> <data.table[20x4]>   41        41         1        20 #>      max_date timestep #> 1: 2021-08-22      day  # Load the latest observations enw_example(type = \"observations\") #>     reference_date location age_group report_date confirm #>  1:     2021-08-02       DE       00+  2021-10-01      59 #>  2:     2021-08-03       DE       00+  2021-10-01     156 #>  3:     2021-08-04       DE       00+  2021-10-01     183 #>  4:     2021-08-05       DE       00+  2021-10-01     147 #>  5:     2021-08-06       DE       00+  2021-10-01     155 #>  6:     2021-08-07       DE       00+  2021-10-01     159 #>  7:     2021-08-08       DE       00+  2021-10-01     119 #>  8:     2021-08-09       DE       00+  2021-10-01      65 #>  9:     2021-08-10       DE       00+  2021-10-01     204 #> 10:     2021-08-11       DE       00+  2021-10-01     275 #> 11:     2021-08-12       DE       00+  2021-10-01     273 #> 12:     2021-08-13       DE       00+  2021-10-01     270 #> 13:     2021-08-14       DE       00+  2021-10-01     262 #> 14:     2021-08-15       DE       00+  2021-10-01     192 #> 15:     2021-08-16       DE       00+  2021-10-01     140 #> 16:     2021-08-17       DE       00+  2021-10-01     323 #> 17:     2021-08-18       DE       00+  2021-10-01     409 #> 18:     2021-08-19       DE       00+  2021-10-01     370 #> 19:     2021-08-20       DE       00+  2021-10-01     361 #> 20:     2021-08-21       DE       00+  2021-10-01     339 #> 21:     2021-08-22       DE       00+  2021-10-01     258 #>     reference_date location age_group report_date confirm  # Load the script used to generate these examples # Optionally source this script to regenerate the example readLines(enw_example(type = \"script\")) #>  [1] \"# Load epinowcast and data.table\"                                                     #>  [2] \"library(epinowcast)\"                                                                  #>  [3] \"library(data.table)\"                                                                  #>  [4] \"\"                                                                                     #>  [5] \"# Load and filter germany hospitalisations\"                                           #>  [6] \"nat_germany_hosp <- germany_covid19_hosp[location == \\\"DE\\\"][age_group %in% \\\"00+\\\"]\" #>  [7] \"nat_germany_hosp <- enw_filter_report_dates(\"                                         #>  [8] \"  nat_germany_hosp,\"                                                                  #>  [9] \"  latest_date = \\\"2021-10-01\\\"\"                                                       #> [10] \")\"                                                                                    #> [11] \"\"                                                                                     #> [12] \"# Make sure observations are complete\"                                                #> [13] \"nat_germany_hosp <- enw_complete_dates(\"                                              #> [14] \"  nat_germany_hosp,\"                                                                  #> [15] \"  by = c(\\\"location\\\", \\\"age_group\\\")\"                                                #> [16] \")\"                                                                                    #> [17] \"\"                                                                                     #> [18] \"# Make a retrospective dataset\"                                                       #> [19] \"retro_nat_germany <- enw_filter_report_dates(\"                                        #> [20] \"  nat_germany_hosp,\"                                                                  #> [21] \"  remove_days = 40\"                                                                   #> [22] \")\"                                                                                    #> [23] \"retro_nat_germany <- enw_filter_reference_dates(\"                                     #> [24] \"  retro_nat_germany,\"                                                                 #> [25] \"  include_days = 40\"                                                                  #> [26] \")\"                                                                                    #> [27] \"\"                                                                                     #> [28] \"# Get latest observations for the same time period\"                                   #> [29] \"latest_obs <- enw_latest_data(nat_germany_hosp)\"                                      #> [30] \"latest_obs <- enw_filter_reference_dates(\"                                            #> [31] \"  latest_obs,\"                                                                        #> [32] \"  remove_days = 40, include_days = 20\"                                                #> [33] \")\"                                                                                    #> [34] \"\"                                                                                     #> [35] \"# Preprocess observations\"                                                            #> [36] \"pobs <- enw_preprocess_data(retro_nat_germany, max_delay = 20)\"                       #> [37] \"\"                                                                                     #> [38] \"# Reference date model\"                                                               #> [39] \"reference_module <- enw_reference(~1, data = pobs)\"                                   #> [40] \"\"                                                                                     #> [41] \"# Report date model\"                                                                  #> [42] \"report_module <- enw_report(~ (1 | day_of_week), data = pobs)\"                        #> [43] \"\"                                                                                     #> [44] \"# Compile nowcasting model using multi-threading\"                                     #> [45] \"model <- enw_model(threads = TRUE)\"                                                   #> [46] \"\"                                                                                     #> [47] \"# Fit nowcast model and produce a nowcast\"                                            #> [48] \"# Note that we have reduced samples for this example to reduce runtimes\"              #> [49] \"nowcast <- epinowcast(pobs,\"                                                          #> [50] \"  reference = reference_module,\"                                                      #> [51] \"  report = report_module,\"                                                            #> [52] \"  fit = enw_fit_opts(\"                                                                #> [53] \"    save_warmup = FALSE, pp = TRUE,\"                                                  #> [54] \"    chains = 2, threads_per_chain = 2,\"                                               #> [55] \"    iter_warmup = 500, iter_sampling = 500\"                                           #> [56] \"  ),\"                                                                                 #> [57] \"  model = model\"                                                                      #> [58] \")\""},{"path":"package.epinowcast.org/dev/reference/enw_expectation.html","id":null,"dir":"Reference","previous_headings":"","what":"Expectation model module — enw_expectation","title":"Expectation model module — enw_expectation","text":"Expectation model module","code":""},{"path":"package.epinowcast.org/dev/reference/enw_expectation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expectation model module — enw_expectation","text":"","code":"enw_expectation(   r = ~0 + (1 | day:.group),   generation_time = 1,   observation = ~1,   latent_reporting_delay = 1,   data,   ... )"},{"path":"package.epinowcast.org/dev/reference/enw_expectation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expectation model module — enw_expectation","text":"r formula (implemented enw_formula()) describing generative process used expected incidence. can use features defined reference date defined metareference produced enw_preprocess_data(). default set use daily random effect group. parameterisation highly flexible may appropriate choice data sparsely reported reporting delays substantially. settings alternative group specific weekly random walk (specified rw(week, = .group). generation_time numeric vector sums 1 defaults 1. Describes weighting apply previous generations (.e part renewal equation). set 1 (default) corresponds modelling daily growth rate. observation formula (implemented enw_formula()) describing modifiers used adjust expected observations. can use features defined reference date defined metareference produced enw_preprocess_data(). default modifiers used common choice might adjust day week. Note baseline modification intercept always used set 0. latent_reporting_delay numeric vector defaults 1. Describes weighting apply past current latent expected observations (recent least). can used convolve based assumed reporting delay rescale observations (multiplying probability mass function fraction) account ascertainment etc. list PMFs can provided allow time-varying PMFs. length modelled time period plus length generation time supplied. data Output enw_preprocess_data(). ... Additional parameters passed enw_add_metaobs_features(). arguments passed enw_preprocess_data() used .","code":""},{"path":"package.epinowcast.org/dev/reference/enw_expectation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expectation model module — enw_expectation","text":"list containing supplied formulas, data passed list describing models, data.frame describing priors used, function takes output data priors returns function can used sample tightened version prior distribution.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_expectation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expectation model module — enw_expectation","text":"","code":"enw_expectation(data = enw_example(\"preprocessed\")) #> A random effect using .group is not possible as this variable has fewer than 2 unique values. #> $formula #> $formula$r #> [1] \"~0 + (1 | day:.group)\" #>  #> $formula$observation #> [1] \"~1\" #>  #>  #> $data_raw #> $data_raw$r #>           date .group location age_group delay day_of_week day week month #>  1: 2021-07-14      1       DE       00+     0   Wednesday   1    0     0 #>  2: 2021-07-15      1       DE       00+     0    Thursday   2    0     0 #>  3: 2021-07-16      1       DE       00+     0      Friday   3    0     0 #>  4: 2021-07-17      1       DE       00+     0    Saturday   4    0     0 #>  5: 2021-07-18      1       DE       00+     0      Sunday   5    0     0 #>  6: 2021-07-19      1       DE       00+     0      Monday   6    0     0 #>  7: 2021-07-20      1       DE       00+     0     Tuesday   7    1     0 #>  8: 2021-07-21      1       DE       00+     0   Wednesday   8    1     0 #>  9: 2021-07-22      1       DE       00+     0    Thursday   9    1     0 #> 10: 2021-07-23      1       DE       00+     0      Friday  10    1     0 #> 11: 2021-07-24      1       DE       00+     0    Saturday  11    1     0 #> 12: 2021-07-25      1       DE       00+     0      Sunday  12    1     0 #> 13: 2021-07-26      1       DE       00+     0      Monday  13    1     0 #> 14: 2021-07-27      1       DE       00+     0     Tuesday  14    2     0 #> 15: 2021-07-28      1       DE       00+     0   Wednesday  15    2     0 #> 16: 2021-07-29      1       DE       00+     0    Thursday  16    2     0 #> 17: 2021-07-30      1       DE       00+     0      Friday  17    2     0 #> 18: 2021-07-31      1       DE       00+     0    Saturday  18    2     0 #> 19: 2021-08-01      1       DE       00+     0      Sunday  19    2     1 #> 20: 2021-08-02      1       DE       00+     0      Monday  20    2     1 #> 21: 2021-08-03      1       DE       00+     0     Tuesday  21    3     1 #> 22: 2021-08-04      1       DE       00+     0   Wednesday  22    3     1 #> 23: 2021-08-05      1       DE       00+     0    Thursday  23    3     1 #> 24: 2021-08-06      1       DE       00+     0      Friday  24    3     1 #> 25: 2021-08-07      1       DE       00+     0    Saturday  25    3     1 #> 26: 2021-08-08      1       DE       00+     0      Sunday  26    3     1 #> 27: 2021-08-09      1       DE       00+     0      Monday  27    3     1 #> 28: 2021-08-10      1       DE       00+     0     Tuesday  28    4     1 #> 29: 2021-08-11      1       DE       00+     0   Wednesday  29    4     1 #> 30: 2021-08-12      1       DE       00+     0    Thursday  30    4     1 #> 31: 2021-08-13      1       DE       00+     0      Friday  31    4     1 #> 32: 2021-08-14      1       DE       00+     0    Saturday  32    4     1 #> 33: 2021-08-15      1       DE       00+     0      Sunday  33    4     1 #> 34: 2021-08-16      1       DE       00+     0      Monday  34    4     1 #> 35: 2021-08-17      1       DE       00+     0     Tuesday  35    5     1 #> 36: 2021-08-18      1       DE       00+     0   Wednesday  36    5     1 #> 37: 2021-08-19      1       DE       00+     0    Thursday  37    5     1 #> 38: 2021-08-20      1       DE       00+     0      Friday  38    5     1 #> 39: 2021-08-21      1       DE       00+     0    Saturday  39    5     1 #> 40: 2021-08-22      1       DE       00+     0      Sunday  40    5     1 #>           date .group location age_group delay day_of_week day week month #>  #> $data_raw$observation #>           date .group location age_group delay day_of_week day week month #>  1: 2021-07-13      1       DE       00+     0     Tuesday   0    0     0 #>  2: 2021-07-14      1       DE       00+     0   Wednesday   1    0     0 #>  3: 2021-07-15      1       DE       00+     0    Thursday   2    0     0 #>  4: 2021-07-16      1       DE       00+     0      Friday   3    0     0 #>  5: 2021-07-17      1       DE       00+     0    Saturday   4    0     0 #>  6: 2021-07-18      1       DE       00+     0      Sunday   5    0     0 #>  7: 2021-07-19      1       DE       00+     0      Monday   6    0     0 #>  8: 2021-07-20      1       DE       00+     0     Tuesday   7    1     0 #>  9: 2021-07-21      1       DE       00+     0   Wednesday   8    1     0 #> 10: 2021-07-22      1       DE       00+     0    Thursday   9    1     0 #> 11: 2021-07-23      1       DE       00+     0      Friday  10    1     0 #> 12: 2021-07-24      1       DE       00+     0    Saturday  11    1     0 #> 13: 2021-07-25      1       DE       00+     0      Sunday  12    1     0 #> 14: 2021-07-26      1       DE       00+     0      Monday  13    1     0 #> 15: 2021-07-27      1       DE       00+     0     Tuesday  14    2     0 #> 16: 2021-07-28      1       DE       00+     0   Wednesday  15    2     0 #> 17: 2021-07-29      1       DE       00+     0    Thursday  16    2     0 #> 18: 2021-07-30      1       DE       00+     0      Friday  17    2     0 #> 19: 2021-07-31      1       DE       00+     0    Saturday  18    2     0 #> 20: 2021-08-01      1       DE       00+     0      Sunday  19    2     1 #> 21: 2021-08-02      1       DE       00+     0      Monday  20    2     1 #> 22: 2021-08-03      1       DE       00+     0     Tuesday  21    3     1 #> 23: 2021-08-04      1       DE       00+     0   Wednesday  22    3     1 #> 24: 2021-08-05      1       DE       00+     0    Thursday  23    3     1 #> 25: 2021-08-06      1       DE       00+     0      Friday  24    3     1 #> 26: 2021-08-07      1       DE       00+     0    Saturday  25    3     1 #> 27: 2021-08-08      1       DE       00+     0      Sunday  26    3     1 #> 28: 2021-08-09      1       DE       00+     0      Monday  27    3     1 #> 29: 2021-08-10      1       DE       00+     0     Tuesday  28    4     1 #> 30: 2021-08-11      1       DE       00+     0   Wednesday  29    4     1 #> 31: 2021-08-12      1       DE       00+     0    Thursday  30    4     1 #> 32: 2021-08-13      1       DE       00+     0      Friday  31    4     1 #> 33: 2021-08-14      1       DE       00+     0    Saturday  32    4     1 #> 34: 2021-08-15      1       DE       00+     0      Sunday  33    4     1 #> 35: 2021-08-16      1       DE       00+     0      Monday  34    4     1 #> 36: 2021-08-17      1       DE       00+     0     Tuesday  35    5     1 #> 37: 2021-08-18      1       DE       00+     0   Wednesday  36    5     1 #> 38: 2021-08-19      1       DE       00+     0    Thursday  37    5     1 #> 39: 2021-08-20      1       DE       00+     0      Friday  38    5     1 #> 40: 2021-08-21      1       DE       00+     0    Saturday  39    5     1 #> 41: 2021-08-22      1       DE       00+     0      Sunday  40    5     1 #>           date .group location age_group delay day_of_week day week month #>  #>  #> $data #> $data$expr_r_seed #> [1] 1 #>  #> $data$expr_gt_n #> [1] 1 #>  #> $data$expr_lrgt #> [1] 0 #>  #> $data$expr_t #> [1] 40 #>  #> $data$expr_obs #> [1] 0 #>  #> $data$expr_g #> [1] 0 #>  #> $data$expr_ft #> [1] 41 #>  #> $data$expr_fdesign #>    day1 day2 day3 day4 day5 day6 day7 day8 day9 day10 day11 day12 day13 day14 #> 1     1    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 2     0    1    0    0    0    0    0    0    0     0     0     0     0     0 #> 3     0    0    1    0    0    0    0    0    0     0     0     0     0     0 #> 4     0    0    0    1    0    0    0    0    0     0     0     0     0     0 #> 5     0    0    0    0    1    0    0    0    0     0     0     0     0     0 #> 6     0    0    0    0    0    1    0    0    0     0     0     0     0     0 #> 7     0    0    0    0    0    0    1    0    0     0     0     0     0     0 #> 8     0    0    0    0    0    0    0    1    0     0     0     0     0     0 #> 9     0    0    0    0    0    0    0    0    1     0     0     0     0     0 #> 10    0    0    0    0    0    0    0    0    0     1     0     0     0     0 #> 11    0    0    0    0    0    0    0    0    0     0     1     0     0     0 #> 12    0    0    0    0    0    0    0    0    0     0     0     1     0     0 #> 13    0    0    0    0    0    0    0    0    0     0     0     0     1     0 #> 14    0    0    0    0    0    0    0    0    0     0     0     0     0     1 #> 15    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 16    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 17    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 18    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 19    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 20    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 21    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 22    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 23    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 24    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 25    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 26    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 27    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 28    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 29    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 30    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 31    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 32    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 33    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 34    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 35    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 36    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 37    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 38    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 39    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #> 40    0    0    0    0    0    0    0    0    0     0     0     0     0     0 #>    day15 day16 day17 day18 day19 day20 day21 day22 day23 day24 day25 day26 #> 1      0     0     0     0     0     0     0     0     0     0     0     0 #> 2      0     0     0     0     0     0     0     0     0     0     0     0 #> 3      0     0     0     0     0     0     0     0     0     0     0     0 #> 4      0     0     0     0     0     0     0     0     0     0     0     0 #> 5      0     0     0     0     0     0     0     0     0     0     0     0 #> 6      0     0     0     0     0     0     0     0     0     0     0     0 #> 7      0     0     0     0     0     0     0     0     0     0     0     0 #> 8      0     0     0     0     0     0     0     0     0     0     0     0 #> 9      0     0     0     0     0     0     0     0     0     0     0     0 #> 10     0     0     0     0     0     0     0     0     0     0     0     0 #> 11     0     0     0     0     0     0     0     0     0     0     0     0 #> 12     0     0     0     0     0     0     0     0     0     0     0     0 #> 13     0     0     0     0     0     0     0     0     0     0     0     0 #> 14     0     0     0     0     0     0     0     0     0     0     0     0 #> 15     1     0     0     0     0     0     0     0     0     0     0     0 #> 16     0     1     0     0     0     0     0     0     0     0     0     0 #> 17     0     0     1     0     0     0     0     0     0     0     0     0 #> 18     0     0     0     1     0     0     0     0     0     0     0     0 #> 19     0     0     0     0     1     0     0     0     0     0     0     0 #> 20     0     0     0     0     0     1     0     0     0     0     0     0 #> 21     0     0     0     0     0     0     1     0     0     0     0     0 #> 22     0     0     0     0     0     0     0     1     0     0     0     0 #> 23     0     0     0     0     0     0     0     0     1     0     0     0 #> 24     0     0     0     0     0     0     0     0     0     1     0     0 #> 25     0     0     0     0     0     0     0     0     0     0     1     0 #> 26     0     0     0     0     0     0     0     0     0     0     0     1 #> 27     0     0     0     0     0     0     0     0     0     0     0     0 #> 28     0     0     0     0     0     0     0     0     0     0     0     0 #> 29     0     0     0     0     0     0     0     0     0     0     0     0 #> 30     0     0     0     0     0     0     0     0     0     0     0     0 #> 31     0     0     0     0     0     0     0     0     0     0     0     0 #> 32     0     0     0     0     0     0     0     0     0     0     0     0 #> 33     0     0     0     0     0     0     0     0     0     0     0     0 #> 34     0     0     0     0     0     0     0     0     0     0     0     0 #> 35     0     0     0     0     0     0     0     0     0     0     0     0 #> 36     0     0     0     0     0     0     0     0     0     0     0     0 #> 37     0     0     0     0     0     0     0     0     0     0     0     0 #> 38     0     0     0     0     0     0     0     0     0     0     0     0 #> 39     0     0     0     0     0     0     0     0     0     0     0     0 #> 40     0     0     0     0     0     0     0     0     0     0     0     0 #>    day27 day28 day29 day30 day31 day32 day33 day34 day35 day36 day37 day38 #> 1      0     0     0     0     0     0     0     0     0     0     0     0 #> 2      0     0     0     0     0     0     0     0     0     0     0     0 #> 3      0     0     0     0     0     0     0     0     0     0     0     0 #> 4      0     0     0     0     0     0     0     0     0     0     0     0 #> 5      0     0     0     0     0     0     0     0     0     0     0     0 #> 6      0     0     0     0     0     0     0     0     0     0     0     0 #> 7      0     0     0     0     0     0     0     0     0     0     0     0 #> 8      0     0     0     0     0     0     0     0     0     0     0     0 #> 9      0     0     0     0     0     0     0     0     0     0     0     0 #> 10     0     0     0     0     0     0     0     0     0     0     0     0 #> 11     0     0     0     0     0     0     0     0     0     0     0     0 #> 12     0     0     0     0     0     0     0     0     0     0     0     0 #> 13     0     0     0     0     0     0     0     0     0     0     0     0 #> 14     0     0     0     0     0     0     0     0     0     0     0     0 #> 15     0     0     0     0     0     0     0     0     0     0     0     0 #> 16     0     0     0     0     0     0     0     0     0     0     0     0 #> 17     0     0     0     0     0     0     0     0     0     0     0     0 #> 18     0     0     0     0     0     0     0     0     0     0     0     0 #> 19     0     0     0     0     0     0     0     0     0     0     0     0 #> 20     0     0     0     0     0     0     0     0     0     0     0     0 #> 21     0     0     0     0     0     0     0     0     0     0     0     0 #> 22     0     0     0     0     0     0     0     0     0     0     0     0 #> 23     0     0     0     0     0     0     0     0     0     0     0     0 #> 24     0     0     0     0     0     0     0     0     0     0     0     0 #> 25     0     0     0     0     0     0     0     0     0     0     0     0 #> 26     0     0     0     0     0     0     0     0     0     0     0     0 #> 27     1     0     0     0     0     0     0     0     0     0     0     0 #> 28     0     1     0     0     0     0     0     0     0     0     0     0 #> 29     0     0     1     0     0     0     0     0     0     0     0     0 #> 30     0     0     0     1     0     0     0     0     0     0     0     0 #> 31     0     0     0     0     1     0     0     0     0     0     0     0 #> 32     0     0     0     0     0     1     0     0     0     0     0     0 #> 33     0     0     0     0     0     0     1     0     0     0     0     0 #> 34     0     0     0     0     0     0     0     1     0     0     0     0 #> 35     0     0     0     0     0     0     0     0     1     0     0     0 #> 36     0     0     0     0     0     0     0     0     0     1     0     0 #> 37     0     0     0     0     0     0     0     0     0     0     1     0 #> 38     0     0     0     0     0     0     0     0     0     0     0     1 #> 39     0     0     0     0     0     0     0     0     0     0     0     0 #> 40     0     0     0     0     0     0     0     0     0     0     0     0 #>    day39 day40 #> 1      0     0 #> 2      0     0 #> 3      0     0 #> 4      0     0 #> 5      0     0 #> 6      0     0 #> 7      0     0 #> 8      0     0 #> 9      0     0 #> 10     0     0 #> 11     0     0 #> 12     0     0 #> 13     0     0 #> 14     0     0 #> 15     0     0 #> 16     0     0 #> 17     0     0 #> 18     0     0 #> 19     0     0 #> 20     0     0 #> 21     0     0 #> 22     0     0 #> 23     0     0 #> 24     0     0 #> 25     0     0 #> 26     0     0 #> 27     0     0 #> 28     0     0 #> 29     0     0 #> 30     0     0 #> 31     0     0 #> 32     0     0 #> 33     0     0 #> 34     0     0 #> 35     0     0 #> 36     0     0 #> 37     0     0 #> 38     0     0 #> 39     1     0 #> 40     0     1 #> attr(,\"assign\") #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #> [39] 1 1 #> attr(,\"contrasts\") #> attr(,\"contrasts\")$day #>    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #> 1  1 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 2  0 1 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 3  0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 4  0 0 0 1 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 5  0 0 0 0 1 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 6  0 0 0 0 0 1 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 7  0 0 0 0 0 0 1 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 8  0 0 0 0 0 0 0 1 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 9  0 0 0 0 0 0 0 0 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 10 0 0 0 0 0 0 0 0 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 11 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 12 0 0 0 0 0 0 0 0 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 13 0 0 0 0 0 0 0 0 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 14 0 0 0 0 0 0 0 0 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 15 0 0 0 0 0 0 0 0 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 16 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 #> 17 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 #> 18 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 #> 19 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 #> 20 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 #> 21 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 #> 22 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 #> 23 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 #> 24 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 #> 25 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 #> 26 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 #> 27 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 #> 28 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 #> 29 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 30 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 31 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 32 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 33 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 34 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 35 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 36 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 37 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 38 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 39 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 40 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>    29 30 31 32 33 34 35 36 37 38 39 40 #> 1   0  0  0  0  0  0  0  0  0  0  0  0 #> 2   0  0  0  0  0  0  0  0  0  0  0  0 #> 3   0  0  0  0  0  0  0  0  0  0  0  0 #> 4   0  0  0  0  0  0  0  0  0  0  0  0 #> 5   0  0  0  0  0  0  0  0  0  0  0  0 #> 6   0  0  0  0  0  0  0  0  0  0  0  0 #> 7   0  0  0  0  0  0  0  0  0  0  0  0 #> 8   0  0  0  0  0  0  0  0  0  0  0  0 #> 9   0  0  0  0  0  0  0  0  0  0  0  0 #> 10  0  0  0  0  0  0  0  0  0  0  0  0 #> 11  0  0  0  0  0  0  0  0  0  0  0  0 #> 12  0  0  0  0  0  0  0  0  0  0  0  0 #> 13  0  0  0  0  0  0  0  0  0  0  0  0 #> 14  0  0  0  0  0  0  0  0  0  0  0  0 #> 15  0  0  0  0  0  0  0  0  0  0  0  0 #> 16  0  0  0  0  0  0  0  0  0  0  0  0 #> 17  0  0  0  0  0  0  0  0  0  0  0  0 #> 18  0  0  0  0  0  0  0  0  0  0  0  0 #> 19  0  0  0  0  0  0  0  0  0  0  0  0 #> 20  0  0  0  0  0  0  0  0  0  0  0  0 #> 21  0  0  0  0  0  0  0  0  0  0  0  0 #> 22  0  0  0  0  0  0  0  0  0  0  0  0 #> 23  0  0  0  0  0  0  0  0  0  0  0  0 #> 24  0  0  0  0  0  0  0  0  0  0  0  0 #> 25  0  0  0  0  0  0  0  0  0  0  0  0 #> 26  0  0  0  0  0  0  0  0  0  0  0  0 #> 27  0  0  0  0  0  0  0  0  0  0  0  0 #> 28  0  0  0  0  0  0  0  0  0  0  0  0 #> 29  1  0  0  0  0  0  0  0  0  0  0  0 #> 30  0  1  0  0  0  0  0  0  0  0  0  0 #> 31  0  0  1  0  0  0  0  0  0  0  0  0 #> 32  0  0  0  1  0  0  0  0  0  0  0  0 #> 33  0  0  0  0  1  0  0  0  0  0  0  0 #> 34  0  0  0  0  0  1  0  0  0  0  0  0 #> 35  0  0  0  0  0  0  1  0  0  0  0  0 #> 36  0  0  0  0  0  0  0  1  0  0  0  0 #> 37  0  0  0  0  0  0  0  0  1  0  0  0 #> 38  0  0  0  0  0  0  0  0  0  1  0  0 #> 39  0  0  0  0  0  0  0  0  0  0  1  0 #> 40  0  0  0  0  0  0  0  0  0  0  0  1 #>  #>  #> $data$expr_fintercept #> [1] 0 #>  #> $data$expr_fnrow #> [1] 40 #>  #> $data$expr_findex #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #> [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #>  #> $data$expr_fnindex #> [1] 40 #>  #> $data$expr_fncol #> [1] 40 #>  #> $data$expr_rdesign #>    fixed day #> 1      0   1 #> 2      0   1 #> 3      0   1 #> 4      0   1 #> 5      0   1 #> 6      0   1 #> 7      0   1 #> 8      0   1 #> 9      0   1 #> 10     0   1 #> 11     0   1 #> 12     0   1 #> 13     0   1 #> 14     0   1 #> 15     0   1 #> 16     0   1 #> 17     0   1 #> 18     0   1 #> 19     0   1 #> 20     0   1 #> 21     0   1 #> 22     0   1 #> 23     0   1 #> 24     0   1 #> 25     0   1 #> 26     0   1 #> 27     0   1 #> 28     0   1 #> 29     0   1 #> 30     0   1 #> 31     0   1 #> 32     0   1 #> 33     0   1 #> 34     0   1 #> 35     0   1 #> 36     0   1 #> 37     0   1 #> 38     0   1 #> 39     0   1 #> 40     0   1 #> attr(,\"assign\") #> [1] 1 2 #>  #> $data$expr_rncol #> [1] 1 #>  #> $data$expl_lrd_n #> [1] 1 #>  #> $data$expl_lrd_nw #> [1] 41 #>  #> $data$expl_lrd_w #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #> [39] 1 1 1 #>  #> $data$expl_lrd_nv #> [1] 41 #>  #> $data$expl_lrd_v #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #> [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #>  #> $data$expl_lrd_nu #> [1] 42 #>  #> $data$expl_lrd_u #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #> [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #>  #> $data$expl_obs #> [1] 0 #>  #> $data$expl_fdesign #>    (Intercept) #> 1            1 #> 2            1 #> 3            1 #> 4            1 #> 5            1 #> 6            1 #> 7            1 #> 8            1 #> 9            1 #> 10           1 #> 11           1 #> 12           1 #> 13           1 #> 14           1 #> 15           1 #> 16           1 #> 17           1 #> 18           1 #> 19           1 #> 20           1 #> 21           1 #> 22           1 #> 23           1 #> 24           1 #> 25           1 #> 26           1 #> 27           1 #> 28           1 #> 29           1 #> 30           1 #> 31           1 #> 32           1 #> 33           1 #> 34           1 #> 35           1 #> 36           1 #> 37           1 #> 38           1 #> 39           1 #> 40           1 #> 41           1 #> attr(,\"assign\") #> [1] 0 #>  #> $data$expl_fintercept #> [1] 1 #>  #> $data$expl_fnrow #> [1] 41 #>  #> $data$expl_findex #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #> [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #>  #> $data$expl_fnindex #> [1] 41 #>  #> $data$expl_fncol #> [1] 0 #>  #> $data$expl_rdesign #>      (Intercept) #> attr(,\"assign\") #> [1] 0 #>  #> $data$expl_rncol #> [1] 0 #>  #>  #> $priors #>             variable dimension #> 1:        expr_r_int         1 #> 2:      expr_beta_sd         1 #> 3: expr_lelatent_int         1 #> 4:      expl_beta_sd         1 #>                                                                           description #> 1:                                                   Intercept of the log growth rate #> 2:                        Standard deviation of scaled pooled log growth rate effects #> 3: Intercept for initial log observations (ordered by group and then\\n          time) #> 4:                        Standard deviation of scaled pooled log growth rate effects #>             distribution mean  sd #> 1:                Normal  0.0 0.2 #> 2: Zero truncated normal  0.0 1.0 #> 3:                Normal  4.1 1.0 #> 4: Zero truncated normal  0.0 1.0 #>  #> $inits #> function (data, priors)  #> { #>     priors <- enw_priors_as_data_list(priors) #>     fn <- function() { #>         init <- list(expr_beta = numeric(0), expr_beta_sd = numeric(0),  #>             expr_lelatent_int = matrix(purrr::map2_dbl(as.vector(priors$expr_lelatent_int_p[1]),  #>                 as.vector(priors$expr_lelatent_int_p[2]), function(x,  #>                   y) { #>                   rnorm(1, x, y * 0.1) #>                 }), nrow = data$expr_gt_n, ncol = data$g), expr_r_int = numeric(0),  #>             expl_beta = numeric(0), expl_beta_sd = numeric(0)) #>         if (data$expr_fncol > 0) { #>             init$expr_beta <- array(rnorm(data$expr_fncol, 0,  #>                 0.01)) #>         } #>         if (data$expr_rncol > 0) { #>             init$expr_beta_sd <- array(abs(rnorm(data$expr_rncol,  #>                 priors$expr_beta_sd_p[1], priors$expr_beta_sd_p[2]/10))) #>         } #>         if (data$expr_fintercept > 0) { #>             init$expr_r_int <- array(rnorm(1, priors$expr_r_int[1],  #>                 priors$expr_r_int[2] * 0.1)) #>         } #>         if (data$expl_fncol > 0) { #>             init$expl_beta <- array(rnorm(data$expl_fncol, 0,  #>                 0.01)) #>         } #>         if (data$expl_rncol > 0) { #>             init$expl_beta_sd <- array(abs(rnorm(data$expl_rncol,  #>                 priors$expl_beta_sd_p[1], priors$expl_beta_sd_p[2]/10))) #>         } #>         return(init) #>     } #>     return(fn) #> } #> <bytecode: 0x5606f922a5b8> #> <environment: 0x5606f920b9d8> #>"},{"path":"package.epinowcast.org/dev/reference/enw_extend_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Extend a time series with additional dates — enw_extend_date","title":"Extend a time series with additional dates — enw_extend_date","text":"Extend time series additional dates. useful extending report dates time series include future dates nowcasting purposes include additional dates backcasting using renewal process expectation model.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_extend_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extend a time series with additional dates — enw_extend_date","text":"","code":"enw_extend_date(   metaobs,   days = 20,   direction = c(\"end\", \"start\"),   timestep = \"day\" )"},{"path":"package.epinowcast.org/dev/reference/enw_extend_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extend a time series with additional dates — enw_extend_date","text":"metaobs data.frame date column. days Number days add time series. Defaults 20. direction new dates added beginning end data. Default \"end\" \"start\" also available. timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_extend_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extend a time series with additional dates — enw_extend_date","text":"data.table columns metaobs additional rows date range date date + days (date - days direction = \"start\"). additional variable observed added value FALSE new dates TRUE existing dates.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_extend_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extend a time series with additional dates — enw_extend_date","text":"","code":"metaobs <- data.frame(date = as.Date(\"2021-01-01\") + 0:4) enw_extend_date(metaobs, days = 2) #>          date .group observed #> 1: 2021-01-01      1     TRUE #> 2: 2021-01-02      1     TRUE #> 3: 2021-01-03      1     TRUE #> 4: 2021-01-04      1     TRUE #> 5: 2021-01-05      1     TRUE #> 6: 2021-01-06      1    FALSE #> 7: 2021-01-07      1    FALSE enw_extend_date(metaobs, days = 2, direction = \"start\") #>          date .group observed #> 1: 2020-12-30      1    FALSE #> 2: 2020-12-31      1    FALSE #> 3: 2021-01-01      1     TRUE #> 4: 2021-01-02      1     TRUE #> 5: 2021-01-03      1     TRUE #> 6: 2021-01-04      1     TRUE #> 7: 2021-01-05      1     TRUE"},{"path":"package.epinowcast.org/dev/reference/enw_filter_reference_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter by reference dates — enw_filter_reference_dates","title":"Filter by reference dates — enw_filter_reference_dates","text":"helper function allows users filter datasets reference date. useful, example, evaluating nowcast performance fully observed data. Users may wish combine function enw_filter_report_dates(). Note definition assumed report date given reference date must equal greater (.e report happen event reported occurs). means function also filter report dates earlier target reference dates.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_filter_reference_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter by reference dates — enw_filter_reference_dates","text":"","code":"enw_filter_reference_dates(   obs,   earliest_date,   include_days,   latest_date,   remove_days )"},{"path":"package.epinowcast.org/dev/reference/enw_filter_reference_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter by reference dates — enw_filter_reference_dates","text":"obs data.frame; must report_date reference_date columns. earliest_date earliest reference date include data set include_days earilest_date given, number reference dates include, ending latest reference date included report dates removed. specified indexed latest_date remove_days. latest_date Date, latest reference date include returned dataset. remove_days Integer, latest_date given, number reference dates remove, starting latest date included.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_filter_reference_dates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter by reference dates — enw_filter_reference_dates","text":"data.table  filtered report date","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_filter_reference_dates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter by reference dates — enw_filter_reference_dates","text":"","code":"# Filter by date enw_filter_reference_dates(   germany_covid19_hosp,   earliest_date = \"2021-09-01\",   latest_date = \"2021-10-01\" ) #>         reference_date location age_group confirm report_date #>      1:     2021-09-01       DE       00+     124  2021-09-01 #>      2:     2021-09-02       DE       00+      94  2021-09-02 #>      3:     2021-09-03       DE       00+     130  2021-09-03 #>      4:     2021-09-04       DE       00+      82  2021-09-04 #>      5:     2021-09-05       DE       00+      42  2021-09-05 #>     ---                                                       #> 129111:     2021-09-01    DE-TH     05-14       0  2021-10-20 #> 129112:     2021-09-01    DE-TH     15-34       0  2021-10-20 #> 129113:     2021-09-01    DE-TH     35-59       1  2021-10-20 #> 129114:     2021-09-01    DE-TH     60-79       2  2021-10-20 #> 129115:     2021-09-01    DE-TH       80+       2  2021-10-20 # # Filter by days enw_filter_reference_dates(   germany_covid19_hosp,   include_days = 10, remove_days = 10 ) #>        reference_date location age_group confirm report_date #>     1:     2021-09-30       DE       00+     110  2021-09-30 #>     2:     2021-10-01       DE       00+     105  2021-10-01 #>     3:     2021-10-02       DE       00+      97  2021-10-02 #>     4:     2021-10-03       DE       00+      41  2021-10-03 #>     5:     2021-10-04       DE       00+      23  2021-10-04 #>    ---                                                       #> 20940:     2021-09-30    DE-TH     05-14       1  2021-10-20 #> 20941:     2021-09-30    DE-TH     15-34       2  2021-10-20 #> 20942:     2021-09-30    DE-TH     35-59       6  2021-10-20 #> 20943:     2021-09-30    DE-TH     60-79       4  2021-10-20 #> 20944:     2021-09-30    DE-TH       80+      10  2021-10-20"},{"path":"package.epinowcast.org/dev/reference/enw_filter_report_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter by report dates — enw_filter_report_dates","title":"Filter by report dates — enw_filter_report_dates","text":"helper function allows users create truncated data sets past time points given larger data set. useful evaluating nowcast performance fully observed data. Users may wish combine function enw_filter_reference_dates().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_filter_report_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter by report dates — enw_filter_report_dates","text":"","code":"enw_filter_report_dates(obs, latest_date, remove_days)"},{"path":"package.epinowcast.org/dev/reference/enw_filter_report_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter by report dates — enw_filter_report_dates","text":"obs data.frame; must report_date reference_date columns. latest_date Date, latest report date include returned dataset. remove_days Integer, latest_date given, number report dates remove, starting latest date included.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_filter_report_dates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter by report dates — enw_filter_report_dates","text":"data.table  filtered report date","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_filter_report_dates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter by report dates — enw_filter_report_dates","text":"","code":"# Filter by date enw_filter_report_dates(germany_covid19_hosp, latest_date = \"2021-09-01\") #>          reference_date location age_group confirm report_date #>       1:     2021-04-06       DE       00+     149  2021-04-06 #>       2:     2021-04-07       DE       00+     312  2021-04-07 #>       3:     2021-04-08       DE       00+     424  2021-04-08 #>       4:     2021-04-09       DE       00+     288  2021-04-09 #>       5:     2021-04-10       DE       00+     273  2021-04-10 #>      ---                                                       #> 1058739:     2021-06-08    DE-TH       80+       4  2021-08-28 #> 1058740:     2021-06-09    DE-TH       80+       4  2021-08-29 #> 1058741:     2021-06-10    DE-TH       80+       1  2021-08-30 #> 1058742:     2021-06-11    DE-TH       80+       0  2021-08-31 #> 1058743:     2021-06-12    DE-TH       80+       2  2021-09-01  # Filter by days enw_filter_report_dates(germany_covid19_hosp, remove_days = 10) #>          reference_date location age_group confirm report_date #>       1:     2021-04-06       DE       00+     149  2021-04-06 #>       2:     2021-04-07       DE       00+     312  2021-04-07 #>       3:     2021-04-08       DE       00+     424  2021-04-08 #>       4:     2021-04-09       DE       00+     288  2021-04-09 #>       5:     2021-04-10       DE       00+     273  2021-04-10 #>      ---                                                       #> 1439301:     2021-07-17    DE-TH       80+       1  2021-10-06 #> 1439302:     2021-07-18    DE-TH       80+       0  2021-10-07 #> 1439303:     2021-07-19    DE-TH       80+       0  2021-10-08 #> 1439304:     2021-07-20    DE-TH       80+       0  2021-10-09 #> 1439305:     2021-07-21    DE-TH       80+       0  2021-10-10"},{"path":"package.epinowcast.org/dev/reference/enw_fit_opts.html","id":null,"dir":"Reference","previous_headings":"","what":"Format model fitting options for use with stan — enw_fit_opts","title":"Format model fitting options for use with stan — enw_fit_opts","text":"Format model fitting options use stan","code":""},{"path":"package.epinowcast.org/dev/reference/enw_fit_opts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format model fitting options for use with stan — enw_fit_opts","text":"","code":"enw_fit_opts(   sampler = epinowcast::enw_sample,   nowcast = TRUE,   pp = FALSE,   likelihood = TRUE,   likelihood_aggregation = c(\"snapshots\", \"groups\"),   debug = FALSE,   output_loglik = FALSE,   ... )"},{"path":"package.epinowcast.org/dev/reference/enw_fit_opts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format model fitting options for use with stan — enw_fit_opts","text":"sampler function creates object used extract posterior samples specified model. default enw_sample() makes use cmdstanr::sample(). nowcast Logical, defaults TRUE. nowcast made using posterior predictions unobserved future reported notifications. pp Logical, defaults FALSE. posterior predictions made observed data. Useful evaluating performance model. likelihood Logical, defaults TRUE. likelihood included model likelihood_aggregation Character string, aggregation stratify likelihood threads = TRUE; enforced base::match.arg(). Currently supported options: \"snapshots\" aggregates report dates groups (.e lowest level observations reported ), \"groups\" aggregates across user defined groups. Note model modules override setting depending model requirements. example, enw_missing() module model forces \"groups\" option. Generally, Users typically want default \"snapshots\" aggregation. debug Logical, defaults FALSE. within model debug information returned. output_loglik Logical, defaults FALSE. log-likelihood output. Disabling speed fitting evaluating model fit required. ... Additional arguments pass fitting function used epinowcast(). default enw_sample() cmdstanr options used.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_fit_opts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format model fitting options for use with stan — enw_fit_opts","text":"list containing specified sampler function, data list specifying fitting options use, additional arguments pass sampler function called.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_fit_opts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format model fitting options for use with stan — enw_fit_opts","text":"","code":"# Default options along with settings to pass to enw_sample enw_fit_opts(iter_sampling = 1000, iter_warmup = 1000) #> $sampler #> function (data, model = epinowcast::enw_model(), diagnostics = TRUE,  #>     ...)  #> { #>     fit <- model$sample(data = data, ...) #>     out <- data.table(fit = list(fit), data = list(data), fit_args = list(list(...))) #>     if (diagnostics) { #>         diag <- fit$sampler_diagnostics(format = \"df\") #>         diagnostics <- data.table(samples = nrow(diag), max_rhat = round(max(fit$summary(variables = NULL,  #>             posterior::rhat, .args = list(na.rm = TRUE))$`posterior::rhat`,  #>             na.rm = TRUE), 2), divergent_transitions = sum(diag$divergent__),  #>             per_divergent_transitions = sum(diag$divergent__)/nrow(diag),  #>             max_treedepth = max(diag$treedepth__)) #>         diagnostics[, `:=`(no_at_max_treedepth, sum(diag$treedepth__ ==  #>             max_treedepth))] #>         diagnostics[, `:=`(per_at_max_treedepth, no_at_max_treedepth/nrow(diag))] #>         out <- cbind(out, diagnostics) #>         timing <- round(fit$time()$total, 1) #>         out[, `:=`(run_time, timing)] #>     } #>     return(out[]) #> } #> <bytecode: 0x56070076f8d8> #> <environment: namespace:epinowcast> #>  #> $data #> $data$debug #> [1] 0 #>  #> $data$likelihood #> [1] 1 #>  #> $data$likelihood_aggregation #> [1] 0 #>  #> $data$pp #> [1] 0 #>  #> $data$cast #> [1] 1 #>  #> $data$ologlik #> [1] 0 #>  #>  #> $args #> $args$iter_sampling #> [1] 1000 #>  #> $args$iter_warmup #> [1] 1000 #>  #>"},{"path":"package.epinowcast.org/dev/reference/enw_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a model using a formula interface — enw_formula","title":"Define a model using a formula interface — enw_formula","text":"function allows models defined using flexible formula interface supports fixed effects, random effects (using lme4 syntax). Note returned fixed effects design matrix sparse index supplied required link observations appropriate design matrix row.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a model using a formula interface — enw_formula","text":"","code":"enw_formula(formula, data, sparse = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a model using a formula interface — enw_formula","text":"formula model formula may use standard fixed effects, random effects using lme4 syntax (see re()), random walks defined using rw() helper function. data data.frame observations. must include variables used supplied formula. sparse Logical, defaults  TRUE. fixed effects design matrix sparely defined.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a model using a formula interface — enw_formula","text":"list containing following: formula: user supplied formula parsed_formula: formula parsed parse_formula() extended_formula: flattened version formula user supplied terms terms added user supplied complex model components. fixed:  list containing fixed effect formula, sparse design matrix, index linking design matrix observations. random: list containing random effect formula, sparse design matrix, index linking design matrix random effects.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a model using a formula interface — enw_formula","text":"","code":"# Use meta data for references dates from the Germany COVID-19 # hospitalisation data. obs <- enw_filter_report_dates(   germany_covid19_hosp[location == \"DE\"],   remove_days = 40 ) obs <- enw_filter_reference_dates(obs, include_days = 40) pobs <- enw_preprocess_data(obs, by = c(\"age_group\", \"location\")) data <- pobs$metareference[[1]]  # Model with fixed effects for age group enw_formula(~ 1 + age_group, data) #> $formula #> [1] \"~1 + age_group\" #>  #> $parsed_formula #> $parsed_formula$fixed #> [1] \"1\"         \"age_group\" #>  #> $parsed_formula$random #> NULL #>  #> $parsed_formula$rw #> character(0) #>  #>  #> $expanded_formula #> [1] \"~1 + age_group\" #>  #> $fixed #> $fixed$formula #> [1] \"~1 + age_group\" #>  #> $fixed$design #>     (Intercept) age_group00+ age_group05-14 age_group15-34 age_group35-59 #> 1             1            1              0              0              0 #> 42            1            0              0              0              0 #> 83            1            0              1              0              0 #> 124           1            0              0              1              0 #> 165           1            0              0              0              1 #> 206           1            0              0              0              0 #> 247           1            0              0              0              0 #>     age_group60-79 age_group80+ #> 1                0            0 #> 42               0            0 #> 83               0            0 #> 124              0            0 #> 165              0            0 #> 206              1            0 #> 247              0            1 #>  #> $fixed$index #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 #> [149] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 #> [186] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 #> [223] 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 #> [260] 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 #>  #>  #> $random #> $random$formula #> [1] \"~1\" #>  #> $random$design #>   (Intercept) #> 1           1 #> 2           1 #> 3           1 #> 4           1 #> 5           1 #> 6           1 #> attr(,\"assign\") #> [1] 0 #>  #> $random$index #> [1] 1 2 3 4 5 6 #>  #>  #> attr(,\"class\") #> [1] \"enw_formula\" \"list\"         # Model with random effects for age group enw_formula(~ 1 + (1 | age_group), data) #> $formula #> [1] \"~1 + (1 | age_group)\" #>  #> $parsed_formula #> $parsed_formula$fixed #> [1] \"1\" #>  #> $parsed_formula$random #> $parsed_formula$random[[1]] #> 1 | age_group #>  #>  #> $parsed_formula$rw #> character(0) #>  #>  #> $expanded_formula #> [1] \"~1 + age_group\" #>  #> $fixed #> $fixed$formula #> [1] \"~1 + age_group\" #>  #> $fixed$design #>     (Intercept) age_group00-04 age_group00+ age_group05-14 age_group15-34 #> 1             1              0            1              0              0 #> 42            1              1            0              0              0 #> 83            1              0            0              1              0 #> 124           1              0            0              0              1 #> 165           1              0            0              0              0 #> 206           1              0            0              0              0 #> 247           1              0            0              0              0 #>     age_group35-59 age_group60-79 age_group80+ #> 1                0              0            0 #> 42               0              0            0 #> 83               0              0            0 #> 124              0              0            0 #> 165              1              0            0 #> 206              0              1            0 #> 247              0              0            1 #>  #> $fixed$index #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 #> [149] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 #> [186] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 #> [223] 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 #> [260] 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 #>  #>  #> $random #> $random$formula #> [1] \"~0 + fixed + age_group\" #>  #> $random$design #>   fixed age_group #> 1     0         1 #> 2     0         1 #> 3     0         1 #> 4     0         1 #> 5     0         1 #> 6     0         1 #> 7     0         1 #> attr(,\"assign\") #> [1] 1 2 #>  #> $random$index #> [1] 1 2 3 4 5 6 7 #>  #>  #> attr(,\"class\") #> [1] \"enw_formula\" \"list\"         # Model with a random effect for age group and a random walk enw_formula(~ 1 + (1 | age_group) + rw(week), data) #> $formula #> [1] \"~1 + (1 | age_group) + rw(week)\" #>  #> $parsed_formula #> $parsed_formula$fixed #> [1] \"1\" #>  #> $parsed_formula$random #> $parsed_formula$random[[1]] #> 1 | age_group #>  #>  #> $parsed_formula$rw #> [1] \"rw(week)\" #>  #>  #> $expanded_formula #> [1] \"~1 + age_group + cweek1 + cweek2 + cweek3 + cweek4 + cweek5\" #>  #> $fixed #> $fixed$formula #> [1] \"~1 + age_group + cweek1 + cweek2 + cweek3 + cweek4 + cweek5\" #>  #> $fixed$design #>     (Intercept) age_group00-04 age_group00+ age_group05-14 age_group15-34 #> 1             1              0            1              0              0 #> 8             1              0            1              0              0 #> 15            1              0            1              0              0 #> 22            1              0            1              0              0 #> 29            1              0            1              0              0 #> 36            1              0            1              0              0 #> 42            1              1            0              0              0 #> 49            1              1            0              0              0 #> 56            1              1            0              0              0 #> 63            1              1            0              0              0 #> 70            1              1            0              0              0 #> 77            1              1            0              0              0 #> 83            1              0            0              1              0 #> 90            1              0            0              1              0 #> 97            1              0            0              1              0 #> 104           1              0            0              1              0 #> 111           1              0            0              1              0 #> 118           1              0            0              1              0 #> 124           1              0            0              0              1 #> 131           1              0            0              0              1 #> 138           1              0            0              0              1 #> 145           1              0            0              0              1 #> 152           1              0            0              0              1 #> 159           1              0            0              0              1 #> 165           1              0            0              0              0 #> 172           1              0            0              0              0 #> 179           1              0            0              0              0 #> 186           1              0            0              0              0 #> 193           1              0            0              0              0 #> 200           1              0            0              0              0 #> 206           1              0            0              0              0 #> 213           1              0            0              0              0 #> 220           1              0            0              0              0 #> 227           1              0            0              0              0 #> 234           1              0            0              0              0 #> 241           1              0            0              0              0 #> 247           1              0            0              0              0 #> 254           1              0            0              0              0 #> 261           1              0            0              0              0 #> 268           1              0            0              0              0 #> 275           1              0            0              0              0 #> 282           1              0            0              0              0 #>     age_group35-59 age_group60-79 age_group80+ cweek1 cweek2 cweek3 cweek4 #> 1                0              0            0      0      0      0      0 #> 8                0              0            0      1      0      0      0 #> 15               0              0            0      1      1      0      0 #> 22               0              0            0      1      1      1      0 #> 29               0              0            0      1      1      1      1 #> 36               0              0            0      1      1      1      1 #> 42               0              0            0      0      0      0      0 #> 49               0              0            0      1      0      0      0 #> 56               0              0            0      1      1      0      0 #> 63               0              0            0      1      1      1      0 #> 70               0              0            0      1      1      1      1 #> 77               0              0            0      1      1      1      1 #> 83               0              0            0      0      0      0      0 #> 90               0              0            0      1      0      0      0 #> 97               0              0            0      1      1      0      0 #> 104              0              0            0      1      1      1      0 #> 111              0              0            0      1      1      1      1 #> 118              0              0            0      1      1      1      1 #> 124              0              0            0      0      0      0      0 #> 131              0              0            0      1      0      0      0 #> 138              0              0            0      1      1      0      0 #> 145              0              0            0      1      1      1      0 #> 152              0              0            0      1      1      1      1 #> 159              0              0            0      1      1      1      1 #> 165              1              0            0      0      0      0      0 #> 172              1              0            0      1      0      0      0 #> 179              1              0            0      1      1      0      0 #> 186              1              0            0      1      1      1      0 #> 193              1              0            0      1      1      1      1 #> 200              1              0            0      1      1      1      1 #> 206              0              1            0      0      0      0      0 #> 213              0              1            0      1      0      0      0 #> 220              0              1            0      1      1      0      0 #> 227              0              1            0      1      1      1      0 #> 234              0              1            0      1      1      1      1 #> 241              0              1            0      1      1      1      1 #> 247              0              0            1      0      0      0      0 #> 254              0              0            1      1      0      0      0 #> 261              0              0            1      1      1      0      0 #> 268              0              0            1      1      1      1      0 #> 275              0              0            1      1      1      1      1 #> 282              0              0            1      1      1      1      1 #>     cweek5 #> 1        0 #> 8        0 #> 15       0 #> 22       0 #> 29       0 #> 36       1 #> 42       0 #> 49       0 #> 56       0 #> 63       0 #> 70       0 #> 77       1 #> 83       0 #> 90       0 #> 97       0 #> 104      0 #> 111      0 #> 118      1 #> 124      0 #> 131      0 #> 138      0 #> 145      0 #> 152      0 #> 159      1 #> 165      0 #> 172      0 #> 179      0 #> 186      0 #> 193      0 #> 200      1 #> 206      0 #> 213      0 #> 220      0 #> 227      0 #> 234      0 #> 241      1 #> 247      0 #> 254      0 #> 261      0 #> 268      0 #> 275      0 #> 282      1 #>  #> $fixed$index #>   [1]  1  1  1  1  1  1  1  2  2  2  2  2  2  2  3  3  3  3  3  3  3  4  4  4  4 #>  [26]  4  4  4  5  5  5  5  5  5  5  6  6  6  6  6  6  7  7  7  7  7  7  7  8  8 #>  [51]  8  8  8  8  8  9  9  9  9  9  9  9 10 10 10 10 10 10 10 11 11 11 11 11 11 #>  [76] 11 12 12 12 12 12 12 13 13 13 13 13 13 13 14 14 14 14 14 14 14 15 15 15 15 #> [101] 15 15 15 16 16 16 16 16 16 16 17 17 17 17 17 17 17 18 18 18 18 18 18 19 19 #> [126] 19 19 19 19 19 20 20 20 20 20 20 20 21 21 21 21 21 21 21 22 22 22 22 22 22 #> [151] 22 23 23 23 23 23 23 23 24 24 24 24 24 24 25 25 25 25 25 25 25 26 26 26 26 #> [176] 26 26 26 27 27 27 27 27 27 27 28 28 28 28 28 28 28 29 29 29 29 29 29 29 30 #> [201] 30 30 30 30 30 31 31 31 31 31 31 31 32 32 32 32 32 32 32 33 33 33 33 33 33 #> [226] 33 34 34 34 34 34 34 34 35 35 35 35 35 35 35 36 36 36 36 36 36 37 37 37 37 #> [251] 37 37 37 38 38 38 38 38 38 38 39 39 39 39 39 39 39 40 40 40 40 40 40 40 41 #> [276] 41 41 41 41 41 41 42 42 42 42 42 42 #>  #>  #> $random #> $random$formula #> [1] \"~0 + fixed + age_group + rw__week\" #>  #> $random$design #>    fixed age_group rw__week #> 1      0         1        0 #> 2      0         1        0 #> 3      0         1        0 #> 4      0         1        0 #> 5      0         1        0 #> 6      0         1        0 #> 7      0         1        0 #> 8      0         0        1 #> 9      0         0        1 #> 10     0         0        1 #> 11     0         0        1 #> 12     0         0        1 #> attr(,\"assign\") #> [1] 1 2 3 #>  #> $random$index #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 #>  #>  #> attr(,\"class\") #> [1] \"enw_formula\" \"list\"         # Model defined without a sparse fixed effects design matrix enw_formula(~1, data[1:20, ]) #> $formula #> [1] \"~1\" #>  #> $parsed_formula #> $parsed_formula$fixed #> [1] \"1\" #>  #> $parsed_formula$random #> NULL #>  #> $parsed_formula$rw #> character(0) #>  #>  #> $expanded_formula #> [1] \"~1\" #>  #> $fixed #> $fixed$formula #> [1] \"~1\" #>  #> $fixed$design #>   (Intercept) #> 1           1 #>  #> $fixed$index #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  #>  #> $random #> $random$formula #> [1] \"~1\" #>  #> $random$design #>      (Intercept) #> attr(,\"assign\") #> [1] 0 #>  #> $random$index #> integer(0) #>  #>  #> attr(,\"class\") #> [1] \"enw_formula\" \"list\"         # Model using an interaction in the right hand side of a random effect # to specify an independent random effect per strata. enw_formula(~ (1 + day | week:month), data = data) #> $formula #> [1] \"~(1 + day | week:month)\" #>  #> $parsed_formula #> $parsed_formula$fixed #> [1] \"1\" #>  #> $parsed_formula$random #> $parsed_formula$random[[1]] #> 1 + day | week:month #>  #>  #> $parsed_formula$rw #> character(0) #>  #>  #> $expanded_formula #> [1] \"~1 + week:month + day:week:month\" #>  #> $fixed #> $fixed$formula #> [1] \"~1 + week:month + day:week:month\" #>  #> $fixed$design #>    (Intercept) week0:month0 week1:month0 week2:month0 week3:month0 week4:month0 #> 1            1            1            0            0            0            0 #> 2            1            1            0            0            0            0 #> 3            1            1            0            0            0            0 #> 4            1            1            0            0            0            0 #> 5            1            1            0            0            0            0 #> 6            1            1            0            0            0            0 #> 7            1            1            0            0            0            0 #> 8            1            0            1            0            0            0 #> 9            1            0            1            0            0            0 #> 10           1            0            1            0            0            0 #> 11           1            0            1            0            0            0 #> 12           1            0            1            0            0            0 #> 13           1            0            1            0            0            0 #> 14           1            0            1            0            0            0 #> 15           1            0            0            1            0            0 #> 16           1            0            0            1            0            0 #> 17           1            0            0            1            0            0 #> 18           1            0            0            1            0            0 #> 19           1            0            0            1            0            0 #> 20           1            0            0            1            0            0 #> 21           1            0            0            1            0            0 #> 22           1            0            0            0            1            0 #> 23           1            0            0            0            1            0 #> 24           1            0            0            0            1            0 #> 25           1            0            0            0            1            0 #> 26           1            0            0            0            1            0 #> 27           1            0            0            0            1            0 #> 28           1            0            0            0            1            0 #> 29           1            0            0            0            0            1 #> 30           1            0            0            0            0            1 #> 31           1            0            0            0            0            1 #> 32           1            0            0            0            0            0 #> 33           1            0            0            0            0            0 #> 34           1            0            0            0            0            0 #> 35           1            0            0            0            0            0 #> 36           1            0            0            0            0            0 #> 37           1            0            0            0            0            0 #> 38           1            0            0            0            0            0 #> 39           1            0            0            0            0            0 #> 40           1            0            0            0            0            0 #> 41           1            0            0            0            0            0 #>    week5:month0 week0:month1 week1:month1 week2:month1 week3:month1 #> 1             0            0            0            0            0 #> 2             0            0            0            0            0 #> 3             0            0            0            0            0 #> 4             0            0            0            0            0 #> 5             0            0            0            0            0 #> 6             0            0            0            0            0 #> 7             0            0            0            0            0 #> 8             0            0            0            0            0 #> 9             0            0            0            0            0 #> 10            0            0            0            0            0 #> 11            0            0            0            0            0 #> 12            0            0            0            0            0 #> 13            0            0            0            0            0 #> 14            0            0            0            0            0 #> 15            0            0            0            0            0 #> 16            0            0            0            0            0 #> 17            0            0            0            0            0 #> 18            0            0            0            0            0 #> 19            0            0            0            0            0 #> 20            0            0            0            0            0 #> 21            0            0            0            0            0 #> 22            0            0            0            0            0 #> 23            0            0            0            0            0 #> 24            0            0            0            0            0 #> 25            0            0            0            0            0 #> 26            0            0            0            0            0 #> 27            0            0            0            0            0 #> 28            0            0            0            0            0 #> 29            0            0            0            0            0 #> 30            0            0            0            0            0 #> 31            0            0            0            0            0 #> 32            0            0            0            0            0 #> 33            0            0            0            0            0 #> 34            0            0            0            0            0 #> 35            0            0            0            0            0 #> 36            0            0            0            0            0 #> 37            0            0            0            0            0 #> 38            0            0            0            0            0 #> 39            0            0            0            0            0 #> 40            0            0            0            0            0 #> 41            0            0            0            0            0 #>    week4:month1 week5:month1 week0:month0:day week1:month0:day week2:month0:day #> 1             0            0                0                0                0 #> 2             0            0                1                0                0 #> 3             0            0                2                0                0 #> 4             0            0                3                0                0 #> 5             0            0                4                0                0 #> 6             0            0                5                0                0 #> 7             0            0                6                0                0 #> 8             0            0                0                7                0 #> 9             0            0                0                8                0 #> 10            0            0                0                9                0 #> 11            0            0                0               10                0 #> 12            0            0                0               11                0 #> 13            0            0                0               12                0 #> 14            0            0                0               13                0 #> 15            0            0                0                0               14 #> 16            0            0                0                0               15 #> 17            0            0                0                0               16 #> 18            0            0                0                0               17 #> 19            0            0                0                0               18 #> 20            0            0                0                0               19 #> 21            0            0                0                0               20 #> 22            0            0                0                0                0 #> 23            0            0                0                0                0 #> 24            0            0                0                0                0 #> 25            0            0                0                0                0 #> 26            0            0                0                0                0 #> 27            0            0                0                0                0 #> 28            0            0                0                0                0 #> 29            0            0                0                0                0 #> 30            0            0                0                0                0 #> 31            0            0                0                0                0 #> 32            1            0                0                0                0 #> 33            1            0                0                0                0 #> 34            1            0                0                0                0 #> 35            1            0                0                0                0 #> 36            0            1                0                0                0 #> 37            0            1                0                0                0 #> 38            0            1                0                0                0 #> 39            0            1                0                0                0 #> 40            0            1                0                0                0 #> 41            0            1                0                0                0 #>    week3:month0:day week4:month0:day week5:month0:day week0:month1:day #> 1                 0                0                0                0 #> 2                 0                0                0                0 #> 3                 0                0                0                0 #> 4                 0                0                0                0 #> 5                 0                0                0                0 #> 6                 0                0                0                0 #> 7                 0                0                0                0 #> 8                 0                0                0                0 #> 9                 0                0                0                0 #> 10                0                0                0                0 #> 11                0                0                0                0 #> 12                0                0                0                0 #> 13                0                0                0                0 #> 14                0                0                0                0 #> 15                0                0                0                0 #> 16                0                0                0                0 #> 17                0                0                0                0 #> 18                0                0                0                0 #> 19                0                0                0                0 #> 20                0                0                0                0 #> 21                0                0                0                0 #> 22               21                0                0                0 #> 23               22                0                0                0 #> 24               23                0                0                0 #> 25               24                0                0                0 #> 26               25                0                0                0 #> 27               26                0                0                0 #> 28               27                0                0                0 #> 29                0               28                0                0 #> 30                0               29                0                0 #> 31                0               30                0                0 #> 32                0                0                0                0 #> 33                0                0                0                0 #> 34                0                0                0                0 #> 35                0                0                0                0 #> 36                0                0                0                0 #> 37                0                0                0                0 #> 38                0                0                0                0 #> 39                0                0                0                0 #> 40                0                0                0                0 #> 41                0                0                0                0 #>    week1:month1:day week2:month1:day week3:month1:day week4:month1:day #> 1                 0                0                0                0 #> 2                 0                0                0                0 #> 3                 0                0                0                0 #> 4                 0                0                0                0 #> 5                 0                0                0                0 #> 6                 0                0                0                0 #> 7                 0                0                0                0 #> 8                 0                0                0                0 #> 9                 0                0                0                0 #> 10                0                0                0                0 #> 11                0                0                0                0 #> 12                0                0                0                0 #> 13                0                0                0                0 #> 14                0                0                0                0 #> 15                0                0                0                0 #> 16                0                0                0                0 #> 17                0                0                0                0 #> 18                0                0                0                0 #> 19                0                0                0                0 #> 20                0                0                0                0 #> 21                0                0                0                0 #> 22                0                0                0                0 #> 23                0                0                0                0 #> 24                0                0                0                0 #> 25                0                0                0                0 #> 26                0                0                0                0 #> 27                0                0                0                0 #> 28                0                0                0                0 #> 29                0                0                0                0 #> 30                0                0                0                0 #> 31                0                0                0                0 #> 32                0                0                0               31 #> 33                0                0                0               32 #> 34                0                0                0               33 #> 35                0                0                0               34 #> 36                0                0                0                0 #> 37                0                0                0                0 #> 38                0                0                0                0 #> 39                0                0                0                0 #> 40                0                0                0                0 #> 41                0                0                0                0 #>    week5:month1:day #> 1                 0 #> 2                 0 #> 3                 0 #> 4                 0 #> 5                 0 #> 6                 0 #> 7                 0 #> 8                 0 #> 9                 0 #> 10                0 #> 11                0 #> 12                0 #> 13                0 #> 14                0 #> 15                0 #> 16                0 #> 17                0 #> 18                0 #> 19                0 #> 20                0 #> 21                0 #> 22                0 #> 23                0 #> 24                0 #> 25                0 #> 26                0 #> 27                0 #> 28                0 #> 29                0 #> 30                0 #> 31                0 #> 32                0 #> 33                0 #> 34                0 #> 35                0 #> 36               35 #> 37               36 #> 38               37 #> 39               38 #> 40               39 #> 41               40 #>  #> $fixed$index #>   [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #>  [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  1  2  3  4  5  6  7  8  9 #>  [51] 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #>  [76] 35 36 37 38 39 40 41  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 #> [101] 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  1  2 #> [126]  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #> [151] 28 29 30 31 32 33 34 35 36 37 38 39 40 41  1  2  3  4  5  6  7  8  9 10 11 #> [176] 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #> [201] 37 38 39 40 41  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 #> [226] 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  1  2  3  4 #> [251]  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #> [276] 30 31 32 33 34 35 36 37 38 39 40 41 #>  #>  #> $random #> $random$formula #> [1] \"~0 + fixed + week__month0 + week__month1 + day__week__month0 + day__week__month1\" #>  #> $random$design #>    fixed week__month0 week__month1 day__week__month0 day__week__month1 #> 1      0            1            0                 0                 0 #> 2      0            1            0                 0                 0 #> 3      0            1            0                 0                 0 #> 4      0            1            0                 0                 0 #> 5      0            1            0                 0                 0 #> 6      0            1            0                 0                 0 #> 7      0            0            1                 0                 0 #> 8      0            0            1                 0                 0 #> 9      0            0            1                 0                 0 #> 10     0            0            1                 0                 0 #> 11     0            0            1                 0                 0 #> 12     0            0            1                 0                 0 #> 13     0            0            0                 1                 0 #> 14     0            0            0                 1                 0 #> 15     0            0            0                 1                 0 #> 16     0            0            0                 1                 0 #> 17     0            0            0                 1                 0 #> 18     0            0            0                 1                 0 #> 19     0            0            0                 0                 1 #> 20     0            0            0                 0                 1 #> 21     0            0            0                 0                 1 #> 22     0            0            0                 0                 1 #> 23     0            0            0                 0                 1 #> 24     0            0            0                 0                 1 #> attr(,\"assign\") #> [1] 1 2 3 4 5 #>  #> $random$index #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #>  #>  #> attr(,\"class\") #> [1] \"enw_formula\" \"list\""},{"path":"package.epinowcast.org/dev/reference/enw_formula_as_data_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Format formula data for use with stan — enw_formula_as_data_list","title":"Format formula data for use with stan — enw_formula_as_data_list","text":"Format formula data use stan","code":""},{"path":"package.epinowcast.org/dev/reference/enw_formula_as_data_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format formula data for use with stan — enw_formula_as_data_list","text":"","code":"enw_formula_as_data_list(formula, prefix, drop_intercept = FALSE)"},{"path":"package.epinowcast.org/dev/reference/enw_formula_as_data_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format formula data for use with stan — enw_formula_as_data_list","text":"formula output enw_formula(). prefix character string indicating variable label use prefix. drop_intercept Logical, defaults FALSE. intercept included fixed effect excluded. used internally model modules intercept must present/absent.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_formula_as_data_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format formula data for use with stan — enw_formula_as_data_list","text":"list defining model formula. includes: prefix_fintercept: intercept present fixed effects design matrix. prefix_fdesign: fixed effects design matrix prefix_fnrow: number rows fixed design matrix prefix_findex: index linking design matrix rows  observations prefix_fnindex: length index prefix_fncol: number columns (.e effects) fixed effect design matrix (minus 1 drop_intercept = TRUE). prefix_rdesign: random effects design matrix prefix_rncol: number columns (.e random effects) random effect design matrix (minus 1 intercept dropped).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_formula_as_data_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format formula data for use with stan — enw_formula_as_data_list","text":"","code":"f <- enw_formula(~ 1 + (1 | cyl), mtcars) enw_formula_as_data_list(f, \"mtcars\") #> $mtcars_fdesign #>   (Intercept) cyl4 cyl6 cyl8 #> 1           1    0    1    0 #> 3           1    1    0    0 #> 5           1    0    0    1 #>  #> $mtcars_fintercept #> [1] 1 #>  #> $mtcars_fnrow #> [1] 3 #>  #> $mtcars_findex #>  [1] 1 1 2 1 3 1 3 2 2 1 1 3 3 3 3 3 3 2 2 2 2 3 3 3 3 2 2 2 3 1 3 2 #>  #> $mtcars_fnindex #> [1] 32 #>  #> $mtcars_fncol #> [1] 4 #>  #> $mtcars_rdesign #>   fixed cyl #> 1     0   1 #> 2     0   1 #> 3     0   1 #> attr(,\"assign\") #> [1] 1 2 #>  #> $mtcars_rncol #> [1] 1 #>   # A missing formula produces the default list enw_formula_as_data_list(prefix = \"missing\") #> $missing_fdesign #> numeric(0) #>  #> $missing_fintercept #> [1] 0 #>  #> $missing_fnrow #> [1] 0 #>  #> $missing_findex #> numeric(0) #>  #> $missing_fnindex #> [1] 0 #>  #> $missing_fncol #> [1] 0 #>  #> $missing_rdesign #> numeric(0) #>  #> $missing_rncol #> [1] 0 #>"},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_cumulative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate cumulative reported cases from incidence of new reports — enw_incidence_to_cumulative","text":"","code":"enw_incidence_to_cumulative(obs, by = NULL)"},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_cumulative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate cumulative reported cases from incidence of new reports — enw_incidence_to_cumulative","text":"obs data.frame containing least following variables: reference date (index date interest), report_date (report date observations), new_confirm (incident observations reference report date). character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling","code":""},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_cumulative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate cumulative reported cases from incidence of new reports — enw_incidence_to_cumulative","text":"input data.frame new variable confirm.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_cumulative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate cumulative reported cases from incidence of new reports — enw_incidence_to_cumulative","text":"","code":"# Default reconstruct incidence dt <- germany_covid19_hosp[location == \"DE\"][age_group == \"00+\"] dt <- enw_add_incidence(dt) dt <- dt[, confirm := NULL] enw_add_cumulative(dt) #>        reference_date location age_group report_date new_confirm delay confirm #>     1:     2021-04-06       DE       00+  2021-04-06         149     0     149 #>     2:     2021-04-06       DE       00+  2021-04-07         140     1     289 #>     3:     2021-04-06       DE       00+  2021-04-08          61     2     350 #>     4:     2021-04-06       DE       00+  2021-04-09          52     3     402 #>     5:     2021-04-06       DE       00+  2021-04-10          36     4     438 #>    ---                                                                         #> 12911:     2021-10-18       DE       00+  2021-10-19          70     1     113 #> 12912:     2021-10-18       DE       00+  2021-10-20          29     2     142 #> 12913:     2021-10-19       DE       00+  2021-10-19         223     0     223 #> 12914:     2021-10-19       DE       00+  2021-10-20         164     1     387 #> 12915:     2021-10-20       DE       00+  2021-10-20         235     0     235  # Make use of maximum reported to calculate empirical daily reporting enw_add_cumulative(dt) #>        reference_date location age_group report_date new_confirm delay confirm #>     1:     2021-04-06       DE       00+  2021-04-06         149     0     149 #>     2:     2021-04-06       DE       00+  2021-04-07         140     1     289 #>     3:     2021-04-06       DE       00+  2021-04-08          61     2     350 #>     4:     2021-04-06       DE       00+  2021-04-09          52     3     402 #>     5:     2021-04-06       DE       00+  2021-04-10          36     4     438 #>    ---                                                                         #> 12911:     2021-10-18       DE       00+  2021-10-19          70     1     113 #> 12912:     2021-10-18       DE       00+  2021-10-20          29     2     142 #> 12913:     2021-10-19       DE       00+  2021-10-19         223     0     223 #> 12914:     2021-10-19       DE       00+  2021-10-20         164     1     387 #> 12915:     2021-10-20       DE       00+  2021-10-20         235     0     235"},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_linelist.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Aggregate Counts (Incidence) to a Line List — enw_incidence_to_linelist","title":"Convert Aggregate Counts (Incidence) to a Line List — enw_incidence_to_linelist","text":"function takes data.table aggregate counts something coercible data.table (data.frame) converts line list row represents case.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_linelist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Aggregate Counts (Incidence) to a Line List — enw_incidence_to_linelist","text":"","code":"enw_incidence_to_linelist(   obs,   reference_date = \"reference_date\",   report_date = \"report_date\" )"},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_linelist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Aggregate Counts (Incidence) to a Line List — enw_incidence_to_linelist","text":"obs object coercible data.table (data.frame) must new_confirm column. reference_date character string variable name use reference_date line list. default \"reference_date\". report_date character string variable name use report_date line list. default \"report_date\".","code":""},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_linelist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Aggregate Counts (Incidence) to a Line List — enw_incidence_to_linelist","text":"data.table following variables: id, reference_date, report_date, variables obs object. Rows obs duplicated based new_confirm column. reference_date report_date may renamed reference_date report_date supplied.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_incidence_to_linelist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Aggregate Counts (Incidence) to a Line List — enw_incidence_to_linelist","text":"","code":"incidence <- enw_add_incidence(germany_covid19_hosp) incidence <- enw_filter_reference_dates(   incidence[location %in% \"DE\"], include_days = 10 ) enw_incidence_to_linelist(incidence, reference_date = \"onset_date\") #>           id onset_date location age_group report_date delay #>     1:     1 2021-10-10       DE       00+  2021-10-10     0 #>     2:     2 2021-10-10       DE       00+  2021-10-10     0 #>     3:     3 2021-10-10       DE       00+  2021-10-10     0 #>     4:     4 2021-10-10       DE       00+  2021-10-10     0 #>     5:     5 2021-10-10       DE       00+  2021-10-10     0 #>    ---                                                       #> 18753: 18753 2021-10-20       DE       80+  2021-10-20     6 #> 18754: 18754 2021-10-20       DE       80+  2021-10-20     6 #> 18755: 18755 2021-10-20       DE       80+  2021-10-20     6 #> 18756: 18756 2021-10-20       DE       80+  2021-10-20     6 #> 18757: 18757 2021-10-20       DE       80+  2021-10-20     6"},{"path":"package.epinowcast.org/dev/reference/enw_latest_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter observations to the latest available reported — enw_latest_data","title":"Filter observations to the latest available reported — enw_latest_data","text":"Filter observations latest available reported data reference date. Note filtering maximum report date cases data may updated maximum number days.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_latest_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter observations to the latest available reported — enw_latest_data","text":"","code":"enw_latest_data(obs)"},{"path":"package.epinowcast.org/dev/reference/enw_latest_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter observations to the latest available reported — enw_latest_data","text":"obs data.frame; must report_date reference_date columns.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_latest_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter observations to the latest available reported — enw_latest_data","text":"data.table observations filtered latest available data reference date.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_latest_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter observations to the latest available reported — enw_latest_data","text":"","code":"# Filter for latest reported data enw_latest_data(germany_covid19_hosp) #>        reference_date location age_group confirm report_date #>     1:     2021-04-06       DE       00+     708  2021-06-26 #>     2:     2021-04-06       DE     00-04      11  2021-06-26 #>     3:     2021-04-06       DE     05-14       5  2021-06-26 #>     4:     2021-04-06       DE     15-34      75  2021-06-26 #>     5:     2021-04-06       DE     35-59     192  2021-06-26 #>    ---                                                       #> 23558:     2021-10-20    DE-TH     05-14       1  2021-10-20 #> 23559:     2021-10-20    DE-TH     15-34       2  2021-10-20 #> 23560:     2021-10-20    DE-TH     35-59       1  2021-10-20 #> 23561:     2021-10-20    DE-TH     60-79       5  2021-10-20 #> 23562:     2021-10-20    DE-TH       80+       5  2021-10-20"},{"path":"package.epinowcast.org/dev/reference/enw_linelist_to_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a Line List to Aggregate Counts (Incidence) — enw_linelist_to_incidence","title":"Convert a Line List to Aggregate Counts (Incidence) — enw_linelist_to_incidence","text":"function takes line list (.e. tabular data row represents case) aggregates count (new_confirm) cases user-specified reference_dates report_dates. enables use enw_preprocess_data() epinowcast() preprocessing functions.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_linelist_to_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a Line List to Aggregate Counts (Incidence) — enw_linelist_to_incidence","text":"","code":"enw_linelist_to_incidence(   linelist,   reference_date = \"reference_date\",   report_date = \"report_date\",   by = NULL,   max_delay,   completion_beyond_max_report = FALSE,   copy = TRUE )"},{"path":"package.epinowcast.org/dev/reference/enw_linelist_to_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a Line List to Aggregate Counts (Incidence) — enw_linelist_to_incidence","text":"linelist object coercible data.table (data.frame) row represents case. Must contain least two date variables variables can coerced dates. reference_date date variable can coerced date represents date interest case. example, reference_date date symptom onset new_confirm number new cases reported (based report_date) day onset day. default \"reference_date\". report_date date variable can coerced date represents date case reported. default \"report_date\". character vector variables also aggregate (.e. well using reference_date report_date). supplied function aggregate just reference_date report_date. max_delay maximum number days reference_date report_date. supplied function use maximum number days reference_date report_date linelist. max_delay less maximum number days reference_date report_date linelist function use value instead inform user. completion_beyond_max_report Logical, entries completed beyond maximum date found data? Default: FALSE copy obs copied (default) modified place?","code":""},{"path":"package.epinowcast.org/dev/reference/enw_linelist_to_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a Line List to Aggregate Counts (Incidence) — enw_linelist_to_incidence","text":"data.table following variables: reference_date, report_date, new_confirm, confirm, delay, variables specified .","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_linelist_to_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a Line List to Aggregate Counts (Incidence) — enw_linelist_to_incidence","text":"","code":"linelist <- data.frame(   onset_date = as.Date(c(\"2021-01-02\", \"2021-01-03\", \"2021-01-02\")),   report_date = as.Date(c(\"2021-01-03\", \"2021-01-05\", \"2021-01-04\")) ) enw_linelist_to_incidence(linelist, reference_date = \"onset_date\") #> Using the maximum observed delay of 4 days to complete the incidence data. #>     report_date reference_date new_confirm confirm delay #>  1:  2021-01-02           <NA>           0       0     0 #>  2:  2021-01-03           <NA>           0       0     1 #>  3:  2021-01-04           <NA>           0       0     2 #>  4:  2021-01-05           <NA>           0       0     3 #>  5:  2021-01-02     2021-01-02           0       0     0 #>  6:  2021-01-03     2021-01-02           1       1     1 #>  7:  2021-01-04     2021-01-02           1       2     2 #>  8:  2021-01-05     2021-01-02           0       2     3 #>  9:  2021-01-03     2021-01-03           0       0     0 #> 10:  2021-01-04     2021-01-03           0       0     1 #> 11:  2021-01-05     2021-01-03           1       1     2 #> 12:  2021-01-04     2021-01-04           0       0     0 #> 13:  2021-01-05     2021-01-04           0       0     1 #> 14:  2021-01-05     2021-01-05           0       0     0  # Specify a custom maximum delay and allow completion beyond the maximum # observed delay enw_linelist_to_incidence(  linelist, reference_date = \"onset_date\", max_delay = 5,  completion_beyond_max_report = TRUE ) #>     report_date reference_date new_confirm confirm delay #>  1:  2021-01-02           <NA>           0       0     0 #>  2:  2021-01-03           <NA>           0       0     1 #>  3:  2021-01-04           <NA>           0       0     2 #>  4:  2021-01-05           <NA>           0       0     3 #>  5:  2021-01-02     2021-01-02           0       0     0 #>  6:  2021-01-03     2021-01-02           1       1     1 #>  7:  2021-01-04     2021-01-02           1       2     2 #>  8:  2021-01-05     2021-01-02           0       2     3 #>  9:  2021-01-06     2021-01-02           0       2     4 #> 10:  2021-01-07     2021-01-02           0       2     5 #> 11:  2021-01-03     2021-01-03           0       0     0 #> 12:  2021-01-04     2021-01-03           0       0     1 #> 13:  2021-01-05     2021-01-03           1       1     2 #> 14:  2021-01-06     2021-01-03           0       1     3 #> 15:  2021-01-07     2021-01-03           0       1     4 #> 16:  2021-01-08     2021-01-03           0       1     5 #> 17:  2021-01-04     2021-01-04           0       0     0 #> 18:  2021-01-05     2021-01-04           0       0     1 #> 19:  2021-01-06     2021-01-04           0       0     2 #> 20:  2021-01-07     2021-01-04           0       0     3 #> 21:  2021-01-08     2021-01-04           0       0     4 #> 22:  2021-01-09     2021-01-04           0       0     5 #> 23:  2021-01-05     2021-01-05           0       0     0 #> 24:  2021-01-06     2021-01-05           0       0     1 #> 25:  2021-01-07     2021-01-05           0       0     2 #> 26:  2021-01-08     2021-01-05           0       0     3 #> 27:  2021-01-09     2021-01-05           0       0     4 #> 28:  2021-01-10     2021-01-05           0       0     5 #>     report_date reference_date new_confirm confirm delay"},{"path":"package.epinowcast.org/dev/reference/enw_manual_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a model manually using fixed and random effects — enw_manual_formula","title":"Define a model manually using fixed and random effects — enw_manual_formula","text":"typical use cases enw_formula() provide sufficient flexibility allow models defined. However, may instances manual model specification required. function supports allowing user supply vectors fixed, random, customised random effects (first treated fixed effect terms). Prior 1.0.0 main interface specifying models still used internally handle parts model specification process.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_manual_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a model manually using fixed and random effects — enw_manual_formula","text":"","code":"enw_manual_formula(   data,   fixed = NULL,   random = NULL,   custom_random = NULL,   no_contrasts = FALSE,   add_intercept = TRUE )"},{"path":"package.epinowcast.org/dev/reference/enw_manual_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a model manually using fixed and random effects — enw_manual_formula","text":"data data.frame observations. must include variables used supplied formula. fixed character vector fixed effects. random character vector random effects. Random effects specified added fixed effects. custom_random vector random effects. Random effects added added vector fixed effects. can used random effects fixed effects partial name match. no_contrasts Logical, defaults FALSE. TRUE means variable uses contrast. Alternatively character vector variables can supplied indicating variables  contrasts. add_intercept Logical, defaults FALSE. intercept added fixed effects.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_manual_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a model manually using fixed and random effects — enw_manual_formula","text":"list specifying fixed effects (formula, design matrix, design matrix index), random effects (formula design matrix).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_manual_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a model manually using fixed and random effects — enw_manual_formula","text":"","code":"data <- enw_example(\"prep\")$metareference[[1]] enw_manual_formula(data, fixed = \"week\", random = \"day_of_week\") #> $fixed #> $fixed$formula #> [1] \"~1 + week + day_of_week\" #>  #> $fixed$design #>    (Intercept) week day_of_weekFriday day_of_weekMonday day_of_weekSaturday #> 1            1    0                 0                 0                   0 #> 2            1    0                 0                 0                   0 #> 3            1    0                 0                 0                   0 #> 4            1    0                 1                 0                   0 #> 5            1    0                 0                 0                   1 #> 6            1    0                 0                 0                   0 #> 7            1    0                 0                 1                   0 #> 8            1    1                 0                 0                   0 #> 9            1    1                 0                 0                   0 #> 10           1    1                 0                 0                   0 #> 11           1    1                 1                 0                   0 #> 12           1    1                 0                 0                   1 #> 13           1    1                 0                 0                   0 #> 14           1    1                 0                 1                   0 #> 15           1    2                 0                 0                   0 #> 16           1    2                 0                 0                   0 #> 17           1    2                 0                 0                   0 #> 18           1    2                 1                 0                   0 #> 19           1    2                 0                 0                   1 #> 20           1    2                 0                 0                   0 #> 21           1    2                 0                 1                   0 #> 22           1    3                 0                 0                   0 #> 23           1    3                 0                 0                   0 #> 24           1    3                 0                 0                   0 #> 25           1    3                 1                 0                   0 #> 26           1    3                 0                 0                   1 #> 27           1    3                 0                 0                   0 #> 28           1    3                 0                 1                   0 #> 29           1    4                 0                 0                   0 #> 30           1    4                 0                 0                   0 #> 31           1    4                 0                 0                   0 #> 32           1    4                 1                 0                   0 #> 33           1    4                 0                 0                   1 #> 34           1    4                 0                 0                   0 #> 35           1    4                 0                 1                   0 #> 36           1    5                 0                 0                   0 #> 37           1    5                 0                 0                   0 #> 38           1    5                 0                 0                   0 #> 39           1    5                 1                 0                   0 #> 40           1    5                 0                 0                   1 #> 41           1    5                 0                 0                   0 #>    day_of_weekSunday day_of_weekThursday day_of_weekTuesday #> 1                  0                   0                  1 #> 2                  0                   0                  0 #> 3                  0                   1                  0 #> 4                  0                   0                  0 #> 5                  0                   0                  0 #> 6                  1                   0                  0 #> 7                  0                   0                  0 #> 8                  0                   0                  1 #> 9                  0                   0                  0 #> 10                 0                   1                  0 #> 11                 0                   0                  0 #> 12                 0                   0                  0 #> 13                 1                   0                  0 #> 14                 0                   0                  0 #> 15                 0                   0                  1 #> 16                 0                   0                  0 #> 17                 0                   1                  0 #> 18                 0                   0                  0 #> 19                 0                   0                  0 #> 20                 1                   0                  0 #> 21                 0                   0                  0 #> 22                 0                   0                  1 #> 23                 0                   0                  0 #> 24                 0                   1                  0 #> 25                 0                   0                  0 #> 26                 0                   0                  0 #> 27                 1                   0                  0 #> 28                 0                   0                  0 #> 29                 0                   0                  1 #> 30                 0                   0                  0 #> 31                 0                   1                  0 #> 32                 0                   0                  0 #> 33                 0                   0                  0 #> 34                 1                   0                  0 #> 35                 0                   0                  0 #> 36                 0                   0                  1 #> 37                 0                   0                  0 #> 38                 0                   1                  0 #> 39                 0                   0                  0 #> 40                 0                   0                  0 #> 41                 1                   0                  0 #>    day_of_weekWednesday #> 1                     0 #> 2                     1 #> 3                     0 #> 4                     0 #> 5                     0 #> 6                     0 #> 7                     0 #> 8                     0 #> 9                     1 #> 10                    0 #> 11                    0 #> 12                    0 #> 13                    0 #> 14                    0 #> 15                    0 #> 16                    1 #> 17                    0 #> 18                    0 #> 19                    0 #> 20                    0 #> 21                    0 #> 22                    0 #> 23                    1 #> 24                    0 #> 25                    0 #> 26                    0 #> 27                    0 #> 28                    0 #> 29                    0 #> 30                    1 #> 31                    0 #> 32                    0 #> 33                    0 #> 34                    0 #> 35                    0 #> 36                    0 #> 37                    1 #> 38                    0 #> 39                    0 #> 40                    0 #> 41                    0 #>  #> $fixed$index #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #> [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #>  #>  #> $random #> $random$formula #> [1] \"~0 + fixed + day_of_week\" #>  #> $random$design #>   fixed day_of_week #> 1     1           0 #> 2     0           1 #> 3     0           1 #> 4     0           1 #> 5     0           1 #> 6     0           1 #> 7     0           1 #> 8     0           1 #> attr(,\"assign\") #> [1] 1 2 #>  #> $random$index #> [1] 1 2 3 4 5 6 7 8 #>  #>"},{"path":"package.epinowcast.org/dev/reference/enw_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract metadata from raw data — enw_metadata","title":"Extract metadata from raw data — enw_metadata","text":"Extract metadata raw data, either reference report date. target date chosen (reference report), confirm, max_confirm``, cum_prop_reported` dropped first observation group date retained.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract metadata from raw data — enw_metadata","text":"","code":"enw_metadata(obs, target_date = c(\"reference_date\", \"report_date\"))"},{"path":"package.epinowcast.org/dev/reference/enw_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract metadata from raw data — enw_metadata","text":"obs data.frame data.table columns: reference_date /report_date; least one must provided, .group, grouping column date, Date column. target_date character string, either \"reference_date\" \"report_date\". column corresponding string used target date metadata extraction.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract metadata from raw data — enw_metadata","text":"data.table columns: date, Date column .group, grouping column first observation group date. data.table sorted .group date.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract metadata from raw data — enw_metadata","text":"","code":"obs <- data.frame(  reference_date = as.Date(\"2021-01-01\"),  report_date = as.Date(\"2022-01-01\"), x = 1:10 ) enw_metadata(obs, target_date = \"reference_date\") #>          date .group x #> 1: 2021-01-01      1 1"},{"path":"package.epinowcast.org/dev/reference/enw_missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Missing reference data model module — enw_missing","title":"Missing reference data model module — enw_missing","text":"Missing reference data model module","code":""},{"path":"package.epinowcast.org/dev/reference/enw_missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Missing reference data model module — enw_missing","text":"","code":"enw_missing(formula = ~1, data)"},{"path":"package.epinowcast.org/dev/reference/enw_missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Missing reference data model module — enw_missing","text":"formula formula (implemented enw_formula()) describing missing data proportion logit scale reference date. can use features defined reference date defined metareference produced enw_preprocess_data(). \"~0\" implies model required. Otherwise intercept always needed data Output enw_preprocess_data().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_missing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Missing reference data model module — enw_missing","text":"list containing supplied formulas, data passed list describing models, data.frame describing priors used, function takes output data priors returns function can used sample tightened version prior distribution.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_missing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Missing reference data model module — enw_missing","text":"","code":"# Missing model with a fixed intercept only enw_missing(data = enw_example(\"preprocessed\")) #> $formula #> [1] \"~1\" #>  #> $data #> $data$miss_fdesign #>    (Intercept) #> 1            1 #> 2            1 #> 3            1 #> 4            1 #> 5            1 #> 6            1 #> 7            1 #> 8            1 #> 9            1 #> 10           1 #> 11           1 #> 12           1 #> 13           1 #> 14           1 #> 15           1 #> 16           1 #> 17           1 #> 18           1 #> 19           1 #> 20           1 #> 21           1 #> 22           1 #> 23           1 #> 24           1 #> 25           1 #> 26           1 #> 27           1 #> 28           1 #> 29           1 #> 30           1 #> 31           1 #> 32           1 #> 33           1 #> 34           1 #> 35           1 #> 36           1 #> 37           1 #> 38           1 #> 39           1 #> 40           1 #> 41           1 #> attr(,\"assign\") #> [1] 0 #>  #> $data$miss_fintercept #> [1] 1 #>  #> $data$miss_fnrow #> [1] 41 #>  #> $data$miss_findex #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #> [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #>  #> $data$miss_fnindex #> [1] 41 #>  #> $data$miss_fncol #> [1] 0 #>  #> $data$miss_rdesign #>      (Intercept) #> attr(,\"assign\") #> [1] 0 #>  #> $data$miss_rncol #> [1] 0 #>  #> $data$miss_st #> [1] 22 #>  #> $data$miss_cst #> [1] 22 #>  #> $data$missing_reference #>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 #>  #> $data$obs_by_report #>         0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17 #>  [1,] 381 362 343 324 305 286 267 248 229 210 191 172 153 134 115  96  77  58 #>  [2,] 401 382 363 344 325 306 287 268 249 230 211 192 173 154 135 116  97  78 #>  [3,] 421 402 383 364 345 326 307 288 269 250 231 212 193 174 155 136 117  98 #>  [4,] 441 422 403 384 365 346 327 308 289 270 251 232 213 194 175 156 137 118 #>  [5,] 461 442 423 404 385 366 347 328 309 290 271 252 233 214 195 176 157 138 #>  [6,] 481 462 443 424 405 386 367 348 329 310 291 272 253 234 215 196 177 158 #>  [7,] 501 482 463 444 425 406 387 368 349 330 311 292 273 254 235 216 197 178 #>  [8,] 521 502 483 464 445 426 407 388 369 350 331 312 293 274 255 236 217 198 #>  [9,] 541 522 503 484 465 446 427 408 389 370 351 332 313 294 275 256 237 218 #> [10,] 561 542 523 504 485 466 447 428 409 390 371 352 333 314 295 276 257 238 #> [11,] 581 562 543 524 505 486 467 448 429 410 391 372 353 334 315 296 277 258 #> [12,] 601 582 563 544 525 506 487 468 449 430 411 392 373 354 335 316 297 278 #> [13,] 621 602 583 564 545 526 507 488 469 450 431 412 393 374 355 336 317 298 #> [14,] 641 622 603 584 565 546 527 508 489 470 451 432 413 394 375 356 337 318 #> [15,] 661 642 623 604 585 566 547 528 509 490 471 452 433 414 395 376 357 338 #> [16,] 681 662 643 624 605 586 567 548 529 510 491 472 453 434 415 396 377 358 #> [17,] 701 682 663 644 625 606 587 568 549 530 511 492 473 454 435 416 397 378 #> [18,] 721 702 683 664 645 626 607 588 569 550 531 512 493 474 455 436 417 398 #> [19,] 741 722 703 684 665 646 627 608 589 570 551 532 513 494 475 456 437 418 #> [20,] 761 742 723 704 685 666 647 628 609 590 571 552 533 514 495 476 457 438 #> [21,] 781 762 743 724 705 686 667 648 629 610 591 572 553 534 515 496 477 458 #> [22,] 801 782 763 744 725 706 687 668 649 630 611 592 573 554 535 516 497 478 #>        18  19 #>  [1,]  39  20 #>  [2,]  59  40 #>  [3,]  79  60 #>  [4,]  99  80 #>  [5,] 119 100 #>  [6,] 139 120 #>  [7,] 159 140 #>  [8,] 179 160 #>  [9,] 199 180 #> [10,] 219 200 #> [11,] 239 220 #> [12,] 259 240 #> [13,] 279 260 #> [14,] 299 280 #> [15,] 319 300 #> [16,] 339 320 #> [17,] 359 340 #> [18,] 379 360 #> [19,] 399 380 #> [20,] 419 400 #> [21,] 439 420 #> [22,] 459 440 #>  #> $data$model_miss #> [1] 1 #>  #> $data$miss_obs #> [1] 22 #>  #>  #> $priors #>        variable #> 1:     miss_int #> 2: miss_beta_sd #>                                                                         description #> 1:          Intercept on the logit scale for the proportion missing reference dates #> 2: Standard deviation of scaled pooled logit missing reference date\\n       effects #>             distribution mean sd #> 1:                Normal    0  1 #> 2: Zero truncated normal    0  1 #>  #> $inits #> function (data, priors)  #> { #>     priors <- enw_priors_as_data_list(priors) #>     fn <- function() { #>         init <- list(miss_int = numeric(0), miss_beta = numeric(0),  #>             miss_beta_sd = numeric(0)) #>         if (data$model_miss) { #>             init$miss_int <- array(rnorm(1, priors$miss_int_p[1],  #>                 priors$miss_int_p[2])) #>             if (data$miss_fncol > 0) { #>                 init$miss_beta <- array(rnorm(data$miss_fncol,  #>                   0, 0.01)) #>             } #>             if (data$miss_rncol > 0) { #>                 init$miss_beta_sd <- array(abs(rnorm(data$miss_rncol,  #>                   priors$miss_beta_sd_p[1], priors$miss_beta_sd_p[2]/10))) #>             } #>         } #>         return(init) #>     } #>     return(fn) #> } #> <bytecode: 0x560700c726a8> #> <environment: 0x560700c6f128> #>   # No missingness model specified enw_missing(~0, data = enw_example(\"preprocessed\")) #> $formula #> [1] \"~0\" #>  #> $data #> $data$miss_fdesign #> numeric(0) #>  #> $data$miss_fintercept #> [1] 0 #>  #> $data$miss_fnrow #> [1] 0 #>  #> $data$miss_findex #> numeric(0) #>  #> $data$miss_fnindex #> [1] 0 #>  #> $data$miss_fncol #> [1] 0 #>  #> $data$miss_rdesign #> numeric(0) #>  #> $data$miss_rncol #> [1] 0 #>  #> $data$missing_reference #> numeric(0) #>  #> $data$obs_by_report #> numeric(0) #>  #> $data$miss_st #> numeric(0) #>  #> $data$miss_cst #> numeric(0) #>  #> $data$model_miss #> [1] 0 #>  #> $data$miss_obs #> [1] 0 #>  #>  #> $priors #>        variable #> 1:     miss_int #> 2: miss_beta_sd #>                                                                         description #> 1:          Intercept on the logit scale for the proportion missing reference dates #> 2: Standard deviation of scaled pooled logit missing reference date\\n       effects #>             distribution mean sd #> 1:                Normal    0  1 #> 2: Zero truncated normal    0  1 #>  #> $inits #> function (data, priors)  #> { #>     priors <- enw_priors_as_data_list(priors) #>     fn <- function() { #>         init <- list(miss_int = numeric(0), miss_beta = numeric(0),  #>             miss_beta_sd = numeric(0)) #>         if (data$model_miss) { #>             init$miss_int <- array(rnorm(1, priors$miss_int_p[1],  #>                 priors$miss_int_p[2])) #>             if (data$miss_fncol > 0) { #>                 init$miss_beta <- array(rnorm(data$miss_fncol,  #>                   0, 0.01)) #>             } #>             if (data$miss_rncol > 0) { #>                 init$miss_beta_sd <- array(abs(rnorm(data$miss_rncol,  #>                   priors$miss_beta_sd_p[1], priors$miss_beta_sd_p[2]/10))) #>             } #>         } #>         return(init) #>     } #>     return(fn) #> } #> <bytecode: 0x560700c726a8> #> <environment: 0x560700422538> #>"},{"path":"package.epinowcast.org/dev/reference/enw_missing_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract reports with missing reference dates — enw_missing_reference","title":"Extract reports with missing reference dates — enw_missing_reference","text":"Returns reports missing reference dates well calculating proportion reports given reference date missing.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_missing_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract reports with missing reference dates — enw_missing_reference","text":"","code":"enw_missing_reference(obs)"},{"path":"package.epinowcast.org/dev/reference/enw_missing_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract reports with missing reference dates — enw_missing_reference","text":"obs data.frame produced enw_add_incidence(). Must contain following variables: report_date, reference_date, .group, confirm, new_confirm.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_missing_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract reports with missing reference dates — enw_missing_reference","text":"data.table missing counts proportions report date group.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_missing_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract reports with missing reference dates — enw_missing_reference","text":"","code":"obs <- data.frame(   report_date = c(\"2021-10-01\", \"2021-10-03\"), reference_date = \"2021-10-01\",   confirm = 1 ) obs <- rbind(   obs,   data.frame(report_date = \"2021-10-04\", reference_date = NA, confirm = 4) ) obs <- enw_complete_dates(obs) obs <- enw_assign_group(obs) obs <- enw_add_incidence(obs) enw_missing_reference(obs) #>    report_date .group confirm prop_missing #> 1:  2021-10-01      1       0            0 #> 2:  2021-10-02      1       0          NaN #> 3:  2021-10-03      1       0          NaN #> 4:  2021-10-04      1       4            1"},{"path":"package.epinowcast.org/dev/reference/enw_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Load and compile the nowcasting model — enw_model","title":"Load and compile the nowcasting model — enw_model","text":"Load compile nowcasting model","code":""},{"path":"package.epinowcast.org/dev/reference/enw_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load and compile the nowcasting model — enw_model","text":"","code":"enw_model(   model = system.file(\"stan\", \"epinowcast.stan\", package = \"epinowcast\"),   include = system.file(\"stan\", package = \"epinowcast\"),   compile = TRUE,   threads = FALSE,   profile = FALSE,   target_dir = tempdir(),   stanc_options = list(),   cpp_options = list(),   verbose = TRUE,   ... )"},{"path":"package.epinowcast.org/dev/reference/enw_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load and compile the nowcasting model — enw_model","text":"model character string indicating path model. supplied package default model used. include character string specifying path stan files include model. missing package default used. compile Logical, defaults TRUE. model loaded compiled using cmdstanr::cmdstan_model(). threads Logical, defaults FALSE. model compile support multi-thread support chain. Note requires use threads_per_chain argument model fitting using enw_sample(), epinowcast(). profile Logical, defaults FALSE. model profiled? profiling see cmdstanr documentation. # nolint target_dir path directory manipulated .stan files without profiling statements stored. avoid overriding original .stan files, different directory original model include_paths. stanc_options list options pass stanc_options cmdstanr::cmdstan_model(). default nothing passed potentially users may wish pass optimisation flags example. See documentation cmdstanr::cmdstan_model() details. cpp_options list options pass cpp_options cmdstanr::cmdstan_model(). default nothing passed potentially users may wish pass optimisation flags example. See documentation cmdstanr::cmdstan_model() details. Note threads argument replaces stan_threads. verbose Logical, defaults TRUE. verbose messages shown. ... Additional arguments passed cmdstanr::cmdstan_model().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load and compile the nowcasting model — enw_model","text":"cmdstanr model.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load and compile the nowcasting model — enw_model","text":"","code":"if (FALSE) { # interactive() mod <- enw_model() }"},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract posterior samples for the nowcast prediction — enw_nowcast_samples","title":"Extract posterior samples for the nowcast prediction — enw_nowcast_samples","text":"generic wrapper around posterior::draws_df() opinionated defaults extract posterior samples nowcast (\"pp_inf_obs\" stan code). functionality function can used directly output epinowcast() using supplied summary.epinowcast() method.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract posterior samples for the nowcast prediction — enw_nowcast_samples","text":"","code":"enw_nowcast_samples(fit, obs, timestep = \"day\")"},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract posterior samples for the nowcast prediction — enw_nowcast_samples","text":"fit cmdstanr fit object. obs observation data.frame containing reference_date columns length number rows posterior date observation date. used align posterior observations. easiest source data output latest output enw_preprocess_data() enw_latest_data(). timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract posterior samples for the nowcast prediction — enw_nowcast_samples","text":"data.frame posterior samples nowcast prediction. uses observed data available posterior prediction .","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_samples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract posterior samples for the nowcast prediction — enw_nowcast_samples","text":"","code":"fit <- enw_example(\"nowcast\") enw_nowcast_samples(fit$fit[[1]], fit$latest[[1]]) #>        reference_date report_date .group max_confirm location age_group confirm #>     1:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>     2:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>     3:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>     4:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>     5:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>    ---                                                                          #> 19996:     2021-08-22  2021-08-22      1          45       DE       00+      45 #> 19997:     2021-08-22  2021-08-22      1          45       DE       00+      45 #> 19998:     2021-08-22  2021-08-22      1          45       DE       00+      45 #> 19999:     2021-08-22  2021-08-22      1          45       DE       00+      45 #> 20000:     2021-08-22  2021-08-22      1          45       DE       00+      45 #>        cum_prop_reported delay prop_reported .chain .iteration .draw sample #>     1:                 1    19             0      1          1     1    149 #>     2:                 1    19             0      1          2     2    149 #>     3:                 1    19             0      1          3     3    149 #>     4:                 1    19             0      1          4     4    149 #>     5:                 1    19             0      1          5     5    149 #>    ---                                                                      #> 19996:                 1     0             1      2        496   996    350 #> 19997:                 1     0             1      2        497   997    584 #> 19998:                 1     0             1      2        498   998    324 #> 19999:                 1     0             1      2        499   999    385 #> 20000:                 1     0             1      2        500  1000    294"},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise the posterior nowcast prediction — enw_nowcast_summary","title":"Summarise the posterior nowcast prediction — enw_nowcast_summary","text":"generic wrapper around enw_posterior() opinionated defaults extract posterior prediction nowcast (\"pp_inf_obs\" stan code). functionality function can used directly output epinowcast() using supplied summary.epinowcast() method.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise the posterior nowcast prediction — enw_nowcast_summary","text":"","code":"enw_nowcast_summary(   fit,   obs,   probs = c(0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95),   timestep = \"day\" )"},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise the posterior nowcast prediction — enw_nowcast_summary","text":"fit cmdstanr fit object. obs observation data.frame containing reference_date columns length number rows posterior date observation date. used align posterior observations. easiest source data output latest output enw_preprocess_data() enw_latest_data(). probs vector numeric probabilities produce quantile summaries . default 5%, 20%, 80%, 95% quantiles also minimum set required plotting functions work. timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise the posterior nowcast prediction — enw_nowcast_summary","text":"data.frame summarising model posterior nowcast prediction. uses observed data available posterior prediction .","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_nowcast_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise the posterior nowcast prediction — enw_nowcast_summary","text":"","code":"fit <- enw_example(\"nowcast\") enw_nowcast_summary(fit$fit[[1]], fit$latest[[1]]) #>     reference_date report_date .group max_confirm location age_group confirm #>  1:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>  2:     2021-08-04  2021-08-22      1         166       DE       00+     166 #>  3:     2021-08-05  2021-08-22      1         133       DE       00+     133 #>  4:     2021-08-06  2021-08-22      1         137       DE       00+     137 #>  5:     2021-08-07  2021-08-22      1         139       DE       00+     139 #>  6:     2021-08-08  2021-08-22      1          97       DE       00+      97 #>  7:     2021-08-09  2021-08-22      1          58       DE       00+      58 #>  8:     2021-08-10  2021-08-22      1         175       DE       00+     175 #>  9:     2021-08-11  2021-08-22      1         233       DE       00+     233 #> 10:     2021-08-12  2021-08-22      1         237       DE       00+     237 #> 11:     2021-08-13  2021-08-22      1         204       DE       00+     204 #> 12:     2021-08-14  2021-08-22      1         189       DE       00+     189 #> 13:     2021-08-15  2021-08-22      1         125       DE       00+     125 #> 14:     2021-08-16  2021-08-22      1          98       DE       00+      98 #> 15:     2021-08-17  2021-08-22      1         242       DE       00+     242 #> 16:     2021-08-18  2021-08-22      1         223       DE       00+     223 #> 17:     2021-08-19  2021-08-22      1         202       DE       00+     202 #> 18:     2021-08-20  2021-08-22      1         171       DE       00+     171 #> 19:     2021-08-21  2021-08-22      1         112       DE       00+     112 #> 20:     2021-08-22  2021-08-22      1          45       DE       00+      45 #>     cum_prop_reported delay prop_reported    mean median         sd     mad #>  1:                 1    19   0.000000000 149.000  149.0   0.000000  0.0000 #>  2:                 1    18   0.000000000 167.440  167.0   1.306946  1.4826 #>  3:                 1    17   0.000000000 135.804  136.0   1.910297  1.4826 #>  4:                 1    16   0.000000000 141.039  141.0   2.336009  1.4826 #>  5:                 1    15   0.007194245 145.916  146.0   3.245223  2.9652 #>  6:                 1    14   0.000000000 103.674  103.0   3.004455  2.9652 #>  7:                 1    13   0.000000000  63.014   63.0   2.633769  2.9652 #>  8:                 1    12   0.000000000 185.131  185.0   3.861703  4.4478 #>  9:                 1    11   0.000000000 255.938  256.0   6.338796  5.9304 #> 10:                 1    10   0.004219409 267.445  267.0   7.795495  7.4130 #> 11:                 1     9   0.000000000 236.189  235.5   8.328183  8.1543 #> 12:                 1     8   0.015873016 230.969  230.0   9.851248  9.6369 #> 13:                 1     7   0.040000000 165.393  165.0  10.147883 10.3782 #> 14:                 1     6   0.010204082 129.419  129.0   8.341524  8.8956 #> 15:                 1     5   0.012396694 293.442  292.0  12.342730 11.8608 #> 16:                 1     4   0.017937220 292.867  292.0  15.235795 14.8260 #> 17:                 1     3   0.019801980 292.416  291.0  20.600906 19.2738 #> 18:                 1     2   0.070175439 294.685  291.0  29.652944 28.1694 #> 19:                 1     1   0.383928571 312.347  307.0  52.500656 50.4084 #> 20:                 1     0   1.000000000 377.870  363.0 106.473272 93.4038 #>         q5 q20    q35   q50    q65 q80    q95      rhat  ess_bulk  ess_tail #>  1: 149.00 149 149.00 149.0 149.00 149 149.00        NA        NA        NA #>  2: 166.00 166 167.00 167.0 168.00 168 170.00 0.9984731 1072.5191 1068.0041 #>  3: 133.00 134 135.00 136.0 136.00 137 139.00 1.0001748 1040.7197 1025.8570 #>  4: 138.00 139 140.00 141.0 142.00 143 145.00 0.9985918 1021.8261  829.9055 #>  5: 141.00 143 145.00 146.0 147.00 148 152.00 1.0014625 1036.5263  915.7683 #>  6:  99.00 101 102.00 103.0 105.00 106 109.00 1.0008170 1084.2564  888.0770 #>  7:  59.00  61  62.00  63.0  64.00  65  68.00 1.0001596 1170.0810  845.5932 #>  8: 179.00 182 183.00 185.0 186.00 188 192.00 1.0016498  826.3595  989.6300 #>  9: 246.00 251 253.00 256.0 258.00 261 267.00 1.0008653  976.1162  943.8214 #> 10: 256.00 261 264.00 267.0 270.00 274 281.00 1.0020121 1016.2724  988.2011 #> 11: 224.00 229 233.00 235.5 239.00 243 251.00 0.9993738 1119.8109  785.8675 #> 12: 216.00 223 227.00 230.0 234.00 239 247.00 0.9997526 1067.0426  980.9775 #> 13: 150.00 157 161.00 165.0 168.00 173 184.00 0.9989137 1252.9097  836.7735 #> 14: 116.00 122 126.00 129.0 132.00 136 144.00 1.0002835 1111.6597  956.2202 #> 15: 276.00 283 288.00 292.0 297.00 303 316.00 0.9993443 1076.8727  782.2336 #> 16: 271.00 279 286.00 292.0 297.00 305 320.05 1.0000165 1040.5391  767.7477 #> 17: 263.00 275 283.00 291.0 298.35 309 331.00 1.0007083  950.4381  731.4047 #> 18: 251.95 270 282.00 291.0 302.00 318 347.05 1.0031517 1230.4660  982.6347 #> 19: 237.00 269 287.65 307.0 327.00 351 403.15 1.0029817 1076.9075  871.5941 #> 20: 239.95 292 327.00 363.0 401.00 451 576.15 1.0034715 1394.6975  915.4979"},{"path":"package.epinowcast.org/dev/reference/enw_obs.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup observation model and data — enw_obs","title":"Setup observation model and data — enw_obs","text":"Setup observation model data","code":""},{"path":"package.epinowcast.org/dev/reference/enw_obs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup observation model and data — enw_obs","text":"","code":"enw_obs(family = c(\"negbin\", \"poisson\"), data)"},{"path":"package.epinowcast.org/dev/reference/enw_obs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup observation model and data — enw_obs","text":"family Character string, observation model use likelihood; enforced base::match.arg(). default negative binomial (\"negbin\") Poisson (\"poisson\") also available. Support additional observation models planned, please open issue suggestions. data Output enw_preprocess_data().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_obs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup observation model and data — enw_obs","text":"list required stan.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_obs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setup observation model and data — enw_obs","text":"","code":"enw_obs(data = enw_example(\"preprocessed\")) #> $family #> [1] \"negbin\" #>  #> $data #> $data$n #> [1] 630 #>  #> $data$t #> [1] 41 #>  #> $data$s #> [1] 41 #>  #> $data$g #> [1] 1 #>  #> $data$groups #> [1] 1 #>  #> $data$st #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #> [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #>  #> $data$ts #>        1 #>  [1,]  1 #>  [2,]  2 #>  [3,]  3 #>  [4,]  4 #>  [5,]  5 #>  [6,]  6 #>  [7,]  7 #>  [8,]  8 #>  [9,]  9 #> [10,] 10 #> [11,] 11 #> [12,] 12 #> [13,] 13 #> [14,] 14 #> [15,] 15 #> [16,] 16 #> [17,] 17 #> [18,] 18 #> [19,] 19 #> [20,] 20 #> [21,] 21 #> [22,] 22 #> [23,] 23 #> [24,] 24 #> [25,] 25 #> [26,] 26 #> [27,] 27 #> [28,] 28 #> [29,] 29 #> [30,] 30 #> [31,] 31 #> [32,] 32 #> [33,] 33 #> [34,] 34 #> [35,] 35 #> [36,] 36 #> [37,] 37 #> [38,] 38 #> [39,] 39 #> [40,] 40 #> [41,] 41 #>  #> $data$sl #>  [1] 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 19 18 17 #> [26] 16 15 14 13 12 11 10  9  8  7  6  5  4  3  2  1 #>  #> $data$csl #>  [1]  20  40  60  80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 #> [20] 400 420 440 459 477 494 510 525 539 552 564 575 585 594 602 609 615 620 624 #> [39] 627 629 630 #>  #> $data$sg #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #> [39] 1 1 1 #>  #> $data$dmax #> [1] 20 #>  #> $data$sdmax #>  [1] 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 #> [26] 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 #>  #> $data$csdmax #>  [1]  20  40  60  80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 #> [20] 400 420 440 460 480 500 520 540 560 580 600 620 640 660 680 700 720 740 760 #> [39] 780 800 820 #>  #> $data$obs #>        0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 #>  [1,] 21 12  3  4  3  0  1  2  4  3  0  0  2  0  0  0  1  2  1  0 #>  [2,] 22 12  4  5  0  1 10  2  5  3  0  1  0  3  1  0  1  0  0  0 #>  [3,] 28 15  3  3  0  1  3  2  3  2  1  0  2  3  0  3  0  0  0  0 #>  [4,] 19 13  0  0  0  4  2  2  2  1  1  1  0  1  0  0  1  0  0  0 #>  [5,] 20  7  1  3 10  3  0  4  3  3  2  0  1  2  0  1  2  1  0  0 #>  [6,]  9  6  6  0  4  5  4  0  1  4  0  0  1  1  1  2  0  0  0  2 #>  [7,]  3 16  4  4  1  1  2  0  0  0  0  1  1  1  1  0  0  0  1  0 #>  [8,] 36 19 10  4  2  3  0  3  2  3  0  2  1  1  2  2  0  0  1  0 #>  [9,] 28 18  8  4  1  2  3  6  1  5  2  2  3  0  2  0  1  0  0  0 #> [10,] 34 19  2  1  5  2  4  3  7  3  1  0  4  3  3  1  2  0  0  1 #> [11,] 30 12  4  1 10  6  0  2  2  1  2  1  4  0  2  3  0  0  4  0 #> [12,] 31  8  4  9  8  2  5  2  1  1  2  4  1  3  1  0  1  2  2  2 #> [13,]  8  4 14  8  6  5  1  3  0  4  1  2  4  2  0  1  2  2  2  0 #> [14,]  9  6  2  3  0  0  0  0  1  2  4  1  0  0  0  0  0  0  0  0 #> [15,] 35 11  6  4  4  1  0  2  2  2  2  0  0  1  4  1  0  0  0  0 #> [16,] 51 28 25  3  5  2  3  5  5  7  1  0  0  4  5  5  1  1  0  0 #> [17,] 47 37  9  2  2  3  4  4  4  3  0  2  0 10  4  3  0  0  0  0 #> [18,] 36 20  2  4 11  8  8  3  5  2  0  2  4  4  0  2  2  0  0  1 #> [19,] 38 16  3 15 14  7  5  5  0  0  5  0  5  1  6  0  0  3  1  0 #> [20,]  7  5  5 11  7  5  1  3  1  6  3  3  4  1  1  7  2  3  2  0 #> [21,] 13 13  8  6  1  3  2  0  0  2  0  2  0  5  3  0  0  0  0  1 #> [22,] 51 43  6  4  4  3  1  6  4  5  5  4  0  4  5  0  2  2  0  0 #> [23,] 51 43 18  5  6  1  2  8  7  7  6  1  0  4  3  1  3  0  0  0 #> [24,] 45 21  6  2  2 11 17  5  7  4  1  0  5  3  0  2  2  0  0  0 #> [25,] 47 31  5  4 20  6  1  9  3  1  0  2  1  5  2  0  0  0  0  0 #> [26,] 40 15  6 23 14 13  8  9  0  1  3  3  2  0  1  1  0  0  0  0 #> [27,] 13 14 27 14  7  7  0  0  0  7  1  4  2  1  0  0  0  0  0  0 #> [28,] 14 23 11  3  1  1  0  0  0  1  0  2  2  0  0  0  0  0  0  0 #> [29,] 78 43 23 11  5  1  0  5  2  2  1  4  0  0  0  0  0  0  0  0 #> [30,] 80 53 17 15  7  3 14 12 13 13  6  0  0  0  0  0  0  0  0  0 #> [31,] 89 48 28  8  1 14 13 13 10 12  1  0  0  0  0  0  0  0  0  0 #> [32,] 86 44  9  3 27 13  7 11  4  0  0  0  0  0  0  0  0  0  0  0 #> [33,] 79 36  7 16 19 13  8  8  3  0  0  0  0  0  0  0  0  0  0  0 #> [34,] 22 24 35 18 10  4  7  5  0  0  0  0  0  0  0  0  0  0  0  0 #> [35,] 23 32 22 10  8  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0 #> [36,] 96 85 30 18 10  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> [37,] 92 86 23 18  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> [38,] 84 87 27  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> [39,] 98 61 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> [40,] 69 43  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> [41,] 45  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>  #> $data$flat_obs #>   [1] 21 12  3  4  3  0  1  2  4  3  0  0  2  0  0  0  1  2  1  0 22 12  4  5  0 #>  [26]  1 10  2  5  3  0  1  0  3  1  0  1  0  0  0 28 15  3  3  0  1  3  2  3  2 #>  [51]  1  0  2  3  0  3  0  0  0  0 19 13  0  0  0  4  2  2  2  1  1  1  0  1  0 #>  [76]  0  1  0  0  0 20  7  1  3 10  3  0  4  3  3  2  0  1  2  0  1  2  1  0  0 #> [101]  9  6  6  0  4  5  4  0  1  4  0  0  1  1  1  2  0  0  0  2  3 16  4  4  1 #> [126]  1  2  0  0  0  0  1  1  1  1  0  0  0  1  0 36 19 10  4  2  3  0  3  2  3 #> [151]  0  2  1  1  2  2  0  0  1  0 28 18  8  4  1  2  3  6  1  5  2  2  3  0  2 #> [176]  0  1  0  0  0 34 19  2  1  5  2  4  3  7  3  1  0  4  3  3  1  2  0  0  1 #> [201] 30 12  4  1 10  6  0  2  2  1  2  1  4  0  2  3  0  0  4  0 31  8  4  9  8 #> [226]  2  5  2  1  1  2  4  1  3  1  0  1  2  2  2  8  4 14  8  6  5  1  3  0  4 #> [251]  1  2  4  2  0  1  2  2  2  0  9  6  2  3  0  0  0  0  1  2  4  1  0  0  0 #> [276]  0  0  0  0  0 35 11  6  4  4  1  0  2  2  2  2  0  0  1  4  1  0  0  0  0 #> [301] 51 28 25  3  5  2  3  5  5  7  1  0  0  4  5  5  1  1  0  0 47 37  9  2  2 #> [326]  3  4  4  4  3  0  2  0 10  4  3  0  0  0  0 36 20  2  4 11  8  8  3  5  2 #> [351]  0  2  4  4  0  2  2  0  0  1 38 16  3 15 14  7  5  5  0  0  5  0  5  1  6 #> [376]  0  0  3  1  0  7  5  5 11  7  5  1  3  1  6  3  3  4  1  1  7  2  3  2  0 #> [401] 13 13  8  6  1  3  2  0  0  2  0  2  0  5  3  0  0  0  0  1 51 43  6  4  4 #> [426]  3  1  6  4  5  5  4  0  4  5  0  2  2  0  0 51 43 18  5  6  1  2  8  7  7 #> [451]  6  1  0  4  3  1  3  0  0 45 21  6  2  2 11 17  5  7  4  1  0  5  3  0  2 #> [476]  2  0 47 31  5  4 20  6  1  9  3  1  0  2  1  5  2  0  0 40 15  6 23 14 13 #> [501]  8  9  0  1  3  3  2  0  1  1 13 14 27 14  7  7  0  0  0  7  1  4  2  1  0 #> [526] 14 23 11  3  1  1  0  0  0  1  0  2  2  0 78 43 23 11  5  1  0  5  2  2  1 #> [551]  4  0 80 53 17 15  7  3 14 12 13 13  6  0 89 48 28  8  1 14 13 13 10 12  1 #> [576] 86 44  9  3 27 13  7 11  4  0 79 36  7 16 19 13  8  8  3 22 24 35 18 10  4 #> [601]  7  5 23 32 22 10  8  2  1 96 85 30 18 10  3 92 86 23 18  4 84 87 27  4 98 #> [626] 61 12 69 43 45 #>  #> $data$latest_obs #>         1 #>  [1,]  59 #>  [2,]  70 #>  [3,]  69 #>  [4,]  47 #>  [5,]  63 #>  [6,]  46 #>  [7,]  36 #>  [8,]  91 #>  [9,]  86 #> [10,]  95 #> [11,]  84 #> [12,]  89 #> [13,]  69 #> [14,]  28 #> [15,]  75 #> [16,] 151 #> [17,] 134 #> [18,] 114 #> [19,] 124 #> [20,]  77 #> [21,]  59 #> [22,] 149 #> [23,] 166 #> [24,] 133 #> [25,] 137 #> [26,] 139 #> [27,]  97 #> [28,]  58 #> [29,] 175 #> [30,] 233 #> [31,] 237 #> [32,] 204 #> [33,] 189 #> [34,] 125 #> [35,]  98 #> [36,] 242 #> [37,] 223 #> [38,] 202 #> [39,] 171 #> [40,] 112 #> [41,]  45 #>  #> $data$model_obs #> [1] 1 #>  #>  #> $priors #>    variable                                              description #> 1: sqrt_phi One over the square root of the reporting overdispersion #>             distribution mean sd #> 1: Zero truncated normal    0  1 #>  #> $inits #> function (data, priors)  #> { #>     priors <- enw_priors_as_data_list(priors) #>     fn <- function() { #>         init <- list(sqrt_phi = numeric(0), phi = numeric(0)) #>         if (data$model_obs == 1) { #>             init$sqrt_phi <- array(max(abs(rnorm(1, priors$sqrt_phi_p[1],  #>                 priors$sqrt_phi_p[2]/10)), 1e-04)) #>             init$phi <- 1/(init$sqrt_phi^2) #>         } #>         return(init) #>     } #>     return(fn) #> } #> <bytecode: 0x560702d781c0> #> <environment: 0x560702d6d730> #>"},{"path":"package.epinowcast.org/dev/reference/enw_plot_nowcast_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot nowcast quantiles — enw_plot_nowcast_quantiles","title":"Plot nowcast quantiles — enw_plot_nowcast_quantiles","text":"Plot nowcast quantiles","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_nowcast_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot nowcast quantiles — enw_plot_nowcast_quantiles","text":"","code":"enw_plot_nowcast_quantiles(nowcast, latest_obs = NULL, log = FALSE, ...)"},{"path":"package.epinowcast.org/dev/reference/enw_plot_nowcast_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot nowcast quantiles — enw_plot_nowcast_quantiles","text":"nowcast data.frame summarised posterior nowcast estimates containing least confirm count column reference_date date variable. latest_obs data.frame observed data containing least confirm count variable date variable main data.frame used plotting. log Logical, defaults FALSE. counts plot log scale. ... Additional arguments passed enw_plot_pp_quantiles().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_nowcast_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot nowcast quantiles — enw_plot_nowcast_quantiles","text":"ggplot2 plot.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_plot_nowcast_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot nowcast quantiles — enw_plot_nowcast_quantiles","text":"","code":"nowcast <- enw_example(\"nowcast\") nowcast <- summary(nowcast, probs = c(0.05, 0.2, 0.8, 0.95)) enw_plot_nowcast_quantiles(nowcast)"},{"path":"package.epinowcast.org/dev/reference/enw_plot_obs.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic quantile plot — enw_plot_obs","title":"Generic quantile plot — enw_plot_obs","text":"Generic quantile plot","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_obs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic quantile plot — enw_plot_obs","text":"","code":"enw_plot_obs(obs, latest_obs = NULL, log = TRUE, ...)"},{"path":"package.epinowcast.org/dev/reference/enw_plot_obs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic quantile plot — enw_plot_obs","text":"obs data.frame summarised posterior estimates containing least confirm count column date variable latest_obs data.frame observed data containing least confirm count variable date variable main data.frame used plotting. log Logical, defaults FALSE. counts plot log scale. ... Additional arguments passed ggplot2::aes() must least specify x date variable.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_obs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic quantile plot — enw_plot_obs","text":"ggplot2 plot.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_plot_obs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic quantile plot — enw_plot_obs","text":"","code":"nowcast <- enw_example(\"nowcast\") obs <- enw_example(\"obs\")  # Plot observed data by reference date enw_plot_obs(obs, x = reference_date)   # Plot observed data by reference date with more recent data enw_plot_obs(nowcast$latest[[1]], obs, x = reference_date)"},{"path":"package.epinowcast.org/dev/reference/enw_plot_pp_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot posterior prediction quantiles — enw_plot_pp_quantiles","title":"Plot posterior prediction quantiles — enw_plot_pp_quantiles","text":"Plot posterior prediction quantiles","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_pp_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot posterior prediction quantiles — enw_plot_pp_quantiles","text":"","code":"enw_plot_pp_quantiles(pp, log = FALSE, ...)"},{"path":"package.epinowcast.org/dev/reference/enw_plot_pp_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot posterior prediction quantiles — enw_plot_pp_quantiles","text":"pp data.frame summarised posterior predictions estimates containing least confirm count column report_date date variable. log Logical, defaults FALSE. counts plot log scale. ... Additional arguments passed enw_plot_pp_quantiles().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_pp_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot posterior prediction quantiles — enw_plot_pp_quantiles","text":"ggplot2 plot.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_plot_pp_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot posterior prediction quantiles — enw_plot_pp_quantiles","text":"","code":"nowcast <- enw_example(\"nowcast\") nowcast <- summary(  nowcast, type = \"posterior_prediction\", probs = c(0.05, 0.2, 0.8, 0.95) ) enw_plot_pp_quantiles(nowcast) +  ggplot2::facet_wrap(ggplot2::vars(reference_date), scales = \"free\") #> `geom_line()`: Each group consists of only one observation. #> ℹ Do you need to adjust the group aesthetic? #> `geom_line()`: Each group consists of only one observation. #> ℹ Do you need to adjust the group aesthetic?"},{"path":"package.epinowcast.org/dev/reference/enw_plot_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic quantile plot — enw_plot_quantiles","title":"Generic quantile plot — enw_plot_quantiles","text":"Generic quantile plot","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic quantile plot — enw_plot_quantiles","text":"","code":"enw_plot_quantiles(posterior, latest_obs = NULL, log = FALSE, ...)"},{"path":"package.epinowcast.org/dev/reference/enw_plot_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic quantile plot — enw_plot_quantiles","text":"posterior data.frame summarised posterior estimates containing least confirm count column date variable, quantile estimates 5%, 20%, 80%, 95% quantiles mean median. function wrapped enw_plot_nowcast_quantiles() enw_plot_pp_quantiles() sensible default labels. latest_obs data.frame observed data containing least confirm count variable date variable main data.frame used plotting. log Logical, defaults FALSE. counts plot log scale. ... Additional arguments passed ggplot2::aes() must least specify x date variable.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic quantile plot — enw_plot_quantiles","text":"ggplot2 plot.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_plot_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic quantile plot — enw_plot_quantiles","text":"","code":"nowcast <- enw_example(\"nowcast\") nowcast <- summary(nowcast, probs = c(0.05, 0.2, 0.8, 0.95)) enw_plot_quantiles(nowcast, x = reference_date)"},{"path":"package.epinowcast.org/dev/reference/enw_plot_theme.html","id":null,"dir":"Reference","previous_headings":"","what":"Package plot theme — enw_plot_theme","title":"Package plot theme — enw_plot_theme","text":"Package plot theme","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_theme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Package plot theme — enw_plot_theme","text":"","code":"enw_plot_theme(plot)"},{"path":"package.epinowcast.org/dev/reference/enw_plot_theme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Package plot theme — enw_plot_theme","text":"plot ggplot2 plot object.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_plot_theme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Package plot theme — enw_plot_theme","text":"ggplot2 plot object.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise the posterior — enw_posterior","title":"Summarise the posterior — enw_posterior","text":"generic wrapper around posterior::summarise_draws() opinionated defaults.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise the posterior — enw_posterior","text":"","code":"enw_posterior(fit, variables = NULL, probs = c(0.05, 0.2, 0.8, 0.95), ...)"},{"path":"package.epinowcast.org/dev/reference/enw_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise the posterior — enw_posterior","text":"fit cmdstanr fit object. variables character vector variables return posterior summaries . default summaries parameters returned. probs vector numeric probabilities produce quantile summaries . default 5%, 20%, 80%, 95% quantiles also minimum set required plotting functions work. ... Additional arguments may passed used.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise the posterior — enw_posterior","text":"data.frame summarising model posterior.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise the posterior — enw_posterior","text":"","code":"fit <- enw_example(\"nowcast\") enw_posterior(fit$fit[[1]], variables = \"expr_beta\") #>          variable        mean      median        sd       mad         q5 #>  1:  expr_beta[1]  0.35691445  0.36498800 0.5764547 0.5484506 -0.5943839 #>  2:  expr_beta[2] -0.34761195 -0.32384900 0.5760045 0.5536463 -1.2701980 #>  3:  expr_beta[3] -0.83816753 -0.83024800 0.5693749 0.5711331 -1.8262760 #>  4:  expr_beta[4]  0.51801887  0.52348450 0.5678107 0.5556399 -0.3951924 #>  5:  expr_beta[5] -0.49017229 -0.49719900 0.5278500 0.4999846 -1.3714010 #>  6:  expr_beta[6] -0.23446383 -0.21519950 0.5755229 0.5527518 -1.2024595 #>  7:  expr_beta[7]  1.72076461  1.70401500 0.5556995 0.5449370  0.8715682 #>  8:  expr_beta[8]  0.34962057  0.34943250 0.5410623 0.5203097 -0.5621784 #>  9:  expr_beta[9]  0.23732838  0.23436150 0.5341452 0.5232866 -0.6420201 #> 10: expr_beta[10] -0.34902716 -0.34409350 0.5217350 0.5295615 -1.1965940 #> 11: expr_beta[11] -0.17188953 -0.16680400 0.4845065 0.4743660 -1.0095885 #> 12: expr_beta[12] -0.55853461 -0.54901350 0.4921987 0.4969349 -1.3611635 #> 13: expr_beta[13] -1.23213415 -1.23010500 0.5682347 0.5755424 -2.1864280 #> 14: expr_beta[14]  1.52471513  1.52728000 0.6255768 0.6206238  0.4838366 #> 15: expr_beta[15]  1.80820361  1.80485500 0.5600774 0.5653524  0.9292188 #> 16: expr_beta[16] -0.22058912 -0.22138500 0.4908559 0.4650221 -1.0230965 #> 17: expr_beta[17] -0.25068399 -0.25479950 0.4912554 0.4890450 -1.0482845 #> 18: expr_beta[18] -0.17175111 -0.16917250 0.4886694 0.5068935 -0.9776898 #> 19: expr_beta[19] -0.56449312 -0.55253050 0.4844249 0.4558706 -1.3610185 #> 20: expr_beta[20] -0.33829765 -0.34597550 0.5274359 0.5072512 -1.1949605 #> 21: expr_beta[21]  1.68238934  1.67413500 0.5279810 0.5121642  0.8400429 #> 22: expr_beta[22]  0.41138546  0.41694050 0.4848998 0.4530284 -0.4269672 #> 23: expr_beta[23] -0.28407707 -0.27718050 0.4429254 0.4290170 -1.0027790 #> 24: expr_beta[24] -0.33421052 -0.32154200 0.4541127 0.4562668 -1.0654940 #> 25: expr_beta[25] -0.12360429 -0.13059150 0.4913108 0.5112924 -0.9331567 #> 26: expr_beta[26] -0.87457779 -0.87055900 0.5120680 0.4747708 -1.7559085 #> 27: expr_beta[27] -0.65372879 -0.64744800 0.5288792 0.5360251 -1.4965265 #> 28: expr_beta[28]  2.09713455  2.08991000 0.5327654 0.5280651  1.2489815 #> 29: expr_beta[29]  1.62818297  1.60410000 0.5205884 0.4904886  0.7600817 #> 30: expr_beta[30]  0.11566660  0.14057550 0.4731800 0.4516771 -0.6606485 #> 31: expr_beta[31] -0.65684394 -0.65804050 0.4933335 0.4917769 -1.4553930 #> 32: expr_beta[32] -0.22655365 -0.21496750 0.4812528 0.4896998 -1.0142790 #> 33: expr_beta[33] -0.65826420 -0.66979550 0.5243565 0.5240576 -1.5382910 #> 34: expr_beta[34] -0.13190444 -0.13824350 0.5499114 0.5404900 -1.0432585 #> 35: expr_beta[35]  1.47507558  1.46098000 0.5497911 0.5541440  0.5757841 #> 36: expr_beta[36]  0.16886656  0.16426950 0.5513899 0.5517659 -0.7193582 #> 37: expr_beta[37]  0.03530783  0.04368235 0.5600475 0.5563963 -0.8796558 #> 38: expr_beta[38]  0.12571370  0.12635600 0.6185879 0.6069401 -0.8701020 #> 39: expr_beta[39]  0.16884623  0.17235550 0.6772904 0.6992572 -0.9112642 #> 40: expr_beta[40]  0.37352032  0.35352300 0.7936915 0.7642136 -0.8954799 #>          variable        mean      median        sd       mad         q5 #>             q20         q80          q95      rhat  ess_bulk ess_tail #>  1: -0.11922640  0.83821680  1.310382000 1.0010635  660.0161 535.7780 #>  2: -0.81108380  0.11612020  0.593448150 1.0026682 1335.8326 740.6334 #>  3: -1.33949200 -0.35110620  0.070130075 1.0016985 1163.2292 789.4890 #>  4:  0.04686534  0.99532180  1.444933500 1.0018444 1102.4074 879.6314 #>  5: -0.91605840 -0.07005216  0.404101100 1.0004425 1113.6900 668.9304 #>  6: -0.71488600  0.22962420  0.693560750 1.0056901  996.5392 648.7603 #>  7:  1.26151800  2.17562000  2.652352000 1.0037668  954.4084 652.8714 #>  8: -0.08204750  0.80780620  1.245801000 1.0008162 1020.0426 902.6647 #>  9: -0.20514160  0.65418700  1.131625000 1.0037875  968.1302 796.1627 #> 10: -0.77210180  0.09092864  0.491583300 1.0037540 1141.1396 732.7558 #> 11: -0.55306220  0.22969240  0.592171100 1.0019680 1318.3628 809.8154 #> 12: -0.96768420 -0.13333260  0.250620500 1.0014743 1134.6824 914.3102 #> 13: -1.69079400 -0.73640560 -0.358825500 1.0030722  946.6902 795.5025 #> 14:  0.99659740  2.04084800  2.598101000 1.0069396 1075.2809 742.3032 #> 15:  1.31686200  2.27177800  2.741562000 1.0015112  951.8782 859.8358 #> 16: -0.61209140  0.19275560  0.572072800 1.0028789 1225.7750 773.4261 #> 17: -0.63679360  0.16880200  0.560836600 1.0029651  910.8575 766.3416 #> 18: -0.58390260  0.28426180  0.607000950 1.0018456 1247.1149 840.7685 #> 19: -0.94331960 -0.17481360  0.193365300 1.0014472 1189.8584 862.9854 #> 20: -0.77095000  0.09148314  0.525546600 0.9982799  962.2272 772.9448 #> 21:  1.24051200  2.10356000  2.606347000 1.0008667 1313.8286 877.8272 #> 22:  0.02028172  0.82299060  1.200706500 1.0037534 1000.4386 606.5635 #> 23: -0.64170760  0.09441038  0.404700000 1.0013013 1002.5619 815.0601 #> 24: -0.71855220  0.04867070  0.415618250 0.9996585 1265.1278 939.4297 #> 25: -0.55576900  0.29392660  0.668455550 1.0002861 1063.4436 663.0799 #> 26: -1.28327200 -0.46753760 -0.002321493 0.9985271 1289.3440 629.9431 #> 27: -1.10884800 -0.19467660  0.190780650 1.0019952 1009.7123 799.0850 #> 28:  1.63177400  2.53894600  3.005590000 1.0002712  763.4697 662.5946 #> 29:  1.18957800  2.04650400  2.504602000 0.9990166 1120.2857 680.8118 #> 30: -0.30102080  0.48244940  0.882347250 1.0010978 1201.0119 760.9960 #> 31: -1.05982800 -0.23950340  0.190652200 1.0006893  951.3861 887.4073 #> 32: -0.63355320  0.19755480  0.523404300 0.9985643 1172.4544 846.3230 #> 33: -1.07347800 -0.20559440  0.178272250 0.9991165 1298.1225 750.9543 #> 34: -0.56258620  0.32878740  0.755459800 1.0003530 1239.1159 681.0165 #> 35:  1.01486000  1.92881000  2.390124000 1.0008108  943.7494 618.1981 #> 36: -0.28282940  0.61264040  1.096016500 0.9996861  896.6749 732.1576 #> 37: -0.43939000  0.50305020  0.938247200 0.9997439  848.4870 841.4673 #> 38: -0.39462300  0.61521820  1.165504000 0.9998664  995.9477 724.1238 #> 39: -0.41606460  0.73891440  1.259385500 1.0009455 1395.7144 812.5458 #> 40: -0.27644920  1.03718400  1.698252500 1.0003707 1172.9385 744.6613 #>             q20         q80          q95      rhat  ess_bulk ess_tail"},{"path":"package.epinowcast.org/dev/reference/enw_pp_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior predictive summary — enw_pp_summary","title":"Posterior predictive summary — enw_pp_summary","text":"function summarises posterior predictives observed data (report reference date). functionality function can used directly output epinowcast() using supplied summary.epinowcast() method.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_pp_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior predictive summary — enw_pp_summary","text":"","code":"enw_pp_summary(fit, diff_obs, probs = c(0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95))"},{"path":"package.epinowcast.org/dev/reference/enw_pp_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior predictive summary — enw_pp_summary","text":"fit cmdstanr fit object. diff_obs data.frame observed data least date variable reference_date, grouping variable .group. probs vector numeric probabilities produce quantile summaries . default 5%, 20%, 80%, 95% quantiles also minimum set required plotting functions work.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_pp_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior predictive summary — enw_pp_summary","text":"data.table summarising posterior predictions.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_pp_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior predictive summary — enw_pp_summary","text":"","code":"fit <- enw_example(\"nowcast\") enw_pp_summary(fit$fit[[1]], fit$new_confirm[[1]], probs = c(0.5)) #>      reference_date report_date .group max_confirm location age_group confirm #>   1:     2021-07-13  2021-07-13      1          59       DE       00+      21 #>   2:     2021-07-13  2021-07-14      1          59       DE       00+      33 #>   3:     2021-07-13  2021-07-15      1          59       DE       00+      36 #>   4:     2021-07-13  2021-07-16      1          59       DE       00+      40 #>   5:     2021-07-13  2021-07-17      1          59       DE       00+      43 #>  ---                                                                          #> 626:     2021-08-20  2021-08-21      1         171       DE       00+     159 #> 627:     2021-08-20  2021-08-22      1         171       DE       00+     171 #> 628:     2021-08-21  2021-08-21      1         112       DE       00+      69 #> 629:     2021-08-21  2021-08-22      1         112       DE       00+     112 #> 630:     2021-08-22  2021-08-22      1          45       DE       00+      45 #>      cum_prop_reported delay new_confirm prop_reported   mean median        sd #>   1:         0.3559322     0          21    0.35593220 19.346     18  8.783133 #>   2:         0.5593220     1          12    0.20338983 20.514     19  9.362236 #>   3:         0.6101695     2           3    0.05084746  6.038      6  3.282275 #>   4:         0.6779661     3           4    0.06779661  4.102      4  2.592357 #>   5:         0.7288136     4           3    0.05084746  2.370      2  1.829330 #>  ---                                                                           #> 626:         0.9298246     1          61    0.35672515 83.928     80 34.506949 #> 627:         1.0000000     2          12    0.07017544 12.644     11  6.681610 #> 628:         0.6160714     0          69    0.61607143 74.909     70 32.940428 #> 629:         1.0000000     1          43    0.38392857 48.384     45 21.248248 #> 630:         1.0000000     0          45    1.00000000 41.418     38 19.492389 #>          mad q50      rhat  ess_bulk  ess_tail #>   1:  8.8956  18 0.9983637  932.3646  881.3256 #>   2:  8.8956  19 1.0011134 1015.9391  735.8017 #>   3:  2.9652   6 0.9992062 1084.5500 1021.5623 #>   4:  2.9652   4 1.0029845  784.8228  875.2947 #>   5:  1.4826   2 1.0010223  901.9783  995.0932 #>  ---                                           #> 626: 34.0998  80 0.9996878  948.3040  881.5462 #> 627:  5.9304  11 1.0002821 1086.3185  891.6927 #> 628: 29.6520  70 1.0027174 1147.8921  986.6337 #> 629: 19.2738  45 1.0014923  944.8684  966.2908 #> 630: 17.7912  38 0.9984329 1035.6813  850.9586"},{"path":"package.epinowcast.org/dev/reference/enw_preprocess_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess observations — enw_preprocess_data","title":"Preprocess observations — enw_preprocess_data","text":"function preprocesses raw observations assumption reported cumulative counts reference report date used assign groups. also constructs data objects used visualisation modelling functions including observed empirical probability report given day, cumulative probability report, latest available observations, incidence observations, metadata date reference report (used construct models). function wraps preprocessing functions may instead used individually required. Note internally reports beyond user specified delay dropped modelling purposes cum_prop_reported max_confirm variables allowing user check impact may (cum_prop_reported significantly 1 longer max_delay may appropriate). Also note missing reference report dates suspected occur data need completed enw_complete_dates().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_preprocess_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess observations — enw_preprocess_data","text":"","code":"enw_preprocess_data(   obs,   by = NULL,   max_delay = 20,   timestep = \"day\",   set_negatives_to_zero = TRUE,   ...,   copy = TRUE )"},{"path":"package.epinowcast.org/dev/reference/enw_preprocess_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess observations — enw_preprocess_data","text":"obs data.frame containing least following variables: reference_date (index date interest), report_date (report date observations), confirm (cumulative observations reference report date). character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling max_delay Numeric defaults 20 needs greater equal 1 integer (internally coerced one using .integer()). maximum number days include delay distribution. Computation scales non-linearly setting consider maximum makes sense data carefully. Note zero indexed includes reference date max_delay - 1 days (.e. max_delay 1 corresponds delay). timestep timestep used process model (.e. reference date model). can string (\"day\", \"week\", \"month\") numeric whole number representing number days. data timestep may wish make use enw_aggregate_cumulative() aggregate data desired timestep. set_negatives_to_zero Logical, defaults TRUE. negative counts (calculated incidence observations) set zero. Currently downstream modelling support negative counts setting must TRUE intending use epinowcast(). ... arguments enw_add_metaobs_features(), e.g. holidays, sets commonly used metadata (e.g. day week, days since start time series) copy logical; TRUE (default) creates copy; otherwise, modifies obs place.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_preprocess_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess observations — enw_preprocess_data","text":"data.table containing processed observations series nested data.frames well variables containing metadata. : obs: (observations addition empirical reporting proportions restricted specified maximum delay). new_confirm: Incidence notifications reference report date. Empirical reporting distributions also added. latest: latest available observations. missing_reference: Observations missing reference dates. reporting_triangle: Incident observations report reference date standard reporting triangle matrix format. metareference: Metadata reference dates derived observations. metrareport: Metadata report dates. metadelay: Metadata reporting delays produced using enw_delay_metadata(). time: Numeric, number timepoints data. snapshots: Numeric, number available data snapshots use nowcasting. groups: Numeric, Number groups/strata supplied observations (set using ). max_delay: Numeric, maximum delay processed data max_date: maximum available report date.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_preprocess_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess observations — enw_preprocess_data","text":"","code":"library(data.table)  # Filter example hospitalisation data to be national and over all ages nat_germany_hosp <- germany_covid19_hosp[location == \"DE\"] nat_germany_hosp <- nat_germany_hosp[age_group %in% \"00+\"]  # Preprocess with default settings pobs <- enw_preprocess_data(nat_germany_hosp) pobs #>                     obs           new_confirm               latest #> 1: <data.table[3770x9]> <data.table[3770x11]> <data.table[198x10]> #>    missing_reference   reporting_triangle       metareference #> 1: <data.table[0x6]> <data.table[198x22]> <data.table[198x9]> #>              metareport          metadelay time snapshots by groups max_delay #> 1: <data.table[217x12]> <data.table[20x4]>  198       198         1        20 #>      max_date timestep #> 1: 2021-10-20      day"},{"path":"package.epinowcast.org/dev/reference/enw_priors_as_data_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert prior data.frame to list — enw_priors_as_data_list","title":"Convert prior data.frame to list — enw_priors_as_data_list","text":"Converts priors defined data.frame list format use stan. addition adds \"_p\" variable names order allow distinguished standard usage within modelling code.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_priors_as_data_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert prior data.frame to list — enw_priors_as_data_list","text":"","code":"enw_priors_as_data_list(priors)"},{"path":"package.epinowcast.org/dev/reference/enw_priors_as_data_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert prior data.frame to list — enw_priors_as_data_list","text":"priors data.frame following variables: variable, mean, sd describing normal priors. Priors appropriate format returned enw_reference() well similar model specification functions.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_priors_as_data_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert prior data.frame to list — enw_priors_as_data_list","text":"named list entry specifying prior length two vector (specifying mean standard deviation prior).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_priors_as_data_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert prior data.frame to list — enw_priors_as_data_list","text":"","code":"priors <- data.frame(variable = \"x\", mean = 1, sd = 2) enw_priors_as_data_list(priors) #> $x_p #>      [,1] #> mean    1 #> sd      2 #>"},{"path":"package.epinowcast.org/dev/reference/enw_quantiles_to_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert summarised quantiles from wide to long format — enw_quantiles_to_long","title":"Convert summarised quantiles from wide to long format — enw_quantiles_to_long","text":"Convert summarised quantiles wide long format","code":""},{"path":"package.epinowcast.org/dev/reference/enw_quantiles_to_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert summarised quantiles from wide to long format — enw_quantiles_to_long","text":"","code":"enw_quantiles_to_long(posterior)"},{"path":"package.epinowcast.org/dev/reference/enw_quantiles_to_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert summarised quantiles from wide to long format — enw_quantiles_to_long","text":"posterior data.frame output enw_posterior().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_quantiles_to_long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert summarised quantiles from wide to long format — enw_quantiles_to_long","text":"data.frame quantiles long format.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_quantiles_to_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert summarised quantiles from wide to long format — enw_quantiles_to_long","text":"","code":"fit <- enw_example(\"nowcast\") posterior <- enw_posterior(fit$fit[[1]], var = \"expr_lelatent_int[1,1]\") enw_quantiles_to_long(posterior) #>                  variable     mean  median        sd       mad     rhat #> 1: expr_lelatent_int[1,1] 4.174822 4.17915 0.1619883 0.1564588 1.002543 #> 2: expr_lelatent_int[1,1] 4.174822 4.17915 0.1619883 0.1564588 1.002543 #> 3: expr_lelatent_int[1,1] 4.174822 4.17915 0.1619883 0.1564588 1.002543 #> 4: expr_lelatent_int[1,1] 4.174822 4.17915 0.1619883 0.1564588 1.002543 #>    ess_bulk ess_tail quantile prediction #> 1: 671.6598 514.3376     0.05   3.899291 #> 2: 671.6598 514.3376     0.20   4.043978 #> 3: 671.6598 514.3376     0.80   4.308002 #> 4: 671.6598 514.3376     0.95   4.432952"},{"path":"package.epinowcast.org/dev/reference/enw_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Reference date logit hazard reporting model module — enw_reference","title":"Reference date logit hazard reporting model module — enw_reference","text":"Reference date logit hazard reporting  model module","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reference date logit hazard reporting model module — enw_reference","text":"","code":"enw_reference(   parametric = ~1,   distribution = c(\"lognormal\", \"none\", \"exponential\", \"gamma\", \"loglogistic\"),   non_parametric = ~0,   data )"},{"path":"package.epinowcast.org/dev/reference/enw_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reference date logit hazard reporting model module — enw_reference","text":"parametric formula (implemented enw_formula()) describing parametric reference date delay model. can use features defined report date defined metareference produced enw_preprocess_data(). Note formula applied summary statistics chosen parametric distribution summary parameter separate effects. Use ~ 0 use parametric model (note recommended non_parametric model implemented). distribution character vector describing parametric delay distribution use. Current options : \"none\", \"lognormal\", \"gamma\", \"exponential\", \"loglogistic\", default \"lognormal\". non_parametric formula (implemented enw_formula()) describing non-parametric logit hazard model. can use features defined reference date delay. draws linked data.frame using metareference metadelay produced enw_preprocess_data(). effect per delay specified approximates cox proportional hazard model discrete time single strata. Note model currently available users. data Output enw_preprocess_data().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reference date logit hazard reporting model module — enw_reference","text":"list containing supplied formulas, data passed list describing models, data.frame describing priors used, function takes output data priors returns function can used sample tightened version prior distribution.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reference date logit hazard reporting model module — enw_reference","text":"","code":"enw_reference(data = enw_example(\"preprocessed\")) #> $formula #> $formula$parametric #> [1] \"~1\" #>  #>  #> $data #> $data$refp_fdesign #>   (Intercept) #> 1           1 #>  #> $data$refp_fintercept #> [1] 1 #>  #> $data$refp_fnrow #> [1] 1 #>  #> $data$refp_findex #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #> [39] 1 1 1 #>  #> $data$refp_fnindex #> [1] 41 #>  #> $data$refp_fncol #> [1] 0 #>  #> $data$refp_rdesign #>      (Intercept) #> attr(,\"assign\") #> [1] 0 #>  #> $data$refp_rncol #> [1] 0 #>  #> $data$model_refp #> [1] 2 #>  #>  #> $priors #>             variable #> 1:     refp_mean_int #> 2:       refp_sd_int #> 3: refp_mean_beta_sd #> 4:   refp_sd_beta_sd #>                                                       description #> 1:         Log mean intercept for parametric reference date delay #> 2: Log standard deviation for the parametric reference date delay #> 3:    Standard deviation of scaled pooled parametric mean effects #> 4:      Standard deviation of scaled pooled parametric sd effects #>             distribution mean sd #> 1:                Normal  1.0  1 #> 2: Zero truncated normal  0.5  1 #> 3: Zero truncated normal  0.0  1 #> 4: Zero truncated normal  0.0  1 #>  #> $inits #> function (data, priors)  #> { #>     priors <- enw_priors_as_data_list(priors) #>     fn <- function() { #>         init <- list(refp_mean_int = numeric(0), refp_sd_int = numeric(0),  #>             refp_mean_beta = numeric(0), refp_sd_beta = numeric(0),  #>             refp_mean_beta_sd = numeric(0), refp_sd_beta_sd = numeric(0)) #>         if (data$model_refp > 0) { #>             init$refp_mean_int <- array(rnorm(1, priors$refp_mean_int[1],  #>                 priors$refp_mean_int[2]/10)) #>         } #>         if (data$model_refp > 1) { #>             init$refp_sd_int <- array(abs(rnorm(1, priors$refp_sd_int[1],  #>                 priors$refp_sd_int[2]/10))) #>         } #>         init$refp_mean <- rep(init$refp_mean_int, data$refp_fnrow) #>         init$refp_sd <- rep(init$refp_sd_int, data$refp_fnrow) #>         if (data$refp_fncol > 0) { #>             init$refp_mean_beta <- array(rnorm(data$refp_fncol,  #>                 0, 0.01)) #>             if (data$model_refp > 1) { #>                 init$refp_sd_beta <- array(rnorm(data$refp_fncol,  #>                   0, 0.01)) #>             } #>         } #>         if (data$refp_rncol > 0) { #>             init$refp_mean_beta_sd <- array(abs(rnorm(data$refp_rncol,  #>                 priors$refp_mean_beta_sd_p[1], priors$refp_mean_beta_sd_p[2]/10))) #>             if (data$model_refp > 1) { #>                 init$refp_sd_beta_sd <- array(abs(rnorm(data$refp_rncol,  #>                   priors$refp_sd_beta_sd_p[1], priors$refp_sd_beta_sd_p[2]/10))) #>             } #>         } #>         return(init) #>     } #>     return(fn) #> } #> <bytecode: 0x5606fc3fd308> #> <environment: 0x5606fc37ef28> #>"},{"path":"package.epinowcast.org/dev/reference/enw_reference_by_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a lookup of references dates by report — enw_reference_by_report","title":"Construct a lookup of references dates by report — enw_reference_by_report","text":"Construct lookup references dates report","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reference_by_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a lookup of references dates by report — enw_reference_by_report","text":"","code":"enw_reference_by_report(   missing_reference,   reps_with_complete_refs,   metareference,   max_delay )"},{"path":"package.epinowcast.org/dev/reference/enw_reference_by_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a lookup of references dates by report — enw_reference_by_report","text":"missing_reference missing_reference data.frame output enw_preprocess_data(). reps_with_complete_refs data.frame report dates complete (.e fully reported) reference dates produced using enw_reps_with_complete_refs(). metareference metareference data.frame output enw_preprocess_data(). max_delay Numeric defaults 20 needs greater equal 1 integer (internally coerced one using .integer()). maximum number days include delay distribution. Computation scales non-linearly setting consider maximum makes sense data carefully. Note zero indexed includes reference date max_delay - 1 days (.e. max_delay 1 corresponds delay).","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reference_by_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a lookup of references dates by report — enw_reference_by_report","text":"wide data.frame row complete report date ' columns observation index reporting delay","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_replace_priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace default priors with user specified priors — enw_replace_priors","title":"Replace default priors with user specified priors — enw_replace_priors","text":"function used internally epinowcast replace default model priors users specified ones (restricted normal priors specified mean standard deviations). common use extracting posterior previous epinowcast() run (using summary(nowcast, type = fit)) using prior.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_replace_priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace default priors with user specified priors — enw_replace_priors","text":"","code":"enw_replace_priors(priors, custom_priors)"},{"path":"package.epinowcast.org/dev/reference/enw_replace_priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace default priors with user specified priors — enw_replace_priors","text":"priors data.frame following variables: variable, mean, sd describing normal priors. Priors appropriate format returned enw_reference() well similar model specification functions. custom_priors data.frame following variables: variable, mean, sd describing normal priors. Priors appropriate format returned enw_reference() well similar model specification functions. Priors data.frame replace default priors. Note currently vectorised prior names (.e form variable[n] treated variable).","code":""},{"path":"package.epinowcast.org/dev/reference/enw_replace_priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace default priors with user specified priors — enw_replace_priors","text":"data.table prior definitions (variable, mean sd).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_replace_priors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace default priors with user specified priors — enw_replace_priors","text":"","code":"# Update priors from a data.frame priors <- data.frame(variable = c(\"x\", \"y\"), mean = c(1, 2), sd = c(1, 2)) custom_priors <- data.frame(variable = \"x[1]\", mean = 10, sd = 2) enw_replace_priors(priors, custom_priors) #>    variable mean sd #> 1:        y    2  2 #> 2:        x   10  2  # Update priors from a previous model fit default_priors <- enw_reference(  distribution = \"lognormal\",  data = enw_example(\"preprocessed\"), )$priors print(default_priors) #>             variable #> 1:     refp_mean_int #> 2:       refp_sd_int #> 3: refp_mean_beta_sd #> 4:   refp_sd_beta_sd #>                                                       description #> 1:         Log mean intercept for parametric reference date delay #> 2: Log standard deviation for the parametric reference date delay #> 3:    Standard deviation of scaled pooled parametric mean effects #> 4:      Standard deviation of scaled pooled parametric sd effects #>             distribution mean sd #> 1:                Normal  1.0  1 #> 2: Zero truncated normal  0.5  1 #> 3: Zero truncated normal  0.0  1 #> 4: Zero truncated normal  0.0  1  fit_priors <- summary(  enw_example(\"nowcast\"), type = \"fit\",  variables = c(\"refp_mean_int\", \"refp_sd_int\", \"sqrt_phi\") ) fit_priors #>            variable      mean   median         sd        mad        q5 #> 1: refp_mean_int[1] 2.9094597 2.890800 0.59278054 0.61464148 1.9945040 #> 2:   refp_sd_int[1] 3.7121802 3.703165 0.28684669 0.28877341 3.2485520 #> 3:      sqrt_phi[1] 0.3457251 0.345330 0.03066519 0.03144891 0.2978062 #>          q20       q80       q95     rhat  ess_bulk ess_tail #> 1: 2.3887180 3.4097680 3.9038630 1.007756  670.7265 813.1303 #> 2: 3.4720380 3.9641120 4.1829380 1.006129  776.8050 789.4460 #> 3: 0.3206198 0.3716398 0.3973088 1.000220 1056.1530 709.8793  enw_replace_priors(default_priors, fit_priors) #>             variable #> 1: refp_mean_beta_sd #> 2:   refp_sd_beta_sd #> 3:     refp_mean_int #> 4:       refp_sd_int #> 5:          sqrt_phi #>                                                    description #> 1: Standard deviation of scaled pooled parametric mean effects #> 2:   Standard deviation of scaled pooled parametric sd effects #> 3:                                                        <NA> #> 4:                                                        <NA> #> 5:                                                        <NA> #>             distribution      mean         sd #> 1: Zero truncated normal 0.0000000 1.00000000 #> 2: Zero truncated normal 0.0000000 1.00000000 #> 3:                  <NA> 2.9094597 0.59278054 #> 4:                  <NA> 3.7121802 0.28684669 #> 5:                  <NA> 0.3457251 0.03066519"},{"path":"package.epinowcast.org/dev/reference/enw_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Report date logit hazard reporting model module — enw_report","title":"Report date logit hazard reporting model module — enw_report","text":"Report date logit hazard reporting  model module","code":""},{"path":"package.epinowcast.org/dev/reference/enw_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Report date logit hazard reporting model module — enw_report","text":"","code":"enw_report(non_parametric = ~0, structural = ~0, data)"},{"path":"package.epinowcast.org/dev/reference/enw_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Report date logit hazard reporting model module — enw_report","text":"non_parametric formula (implemented enw_formula()) describing non-parametric logit hazard model. can use features defined report date defined metareport produced enw_preprocess_data(). Note intercept model set 0 used specifying report date related hazards vs time invariant hazards instead modelled using non_parametric argument enw_reference() structural formula fixed effects using binary variables, factors describing known reporting structure (.e weekday reporting). base case (.e first factor entry) describe dates reporting possible. Internally dates non-zero element design matrix hazard set 0. can use features defined report date defined metareport produced enw_preprocess_data(). Note intercept model set 0 order allow dates without structural reasons reported reported. Note feature yet available users. data Output enw_preprocess_data().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Report date logit hazard reporting model module — enw_report","text":"list containing supplied formulas, data passed list describing models, data.frame describing priors used, function takes output data priors returns function can used sample tightened version prior distribution.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Report date logit hazard reporting model module — enw_report","text":"","code":"enw_report(data = enw_example(\"preprocessed\")) #> $formula #> $formula$non_parametric #> [1] \"~1\" #>  #>  #> $data #> $data$rep_fdesign #>   (Intercept) #> 1           1 #>  #> $data$rep_fintercept #> [1] 1 #>  #> $data$rep_fnrow #> [1] 1 #>  #> $data$rep_findex #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] #> [1,]    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #>      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] #> [1,]     1     1     1     1     1     1     1     1     1     1     1     1 #>      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] #> [1,]     1     1     1     1     1     1     1     1     1     1     1     1 #>      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] #> [1,]     1     1     1     1     1     1     1     1     1     1     1     1 #>      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] #> [1,]     1     1     1     1     1     1     1     1     1     1 #>  #> $data$rep_fnindex #> [1] 60 #>  #> $data$rep_fncol #> [1] 0 #>  #> $data$rep_rdesign #>      (Intercept) #> attr(,\"assign\") #> [1] 0 #>  #> $data$rep_rncol #> [1] 0 #>  #> $data$rep_t #> [1] 60 #>  #> $data$model_rep #> [1] 0 #>  #>  #> $priors #>       variable                                             description #> 1: rep_beta_sd Standard deviation of scaled pooled report date effects #>             distribution mean sd #> 1: Zero truncated normal    0  1 #>  #> $inits #> function (data, priors)  #> { #>     priors <- enw_priors_as_data_list(priors) #>     fn <- function() { #>         init <- list(rep_beta = numeric(0), rep_beta_sd = numeric(0)) #>         if (data$rep_fncol > 0) { #>             init$rep_beta <- array(rnorm(data$rep_fncol, 0, 0.01)) #>         } #>         if (data$rep_rncol > 0) { #>             init$rep_beta_sd <- array(abs(rnorm(data$rep_rncol,  #>                 priors$rep_beta_sd_p[1], priors$rep_beta_sd_p[2]/10))) #>         } #>         return(init) #>     } #>     return(fn) #> } #> <bytecode: 0x560712575ce0> #> <environment: 0x56070e8ae758> #>"},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct the reporting triangle — enw_reporting_triangle","title":"Construct the reporting triangle — enw_reporting_triangle","text":"Constructs reporting triangle row representing reference date columns observations report date","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct the reporting triangle — enw_reporting_triangle","text":"","code":"enw_reporting_triangle(obs)"},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct the reporting triangle — enw_reporting_triangle","text":"obs data.frame produced enw_add_incidence(). Must contain following variables: reference_date, .group, delay.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct the reporting triangle — enw_reporting_triangle","text":"data.frame row reference date, columns observations reporting delay.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct the reporting triangle — enw_reporting_triangle","text":"","code":"obs <- enw_example(\"preprocessed\")$new_confirm enw_reporting_triangle(obs) #>     .group reference_date  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 #>  1:      1     2021-07-13 21 12  3  4  3  0  1  2  4  3  0  0  2  0  0  0  1  2 #>  2:      1     2021-07-14 22 12  4  5  0  1 10  2  5  3  0  1  0  3  1  0  1  0 #>  3:      1     2021-07-15 28 15  3  3  0  1  3  2  3  2  1  0  2  3  0  3  0  0 #>  4:      1     2021-07-16 19 13  0  0  0  4  2  2  2  1  1  1  0  1  0  0  1  0 #>  5:      1     2021-07-17 20  7  1  3 10  3  0  4  3  3  2  0  1  2  0  1  2  1 #>  6:      1     2021-07-18  9  6  6  0  4  5  4  0  1  4  0  0  1  1  1  2  0  0 #>  7:      1     2021-07-19  3 16  4  4  1  1  2  0  0  0  0  1  1  1  1  0  0  0 #>  8:      1     2021-07-20 36 19 10  4  2  3  0  3  2  3  0  2  1  1  2  2  0  0 #>  9:      1     2021-07-21 28 18  8  4  1  2  3  6  1  5  2  2  3  0  2  0  1  0 #> 10:      1     2021-07-22 34 19  2  1  5  2  4  3  7  3  1  0  4  3  3  1  2  0 #> 11:      1     2021-07-23 30 12  4  1 10  6  0  2  2  1  2  1  4  0  2  3  0  0 #> 12:      1     2021-07-24 31  8  4  9  8  2  5  2  1  1  2  4  1  3  1  0  1  2 #> 13:      1     2021-07-25  8  4 14  8  6  5  1  3  0  4  1  2  4  2  0  1  2  2 #> 14:      1     2021-07-26  9  6  2  3  0  0  0  0  1  2  4  1  0  0  0  0  0  0 #> 15:      1     2021-07-27 35 11  6  4  4  1  0  2  2  2  2  0  0  1  4  1  0  0 #> 16:      1     2021-07-28 51 28 25  3  5  2  3  5  5  7  1  0  0  4  5  5  1  1 #> 17:      1     2021-07-29 47 37  9  2  2  3  4  4  4  3  0  2  0 10  4  3  0  0 #> 18:      1     2021-07-30 36 20  2  4 11  8  8  3  5  2  0  2  4  4  0  2  2  0 #> 19:      1     2021-07-31 38 16  3 15 14  7  5  5  0  0  5  0  5  1  6  0  0  3 #> 20:      1     2021-08-01  7  5  5 11  7  5  1  3  1  6  3  3  4  1  1  7  2  3 #> 21:      1     2021-08-02 13 13  8  6  1  3  2  0  0  2  0  2  0  5  3  0  0  0 #> 22:      1     2021-08-03 51 43  6  4  4  3  1  6  4  5  5  4  0  4  5  0  2  2 #> 23:      1     2021-08-04 51 43 18  5  6  1  2  8  7  7  6  1  0  4  3  1  3  0 #> 24:      1     2021-08-05 45 21  6  2  2 11 17  5  7  4  1  0  5  3  0  2  2  0 #> 25:      1     2021-08-06 47 31  5  4 20  6  1  9  3  1  0  2  1  5  2  0  0  0 #> 26:      1     2021-08-07 40 15  6 23 14 13  8  9  0  1  3  3  2  0  1  1  0  0 #> 27:      1     2021-08-08 13 14 27 14  7  7  0  0  0  7  1  4  2  1  0  0  0  0 #> 28:      1     2021-08-09 14 23 11  3  1  1  0  0  0  1  0  2  2  0  0  0  0  0 #> 29:      1     2021-08-10 78 43 23 11  5  1  0  5  2  2  1  4  0  0  0  0  0  0 #> 30:      1     2021-08-11 80 53 17 15  7  3 14 12 13 13  6  0  0  0  0  0  0  0 #> 31:      1     2021-08-12 89 48 28  8  1 14 13 13 10 12  1  0  0  0  0  0  0  0 #> 32:      1     2021-08-13 86 44  9  3 27 13  7 11  4  0  0  0  0  0  0  0  0  0 #> 33:      1     2021-08-14 79 36  7 16 19 13  8  8  3  0  0  0  0  0  0  0  0  0 #> 34:      1     2021-08-15 22 24 35 18 10  4  7  5  0  0  0  0  0  0  0  0  0  0 #> 35:      1     2021-08-16 23 32 22 10  8  2  1  0  0  0  0  0  0  0  0  0  0  0 #> 36:      1     2021-08-17 96 85 30 18 10  3  0  0  0  0  0  0  0  0  0  0  0  0 #> 37:      1     2021-08-18 92 86 23 18  4  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 38:      1     2021-08-19 84 87 27  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 39:      1     2021-08-20 98 61 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 40:      1     2021-08-21 69 43  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #> 41:      1     2021-08-22 45  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>     .group reference_date  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 #>     18 19 #>  1:  1  0 #>  2:  0  0 #>  3:  0  0 #>  4:  0  0 #>  5:  0  0 #>  6:  0  2 #>  7:  1  0 #>  8:  1  0 #>  9:  0  0 #> 10:  0  1 #> 11:  4  0 #> 12:  2  2 #> 13:  2  0 #> 14:  0  0 #> 15:  0  0 #> 16:  0  0 #> 17:  0  0 #> 18:  0  1 #> 19:  1  0 #> 20:  2  0 #> 21:  0  1 #> 22:  0  0 #> 23:  0  0 #> 24:  0  0 #> 25:  0  0 #> 26:  0  0 #> 27:  0  0 #> 28:  0  0 #> 29:  0  0 #> 30:  0  0 #> 31:  0  0 #> 32:  0  0 #> 33:  0  0 #> 34:  0  0 #> 35:  0  0 #> 36:  0  0 #> 37:  0  0 #> 38:  0  0 #> 39:  0  0 #> 40:  0  0 #> 41:  0  0 #>     18 19"},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle_to_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Recast the reporting triangle from wide to long format — enw_reporting_triangle_to_long","title":"Recast the reporting triangle from wide to long format — enw_reporting_triangle_to_long","text":"Recast reporting triangle wide long format","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle_to_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recast the reporting triangle from wide to long format — enw_reporting_triangle_to_long","text":"","code":"enw_reporting_triangle_to_long(obs)"},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle_to_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recast the reporting triangle from wide to long format — enw_reporting_triangle_to_long","text":"obs data.frame format produced enw_reporting_triangle().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle_to_long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recast the reporting triangle from wide to long format — enw_reporting_triangle_to_long","text":"long format reporting triangle data.frame additional variables new_confirm delay.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_reporting_triangle_to_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recast the reporting triangle from wide to long format — enw_reporting_triangle_to_long","text":"","code":"obs <- enw_example(\"preprocessed\")$new_confirm rt <- enw_reporting_triangle(obs) enw_reporting_triangle_to_long(rt) #>      reference_date .group delay new_confirm #>   1:     2021-07-13      1     0          21 #>   2:     2021-07-13      1     1          12 #>   3:     2021-07-13      1     2           3 #>   4:     2021-07-13      1     3           4 #>   5:     2021-07-13      1     4           3 #>  ---                                         #> 816:     2021-08-22      1    15           0 #> 817:     2021-08-22      1    16           0 #> 818:     2021-08-22      1    17           0 #> 819:     2021-08-22      1    18           0 #> 820:     2021-08-22      1    19           0"},{"path":"package.epinowcast.org/dev/reference/enw_reps_with_complete_refs.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify report dates with complete (i.e up to the maximum delay) reference dates — enw_reps_with_complete_refs","title":"Identify report dates with complete (i.e up to the maximum delay) reference dates — enw_reps_with_complete_refs","text":"Identify report dates complete (.e maximum delay) reference dates","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reps_with_complete_refs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify report dates with complete (i.e up to the maximum delay) reference dates — enw_reps_with_complete_refs","text":"","code":"enw_reps_with_complete_refs(new_confirm, max_delay, by = NULL, copy = TRUE)"},{"path":"package.epinowcast.org/dev/reference/enw_reps_with_complete_refs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify report dates with complete (i.e up to the maximum delay) reference dates — enw_reps_with_complete_refs","text":"new_confirm new_confirm data.frame output enw_preprocess_data(). max_delay Numeric defaults 20 needs greater equal 1 integer (internally coerced one using .integer()). maximum number days include delay distribution. Computation scales non-linearly setting consider maximum makes sense data carefully. Note zero indexed includes reference date max_delay - 1 days (.e. max_delay 1 corresponds delay). character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling copy logical; TRUE (default) creates copy; otherwise, modifies obs place.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_reps_with_complete_refs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify report dates with complete (i.e up to the maximum delay) reference dates — enw_reps_with_complete_refs","text":"data.frame containing report_date variable, grouping variables specified report dates complete reporting.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a CmdStan model using NUTS — enw_sample","title":"Fit a CmdStan model using NUTS — enw_sample","text":"Fit CmdStan model using NUTS","code":""},{"path":"package.epinowcast.org/dev/reference/enw_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a CmdStan model using NUTS — enw_sample","text":"","code":"enw_sample(data, model = epinowcast::enw_model(), diagnostics = TRUE, ...)"},{"path":"package.epinowcast.org/dev/reference/enw_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a CmdStan model using NUTS — enw_sample","text":"data list data produced model modules (example enw_expectation(), enw_obs(), etc.) required use model used. model cmdstanr model object loaded enw_model() supplied user. diagnostics Logical, defaults TRUE. fitting diagnostics returned data.frame. ... Additional parameters passed sample method cmdstanr.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a CmdStan model using NUTS — enw_sample","text":"data.frame containing cmdstanr fit, input data, fitting arguments, optionally summary diagnostics.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_score_nowcast.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate nowcasts using proper scoring rules — enw_score_nowcast","title":"Evaluate nowcasts using proper scoring rules — enw_score_nowcast","text":"Acts wrapper scoringutils::score(). particular, handling filtering nowcast summary output linking output observed data. See documentation scoringutils package forecast scoring.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_score_nowcast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate nowcasts using proper scoring rules — enw_score_nowcast","text":"","code":"enw_score_nowcast(   nowcast,   latest_obs,   log = FALSE,   check = FALSE,   round_to = 3,   ... )"},{"path":"package.epinowcast.org/dev/reference/enw_score_nowcast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate nowcasts using proper scoring rules — enw_score_nowcast","text":"nowcast posterior nowcast posterior prediction returned summary.epinowcast(), used output epinowcast(). latest_obs data.frame latest available observations produced enw_latest_data() otherwise. log Logical, defaults FALSE. scores calculated log scale (0.01 shift) observations nowcasts. Scoring way can thought relative score vs usual absolute measure. may useful targets different scales forecaster interested good round performance versus good performance targets large values. check Logical, defaults FALSE. scoringutils::check_forecasts() used check input nowcasts. round_to Integer defaults 3. Number digits round scoring output . ... Arguments passed scoringutils::score data data.frame data.table predictions observations. scoring using score(), following columns need present: true_value - true observed values prediction - predictions predictive samples one true value. (need provide prediction column want score quantile forecasts wide range format.) scoring integer continuous forecasts sample column needed: sample - index identify predictive samples prediction column generated one model one true value. necessary continuous integer forecasts, binary predictions. scoring predictions quantile-format forecast provide column called quantile: quantile: quantile prediction corresponds addition model column suggested present flagged added input data forecasts assigned \"unspecified model\"). can check format data using check_forecasts() examples format (example_quantile, example_continuous, example_integer, example_binary). metrics metrics want output. NULL (default), available metrics computed. list available metrics see available_metrics(),  check metrics data set.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_score_nowcast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate nowcasts using proper scoring rules — enw_score_nowcast","text":"data.table returned scoringutils::score().","code":""},{"path":"package.epinowcast.org/dev/reference/enw_score_nowcast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate nowcasts using proper scoring rules — enw_score_nowcast","text":"","code":"if (FALSE) { # interactive() library(data.table) library(scoringutils)  # Summarise example nowcast nowcast <- enw_example(\"nowcast\") summarised_nowcast <- summary(nowcast)  # Load latest available observations obs <- enw_example(\"observations\")  # Keep the last 7 days of data obs <- obs[reference_date > (max(reference_date) - 7)]  # score on the absolute scale scores <- enw_score_nowcast(summarised_nowcast, obs) summarise_scores(scores, by = \"location\")  # score overall on a log scale log_scores <- enw_score_nowcast(summarised_nowcast, obs, log = TRUE) summarise_scores(log_scores, by = \"location\") }"},{"path":"package.epinowcast.org/dev/reference/enw_simulate_missing_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate observations with a missing reference date. — enw_simulate_missing_reference","title":"Simulate observations with a missing reference date. — enw_simulate_missing_reference","text":"simple binomial simulator missing data reference date using simulated observed data input. function may used validate missing data models, part examples case studies, explore implications missing data use case.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_simulate_missing_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate observations with a missing reference date. — enw_simulate_missing_reference","text":"","code":"enw_simulate_missing_reference(obs, proportion = 0.2, by = NULL)"},{"path":"package.epinowcast.org/dev/reference/enw_simulate_missing_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate observations with a missing reference date. — enw_simulate_missing_reference","text":"obs data.frame containing least following variables: reference date (index date interest), report_date (report date observations), confirm (cumulative observations reference report date). proportion Numeric, proportion observations missing reference date, indexed reference date. Currently fixed proportion supported defaults 0.2. character vector describing stratification observations. defaults grouping. used modelling multiple time series order identify downstream modelling","code":""},{"path":"package.epinowcast.org/dev/reference/enw_simulate_missing_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate observations with a missing reference date. — enw_simulate_missing_reference","text":"data.table format input simulated proportion observations now missing reference date.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_simulate_missing_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate observations with a missing reference date. — enw_simulate_missing_reference","text":"","code":"# Load and filter germany hospitalisations nat_germany_hosp <- subset(   germany_covid19_hosp, location == \"DE\" & age_group %in% \"00+\" ) nat_germany_hosp <- enw_filter_report_dates(   nat_germany_hosp,   latest_date = \"2021-08-01\" )  # Make sure observations are complete nat_germany_hosp <- enw_complete_dates(   nat_germany_hosp,   by = c(\"location\", \"age_group\"), missing_reference = FALSE )  # Simulate enw_simulate_missing_reference(   nat_germany_hosp,   proportion = 0.35, by = c(\"location\", \"age_group\") ) #>       location age_group report_date reference_date confirm #>    1:       DE       00+  2021-04-06           <NA>      53 #>    2:       DE       00+  2021-04-07           <NA>     160 #>    3:       DE       00+  2021-04-08           <NA>     271 #>    4:       DE       00+  2021-04-09           <NA>     226 #>    5:       DE       00+  2021-04-10           <NA>     264 #>   ---                                                       #> 7135:       DE       00+  2021-07-31     2021-07-30      38 #> 7136:       DE       00+  2021-08-01     2021-07-30      38 #> 7137:       DE       00+  2021-07-31     2021-07-31      29 #> 7138:       DE       00+  2021-08-01     2021-07-31      40 #> 7139:       DE       00+  2021-08-01     2021-08-01       3"},{"path":"package.epinowcast.org/dev/reference/enw_summarise_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise posterior samples — enw_summarise_samples","title":"Summarise posterior samples — enw_summarise_samples","text":"function summarises posterior samples arbitrary strata. optionally holds observed data (variables \".draw\", \".iteration\", \".sample\", \".chain\" ) joins summarised posterior.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_summarise_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise posterior samples — enw_summarise_samples","text":"","code":"enw_summarise_samples(   samples,   probs = c(0.05, 0.2, 0.35, 0.5, 0.65, 0.8, 0.95),   by = c(\"reference_date\", \".group\"),   link_with_obs = TRUE )"},{"path":"package.epinowcast.org/dev/reference/enw_summarise_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise posterior samples — enw_summarise_samples","text":"samples data.frame posterior samples least numeric sample variable. probs vector numeric probabilities produce quantile summaries . default 5%, 20%, 80%, 95% quantiles also minimum set required plotting functions work. character vector variables summarise . Defaults c(\"reference_date\", \".group\"). link_with_obs Logical, observed data linked posterior summary? useful plotting posterior observed data. Defaults TRUE.","code":""},{"path":"package.epinowcast.org/dev/reference/enw_summarise_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise posterior samples — enw_summarise_samples","text":"data.frame summarising posterior samples.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/enw_summarise_samples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise posterior samples — enw_summarise_samples","text":"","code":"fit <- enw_example(\"nowcast\") samples <- summary(fit, type = \"nowcast_sample\") enw_summarise_samples(samples, probs = c(0.05, 0.5, 0.95)) #>     reference_date .group report_date max_confirm location age_group confirm #>  1:     2021-08-03      1  2021-08-22         149       DE       00+     149 #>  2:     2021-08-04      1  2021-08-22         166       DE       00+     166 #>  3:     2021-08-05      1  2021-08-22         133       DE       00+     133 #>  4:     2021-08-06      1  2021-08-22         137       DE       00+     137 #>  5:     2021-08-07      1  2021-08-22         139       DE       00+     139 #>  6:     2021-08-08      1  2021-08-22          97       DE       00+      97 #>  7:     2021-08-09      1  2021-08-22          58       DE       00+      58 #>  8:     2021-08-10      1  2021-08-22         175       DE       00+     175 #>  9:     2021-08-11      1  2021-08-22         233       DE       00+     233 #> 10:     2021-08-12      1  2021-08-22         237       DE       00+     237 #> 11:     2021-08-13      1  2021-08-22         204       DE       00+     204 #> 12:     2021-08-14      1  2021-08-22         189       DE       00+     189 #> 13:     2021-08-15      1  2021-08-22         125       DE       00+     125 #> 14:     2021-08-16      1  2021-08-22          98       DE       00+      98 #> 15:     2021-08-17      1  2021-08-22         242       DE       00+     242 #> 16:     2021-08-18      1  2021-08-22         223       DE       00+     223 #> 17:     2021-08-19      1  2021-08-22         202       DE       00+     202 #> 18:     2021-08-20      1  2021-08-22         171       DE       00+     171 #> 19:     2021-08-21      1  2021-08-22         112       DE       00+     112 #> 20:     2021-08-22      1  2021-08-22          45       DE       00+      45 #>     cum_prop_reported delay prop_reported    mean median         sd     mad #>  1:                 1    19   0.000000000 149.000  149.0   0.000000  0.0000 #>  2:                 1    18   0.000000000 167.440  167.0   1.306946  1.4826 #>  3:                 1    17   0.000000000 135.804  136.0   1.910297  1.4826 #>  4:                 1    16   0.000000000 141.039  141.0   2.336009  1.4826 #>  5:                 1    15   0.007194245 145.916  146.0   3.245223  2.9652 #>  6:                 1    14   0.000000000 103.674  103.0   3.004455  2.9652 #>  7:                 1    13   0.000000000  63.014   63.0   2.633769  2.9652 #>  8:                 1    12   0.000000000 185.131  185.0   3.861703  4.4478 #>  9:                 1    11   0.000000000 255.938  256.0   6.338796  5.9304 #> 10:                 1    10   0.004219409 267.445  267.0   7.795495  7.4130 #> 11:                 1     9   0.000000000 236.189  235.5   8.328183  8.1543 #> 12:                 1     8   0.015873016 230.969  230.0   9.851248  9.6369 #> 13:                 1     7   0.040000000 165.393  165.0  10.147883 10.3782 #> 14:                 1     6   0.010204082 129.419  129.0   8.341524  8.8956 #> 15:                 1     5   0.012396694 293.442  292.0  12.342730 11.8608 #> 16:                 1     4   0.017937220 292.867  292.0  15.235795 14.8260 #> 17:                 1     3   0.019801980 292.416  291.0  20.600906 19.2738 #> 18:                 1     2   0.070175439 294.685  291.0  29.652944 28.1694 #> 19:                 1     1   0.383928571 312.347  307.0  52.500656 50.4084 #> 20:                 1     0   1.000000000 377.870  363.0 106.473272 93.4038 #>         q5   q50    q95 #>  1: 149.00 149.0 149.00 #>  2: 166.00 167.0 170.00 #>  3: 133.00 136.0 139.00 #>  4: 138.00 141.0 145.00 #>  5: 141.00 146.0 152.00 #>  6:  99.00 103.0 109.00 #>  7:  59.00  63.0  68.00 #>  8: 179.00 185.0 192.00 #>  9: 246.00 256.0 267.00 #> 10: 256.00 267.0 281.00 #> 11: 224.00 235.5 251.00 #> 12: 216.00 230.0 247.00 #> 13: 150.00 165.0 184.00 #> 14: 116.00 129.0 144.00 #> 15: 276.00 292.0 316.00 #> 16: 271.00 292.0 320.05 #> 17: 263.00 291.0 331.00 #> 18: 251.95 291.0 347.05 #> 19: 237.00 307.0 403.15 #> 20: 239.95 363.0 576.15"},{"path":"package.epinowcast.org/dev/reference/epinowcast-package.html","id":null,"dir":"Reference","previous_headings":"","what":"epinowcast: Flexible Hierarchical Nowcasting — epinowcast-package","title":"epinowcast: Flexible Hierarchical Nowcasting — epinowcast-package","text":"Tools enable flexible efficient hierarchical nowcasting right-truncated epidemiological time-series using semi-mechanistic Bayesian model support range reporting generative processes. Nowcasting, context, gaining situational awareness using currently available observations reporting patterns historical observations. can useful tracking spread infectious disease real-time: without nowcasting, changes trends can obfuscated partial reporting detection may delayed due use simpler methods like truncation. package designed epidemiological applications mind, applied set right-truncated time-series count data.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/epinowcast-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"epinowcast: Flexible Hierarchical Nowcasting — epinowcast-package","text":"Maintainer: Sam Abbott contact@samabbott.co.uk (ORCID) Authors: Adrian Lison adrian.lison@bsse.ethz.ch (ORCID) Sebastian Funk sebastian.funk@lshtm.ac.uk Carl Pearson carl.ab.pearson@gmail.com (ORCID) Hugo Gruson hugo.gruson@normalesup.org (ORCID) Felix Guenther felixguenther1@gmx.de (ORCID) contributors: Michael DeWitt .dewitt.jr@gmail.com (ORCID) [contributor] Hannah Choi hannah.choi1@lshtm.ac.uk [contributor] Pratik Gupte pratik.gupte@lshtm.ac.uk (ORCID) [contributor] Joel Hellewell joel@ebi.ac.uk (ORCID) [contributor] Luis Rivas luisnicolasrivas@gmail.com [contributor] Sang Woo Park swp2@princeton.edu (ORCID) [contributor]","code":""},{"path":"package.epinowcast.org/dev/reference/epinowcast.html","id":null,"dir":"Reference","previous_headings":"","what":"Nowcast using partially observed data — epinowcast","title":"Nowcast using partially observed data — epinowcast","text":"Provides user friendly interface around package functionality produce nowcast observed preprocessed data, series user defined models. default model assumes fixed parametric reporting distribution flexible expectation model used. Explore individual model components additional documentation see package case studies example model specifications different tasks.","code":""},{"path":"package.epinowcast.org/dev/reference/epinowcast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nowcast using partially observed data — epinowcast","text":"","code":"epinowcast(   data,   reference = epinowcast::enw_reference(parametric = ~1, distribution = \"lognormal\",     non_parametric = ~0, data = data),   report = epinowcast::enw_report(non_parametric = ~0, structural = ~0, data = data),   expectation = epinowcast::enw_expectation(r = ~0 + (1 | day:.group), generation_time =     1, observation = ~1, latent_reporting_delay = 1, data = data),   missing = epinowcast::enw_missing(formula = ~0, data = data),   obs = epinowcast::enw_obs(family = \"negbin\", data = data),   fit = epinowcast::enw_fit_opts(sampler = epinowcast::enw_sample, nowcast = TRUE, pp =     FALSE, likelihood = TRUE, debug = FALSE, output_loglik = FALSE),   model = epinowcast::enw_model(),   priors,   ... )"},{"path":"package.epinowcast.org/dev/reference/epinowcast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nowcast using partially observed data — epinowcast","text":"data Output enw_preprocess_data(). reference reference date indexed reporting process model specification defined using enw_reference(). report report date indexed reporting process model specification defined using enw_report(). expectation expectation model specification defined using enw_expectation(). default set highly flexible random effect reference date group thus weakly informed. Depending context (particular density data reporting) choices enforce assumptions may appropriate (example weekly random walk (specified using rw(week, = .group))). missing missing reference date model specification defined using enw_missing(). default set used. obs observation model defined enw_obs(). Observations also processed within function use modelling. fit Model fit options defined using enw_fit_opts(). includes sampler function use (package default enw_sample()), whether now nowcast used, etc. See enw_fit_opts() details. model model use within fit. default uses enw_model(). priors data.frame following variables: variable, mean, sd describing normal priors. Priors appropriate format returned enw_reference() well similar model specification functions. Priors data.frame replace default priors specified model component. ... Additional model modules pass model. User modules may used currently require supplied model adapted.","code":""},{"path":"package.epinowcast.org/dev/reference/epinowcast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nowcast using partially observed data — epinowcast","text":"object class \"epinowcast\" inherits enw_preprocess_data() data.table, combines output sampler specified enw_fit_opts().","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/epinowcast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nowcast using partially observed data — epinowcast","text":"","code":"if (FALSE) { # interactive() # Load data.table and ggplot2 library(data.table) library(ggplot2)  # Use 2 cores options(mc.cores = 2) # Load and filter germany hospitalisations nat_germany_hosp <-   germany_covid19_hosp[location == \"DE\"][age_group %in% \"00+\"] nat_germany_hosp <- enw_filter_report_dates(   nat_germany_hosp,   latest_date = \"2021-10-01\" ) # Make sure observations are complete nat_germany_hosp <- enw_complete_dates(   nat_germany_hosp,   by = c(\"location\", \"age_group\") ) # Make a retrospective dataset retro_nat_germany <- enw_filter_report_dates(   nat_germany_hosp,   remove_days = 40 ) retro_nat_germany <- enw_filter_reference_dates(   retro_nat_germany,   include_days = 40 ) # Get latest observations for the same time period latest_obs <- enw_latest_data(nat_germany_hosp) latest_obs <- enw_filter_reference_dates(   latest_obs,   remove_days = 40, include_days = 20 ) # Preprocess observations (note this maximum delay is likely too short) pobs <- enw_preprocess_data(retro_nat_germany, max_delay = 20) # Fit the default nowcast model and produce a nowcast # Note that we have reduced samples for this example to reduce runtimes nowcast <- epinowcast(pobs,   fit = enw_fit_opts(     save_warmup = FALSE, pp = TRUE,     chains = 2, iter_warmup = 500, iter_sampling = 500   ) ) nowcast # plot the nowcast vs latest available observations plot(nowcast, latest_obs = latest_obs)  # plot posterior predictions for the delay distribution by date plot(nowcast, type = \"posterior\") +   facet_wrap(vars(reference_date), scale = \"free\") }"},{"path":"package.epinowcast.org/dev/reference/expose_stan_fns.html","id":null,"dir":"Reference","previous_headings":"","what":"Expose stan functions in R — expose_stan_fns","title":"Expose stan functions in R — expose_stan_fns","text":"function builds top rstan::expose_stan_functions() order facilitate exposing package functions R internal use, testing, exploration. Crucially performs conversion package cmdstan stan code rstan compatible stan code. generally recommended users make use function apart exploring package functionality.","code":""},{"path":"package.epinowcast.org/dev/reference/expose_stan_fns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expose stan functions in R — expose_stan_fns","text":"","code":"expose_stan_fns(files, target_dir, ...)"},{"path":"package.epinowcast.org/dev/reference/expose_stan_fns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expose stan functions in R — expose_stan_fns","text":"files character vector file names target_dir character string giving directory files can found. ... Arguments pass rstan::expose_stan_functions()","code":""},{"path":"package.epinowcast.org/dev/reference/expose_stan_fns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expose stan functions in R — expose_stan_fns","text":"NULL (indivisibly)","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/extract_sparse_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract sparse matrix elements — extract_sparse_matrix","title":"Extract sparse matrix elements — extract_sparse_matrix","text":"helper function allows extraction sparse matrix matrix using rstan::extract_sparse_parsts() returns elements named list use stan.","code":""},{"path":"package.epinowcast.org/dev/reference/extract_sparse_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract sparse matrix elements — extract_sparse_matrix","text":"","code":"extract_sparse_matrix(mat, prefix = \"\")"},{"path":"package.epinowcast.org/dev/reference/extract_sparse_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract sparse matrix elements — extract_sparse_matrix","text":"mat matrix extract sparse matrix . prefix character string prefix names returned list.","code":""},{"path":"package.epinowcast.org/dev/reference/extract_sparse_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract sparse matrix elements — extract_sparse_matrix","text":"Return list describes sparse matrix includes: nw number non-zero elements matrix. w non-zero elements matrix. nv number non-zero row identifiers matrix. v non-zero row identifiers matrix. nu number non-zero column identifiers matrix. u non-zero column identifiers matrix.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/extract_sparse_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract sparse matrix elements — extract_sparse_matrix","text":"","code":"mat <- matrix(1:9, nrow = 3) extract_sparse_matrix(mat) #> $nw #> [1] 9 #>  #> $w #> [1] 1 4 7 2 5 8 3 6 9 #>  #> $nv #> [1] 9 #>  #> $v #> [1] 1 2 3 1 2 3 1 2 3 #>  #> $nu #> [1] 4 #>  #> $u #> [1]  1  4  7 10 #>"},{"path":"package.epinowcast.org/dev/reference/germany_covid19_hosp.html","id":null,"dir":"Reference","previous_headings":"","what":"Hospitalisations in Germany by date of report and reference — germany_covid19_hosp","title":"Hospitalisations in Germany by date of report and reference — germany_covid19_hosp","text":"Hospitalisations Germany date report reference","code":""},{"path":"package.epinowcast.org/dev/reference/germany_covid19_hosp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hospitalisations in Germany by date of report and reference — germany_covid19_hosp","text":"","code":"germany_covid19_hosp"},{"path":"package.epinowcast.org/dev/reference/germany_covid19_hosp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Hospitalisations in Germany by date of report and reference — germany_covid19_hosp","text":"object class data.table (inherits data.frame) 1536885 rows 5 columns.","code":""},{"path":"package.epinowcast.org/dev/reference/germany_covid19_hosp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hospitalisations in Germany by date of report and reference — germany_covid19_hosp","text":"data.table","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/get_internal_timestep.html","id":null,"dir":"Reference","previous_headings":"","what":"Get internal timestep — get_internal_timestep","title":"Get internal timestep — get_internal_timestep","text":"function converts string representation timestep corresponding numeric value returns numeric input (whole number). \"day\", \"week\", returns 1 7 respectively. \"month\", returns \"month\" months fixed number days. input numeric whole number, returned .","code":""},{"path":"package.epinowcast.org/dev/reference/get_internal_timestep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get internal timestep — get_internal_timestep","text":"","code":"get_internal_timestep(timestep)"},{"path":"package.epinowcast.org/dev/reference/get_internal_timestep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get internal timestep — get_internal_timestep","text":"timestep timestep used. can string (\"day\", \"week\", \"month\") numeric whole number representing number days.","code":""},{"path":"package.epinowcast.org/dev/reference/get_internal_timestep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get internal timestep — get_internal_timestep","text":"numeric value representing number days \"day\" \"week\", \"month\" \"month\",  input value numeric whole number.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/is.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Check an object is a Date — is.Date","title":"Check an object is a Date — is.Date","text":"Checks object date","code":""},{"path":"package.epinowcast.org/dev/reference/is.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check an object is a Date — is.Date","text":"","code":"is.Date(x)"},{"path":"package.epinowcast.org/dev/reference/is.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check an object is a Date — is.Date","text":"x object","code":""},{"path":"package.epinowcast.org/dev/reference/is.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check an object is a Date — is.Date","text":"logical","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/latest_obs_as_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert latest observed data to a matrix — latest_obs_as_matrix","title":"Convert latest observed data to a matrix — latest_obs_as_matrix","text":"Convert latest observed data matrix","code":""},{"path":"package.epinowcast.org/dev/reference/latest_obs_as_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert latest observed data to a matrix — latest_obs_as_matrix","text":"","code":"latest_obs_as_matrix(latest)"},{"path":"package.epinowcast.org/dev/reference/latest_obs_as_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert latest observed data to a matrix — latest_obs_as_matrix","text":"latest latest data.frame output enw_preprocess_data().","code":""},{"path":"package.epinowcast.org/dev/reference/latest_obs_as_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert latest observed data to a matrix — latest_obs_as_matrix","text":"matrix column group row reference date","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/parse_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse a formula into components — parse_formula","title":"Parse a formula into components — parse_formula","text":"function uses series internal functions break input formula component parts can handled separately. Currently supported components fixed effects, lme4 style random effects, random walks using rw() helper function.","code":""},{"path":"package.epinowcast.org/dev/reference/parse_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse a formula into components — parse_formula","text":"","code":"parse_formula(formula)"},{"path":"package.epinowcast.org/dev/reference/parse_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse a formula into components — parse_formula","text":"formula model formula may use standard fixed effects, random effects using lme4 syntax (see re()), random walks defined using rw() helper function.","code":""},{"path":"package.epinowcast.org/dev/reference/parse_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse a formula into components — parse_formula","text":"list formula components. currently include: fixed: character vector fixed effect terms random: list lme4 style random effects rw: character vector rw() random walk terms.","code":""},{"path":"package.epinowcast.org/dev/reference/parse_formula.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Parse a formula into components — parse_formula","text":"random walk functions used internally function adapted code written J Scott (MIT license) part epidemia package (https://github.com/ImperialCollegeLondon/epidemia/).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/parse_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parse a formula into components — parse_formula","text":"","code":"epinowcast:::parse_formula(~ 1 + age_group + location) #> $fixed #> [1] \"1\"         \"age_group\" \"location\"  #>  #> $random #> NULL #>  #> $rw #> character(0) #>   epinowcast:::parse_formula(~ 1 + age_group + (1 | location)) #> $fixed #> [1] \"1\"         \"age_group\" #>  #> $random #> $random[[1]] #> 1 | location #>  #>  #> $rw #> character(0) #>   epinowcast:::parse_formula(~ 1 + (age_group | location)) #> $fixed #> [1] \"1\" #>  #> $random #> $random[[1]] #> age_group | location #>  #>  #> $rw #> character(0) #>   epinowcast:::parse_formula(~ 1 + (1 | location) + rw(week, location)) #> $fixed #> [1] \"1\" #>  #> $random #> $random[[1]] #> 1 | location #>  #>  #> $rw #> [1] \"rw(week, location)\" #>"},{"path":"package.epinowcast.org/dev/reference/plot.epinowcast.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for epinowcast — plot.epinowcast","title":"Plot method for epinowcast — plot.epinowcast","text":"plot method class \"epinowcast\".","code":""},{"path":"package.epinowcast.org/dev/reference/plot.epinowcast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for epinowcast — plot.epinowcast","text":"","code":"# S3 method for epinowcast plot(   x,   latest_obs = NULL,   type = c(\"nowcast\", \"posterior_prediction\"),   log = FALSE,   ... )"},{"path":"package.epinowcast.org/dev/reference/plot.epinowcast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for epinowcast — plot.epinowcast","text":"x data.table output produced epinowcast(). latest_obs data.frame observed data may passed lower level methods. type Character string indicating plot required; enforced base::match.arg(). Currently supported options: \"nowcast\" plots nowcast dataset along latest available observed data using enw_plot_nowcast_quantiles(), \"posterior_prediction\" plots observations reported time simulated observations model using enw_plot_pp_quantiles(). log Logical, defaults FALSE. counts plot log scale. ... Additional arguments plot function specified type.","code":""},{"path":"package.epinowcast.org/dev/reference/plot.epinowcast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for epinowcast — plot.epinowcast","text":"ggplot2 object","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/plot.epinowcast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for epinowcast — plot.epinowcast","text":"","code":"nowcast <- enw_example(\"nowcast\") latest_obs <- enw_example(\"obs\")  # Plot nowcast plot(nowcast, latest_obs = latest_obs, type = \"nowcast\")   # Plot posterior predictions by reference date plot(nowcast, type = \"posterior_prediction\") +  ggplot2::facet_wrap(ggplot2::vars(reference_date), scales = \"free\") #> `geom_line()`: Each group consists of only one observation. #> ℹ Do you need to adjust the group aesthetic? #> `geom_line()`: Each group consists of only one observation. #> ℹ Do you need to adjust the group aesthetic?"},{"path":"package.epinowcast.org/dev/reference/re.html","id":null,"dir":"Reference","previous_headings":"","what":"Defines random effect terms using the lme4 syntax — re","title":"Defines random effect terms using the lme4 syntax — re","text":"Defines random effect terms using lme4 syntax","code":""},{"path":"package.epinowcast.org/dev/reference/re.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Defines random effect terms using the lme4 syntax — re","text":"","code":"re(formula)"},{"path":"package.epinowcast.org/dev/reference/re.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Defines random effect terms using the lme4 syntax — re","text":"formula random effect returned lme4::findbars() random effect defined using lme4 syntax formula. Currently simplified random effects (.e LHS | RHS) supported.","code":""},{"path":"package.epinowcast.org/dev/reference/re.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Defines random effect terms using the lme4 syntax — re","text":"list defining fixed random effects specified random effect","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Defines random effect terms using the lme4 syntax — re","text":"","code":"form <- epinowcast:::parse_formula(~ 1 + (1 | age_group)) re(form$random[[1]]) #> $fixed #> [1] \"1\" #>  #> $random #> [1] \"age_group\" #>  #> attr(,\"class\") #> [1] \"enw_re_term\"  form <- epinowcast:::parse_formula(~ 1 + (location | age_group)) re(form$random[[1]]) #> $fixed #> [1] \"location\" #>  #> $random #> [1] \"age_group\" #>  #> attr(,\"class\") #> [1] \"enw_re_term\""},{"path":"package.epinowcast.org/dev/reference/remove_profiling.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove profiling statements from a character vector representing stan code — remove_profiling","title":"Remove profiling statements from a character vector representing stan code — remove_profiling","text":"Remove profiling statements character vector representing stan code","code":""},{"path":"package.epinowcast.org/dev/reference/remove_profiling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove profiling statements from a character vector representing stan code — remove_profiling","text":"","code":"remove_profiling(s)"},{"path":"package.epinowcast.org/dev/reference/remove_profiling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove profiling statements from a character vector representing stan code — remove_profiling","text":"s Character vector representing stan code","code":""},{"path":"package.epinowcast.org/dev/reference/remove_profiling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove profiling statements from a character vector representing stan code — remove_profiling","text":"character vector stan code without profiling statements","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/remove_rw_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove random walk terms from a formula object — remove_rw_terms","title":"Remove random walk terms from a formula object — remove_rw_terms","text":"function removes random walk terms denoted using rw() formula can processed .","code":""},{"path":"package.epinowcast.org/dev/reference/remove_rw_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove random walk terms from a formula object — remove_rw_terms","text":"","code":"remove_rw_terms(formula)"},{"path":"package.epinowcast.org/dev/reference/remove_rw_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove random walk terms from a formula object — remove_rw_terms","text":"formula model formula may use standard fixed effects, random effects using lme4 syntax (see re()), random walks defined using rw() helper function.","code":""},{"path":"package.epinowcast.org/dev/reference/remove_rw_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove random walk terms from a formula object — remove_rw_terms","text":"formula object random walk terms removed.","code":""},{"path":"package.epinowcast.org/dev/reference/remove_rw_terms.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Remove random walk terms from a formula object — remove_rw_terms","text":"function adapted code written J Scott (MIT license) part epidemia package (https://github.com/ImperialCollegeLondon/epidemia/).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/remove_rw_terms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove random walk terms from a formula object — remove_rw_terms","text":"","code":"epinowcast:::remove_rw_terms(~ 1 + age_group + location) #> ~1 + age_group + location #> <environment: 0x560713a95bc8>  epinowcast:::remove_rw_terms(~ 1 + age_group + location + rw(week, location)) #> ~1 + age_group + location #> <environment: 0x56070fe90c48>"},{"path":"package.epinowcast.org/dev/reference/rw.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds random walks with Gaussian steps to the model. — rw","title":"Adds random walks with Gaussian steps to the model. — rw","text":"call rw() can used 'formula' argument model construction functions epinowcast package enw_formula(). evaluate arguments instead simply passes information use model construction.","code":""},{"path":"package.epinowcast.org/dev/reference/rw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds random walks with Gaussian steps to the model. — rw","text":"","code":"rw(time, by, type = c(\"independent\", \"dependent\"))"},{"path":"package.epinowcast.org/dev/reference/rw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds random walks with Gaussian steps to the model. — rw","text":"time Defines random walk time period. Defines grouping parameter used random walk. specified grouping used. Currently limited single variable. type Character string, standard deviation grouped random walks estimated: \"independent\", \"dependent\" across groups; enforced base::match.arg().","code":""},{"path":"package.epinowcast.org/dev/reference/rw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds random walks with Gaussian steps to the model. — rw","text":"list defining time frame, group, type class \"enw_rw_term\" can interpreted construct_rw().","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/rw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adds random walks with Gaussian steps to the model. — rw","text":"","code":"rw(time) #> $time #> [1] \"time\" #>  #> $by #> NULL #>  #> $type #> [1] \"independent\" #>  #> attr(,\"class\") #> [1] \"enw_rw_term\"  rw(time, location) #> $time #> [1] \"time\" #>  #> $by #> [1] \"location\" #>  #> $type #> [1] \"independent\" #>  #> attr(,\"class\") #> [1] \"enw_rw_term\"  rw(time, location, type = \"dependent\") #> $time #> [1] \"time\" #>  #> $by #> [1] \"location\" #>  #> $type #> [1] \"dependent\" #>  #> attr(,\"class\") #> [1] \"enw_rw_term\""},{"path":"package.epinowcast.org/dev/reference/rw_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds random walk terms in a formula object — rw_terms","title":"Finds random walk terms in a formula object — rw_terms","text":"function extracts random walk terms denoted using rw() formula can processed .","code":""},{"path":"package.epinowcast.org/dev/reference/rw_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds random walk terms in a formula object — rw_terms","text":"","code":"rw_terms(formula)"},{"path":"package.epinowcast.org/dev/reference/rw_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds random walk terms in a formula object — rw_terms","text":"formula model formula may use standard fixed effects, random effects using lme4 syntax (see re()), random walks defined using rw() helper function.","code":""},{"path":"package.epinowcast.org/dev/reference/rw_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds random walk terms in a formula object — rw_terms","text":"character vector containing random walk terms identified supplied formula.","code":""},{"path":"package.epinowcast.org/dev/reference/rw_terms.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Finds random walk terms in a formula object — rw_terms","text":"function adapted code written J Scott (MIT license) part epidemia package (https://github.com/ImperialCollegeLondon/epidemia/).","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/rw_terms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds random walk terms in a formula object — rw_terms","text":"","code":"epinowcast:::rw_terms(~ 1 + age_group + location) #> character(0)  epinowcast:::rw_terms(~ 1 + age_group + location + rw(week, location)) #> [1] \"rw(week, location)\""},{"path":"package.epinowcast.org/dev/reference/simulate_double_censored_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate daily double censored PMF — simulate_double_censored_pmf","title":"Simulate daily double censored PMF — simulate_double_censored_pmf","text":"function simulates probability mass function  daily double-censored process. process involves two distributions: primary distribution represents censoring process primary event another distribution (offset primary).","code":""},{"path":"package.epinowcast.org/dev/reference/simulate_double_censored_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate daily double censored PMF — simulate_double_censored_pmf","text":"","code":"simulate_double_censored_pmf(   max,   fun_primary = stats::runif,   primary_args = list(),   fun_dist = stats::rlnorm,   dist_args = list(...),   n = 1e+06,   ... )"},{"path":"package.epinowcast.org/dev/reference/simulate_double_censored_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate daily double censored PMF — simulate_double_censored_pmf","text":"max Maximum value computed CDF. specified, maximum value maximum simulated delay. fun_primary Primary distribution function (default runif). primary_args List additional arguments passed primary distribution function. fun_dist Distribution function added primary (default rlnorm). dist_args List additional arguments passed distribution function. n Number simulations (default 1e6). ... Additional arguments passed distribution function. alternative dist_args.","code":""},{"path":"package.epinowcast.org/dev/reference/simulate_double_censored_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate daily double censored PMF — simulate_double_censored_pmf","text":"numeric vector representing PMF.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/simulate_double_censored_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate daily double censored PMF — simulate_double_censored_pmf","text":"","code":"simulate_double_censored_pmf(10, meanlog = 0, sdlog = 1) #>  [1] 0.238155 0.409747 0.169230 0.076597 0.039502 0.022401 0.013731 0.008615 #>  [9] 0.005808 0.004012 0.002880"},{"path":"package.epinowcast.org/dev/reference/split_formula_to_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Split formula into individual terms — split_formula_to_terms","title":"Split formula into individual terms — split_formula_to_terms","text":"Split formula individual terms","code":""},{"path":"package.epinowcast.org/dev/reference/split_formula_to_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split formula into individual terms — split_formula_to_terms","text":"","code":"split_formula_to_terms(formula)"},{"path":"package.epinowcast.org/dev/reference/split_formula_to_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split formula into individual terms — split_formula_to_terms","text":"formula model formula may use standard fixed effects, random effects using lme4 syntax (see re()), random walks defined using rw() helper function.","code":""},{"path":"package.epinowcast.org/dev/reference/split_formula_to_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split formula into individual terms — split_formula_to_terms","text":"character vector formula terms","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/split_formula_to_terms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split formula into individual terms — split_formula_to_terms","text":"","code":"epinowcast:::split_formula_to_terms(~ 1 + age_group + location) #> [1] \"1\"         \"age_group\" \"location\""},{"path":"package.epinowcast.org/dev/reference/stan_fns_as_string.html","id":null,"dir":"Reference","previous_headings":"","what":"Read in a stan function file as a character string — stan_fns_as_string","title":"Read in a stan function file as a character string — stan_fns_as_string","text":"Read stan function file character string","code":""},{"path":"package.epinowcast.org/dev/reference/stan_fns_as_string.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read in a stan function file as a character string — stan_fns_as_string","text":"","code":"stan_fns_as_string(files, target_dir)"},{"path":"package.epinowcast.org/dev/reference/stan_fns_as_string.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read in a stan function file as a character string — stan_fns_as_string","text":"files character vector file names target_dir character string giving directory files can found.","code":""},{"path":"package.epinowcast.org/dev/reference/stan_fns_as_string.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read in a stan function file as a character string — stan_fns_as_string","text":"character string stan functions.","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/summary.epinowcast.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for epinowcast — summary.epinowcast","title":"Summary method for epinowcast — summary.epinowcast","text":"summary method class \"epinowcast\".","code":""},{"path":"package.epinowcast.org/dev/reference/summary.epinowcast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for epinowcast — summary.epinowcast","text":"","code":"# S3 method for epinowcast summary(   object,   type = c(\"nowcast\", \"nowcast_samples\", \"fit\", \"posterior_prediction\"),   ... )"},{"path":"package.epinowcast.org/dev/reference/summary.epinowcast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for epinowcast — summary.epinowcast","text":"object data.table output epinowcast(). type Character string indicating summary return; enforced base::match.arg(). Supported options : \"nowcast\" summarises nowcast posterior enw_nowcast_summary(), \"nowcast_samples\" samples latest enw_nowcast_samples(), \"fit\" returns summarised cmdstanr fit enw_posterior(), \"posterior_prediction\" returns summarised posterior predictions observations fitting using enw_pp_summary(). ... Additional arguments passed summary specified type.","code":""},{"path":"package.epinowcast.org/dev/reference/summary.epinowcast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for epinowcast — summary.epinowcast","text":"summary data.frame","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/reference/summary.epinowcast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for epinowcast — summary.epinowcast","text":"","code":"nowcast <- enw_example(\"nowcast\")  # Summarise nowcast posterior summary(nowcast, type = \"nowcast\") #>     reference_date report_date .group max_confirm location age_group confirm #>  1:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>  2:     2021-08-04  2021-08-22      1         166       DE       00+     166 #>  3:     2021-08-05  2021-08-22      1         133       DE       00+     133 #>  4:     2021-08-06  2021-08-22      1         137       DE       00+     137 #>  5:     2021-08-07  2021-08-22      1         139       DE       00+     139 #>  6:     2021-08-08  2021-08-22      1          97       DE       00+      97 #>  7:     2021-08-09  2021-08-22      1          58       DE       00+      58 #>  8:     2021-08-10  2021-08-22      1         175       DE       00+     175 #>  9:     2021-08-11  2021-08-22      1         233       DE       00+     233 #> 10:     2021-08-12  2021-08-22      1         237       DE       00+     237 #> 11:     2021-08-13  2021-08-22      1         204       DE       00+     204 #> 12:     2021-08-14  2021-08-22      1         189       DE       00+     189 #> 13:     2021-08-15  2021-08-22      1         125       DE       00+     125 #> 14:     2021-08-16  2021-08-22      1          98       DE       00+      98 #> 15:     2021-08-17  2021-08-22      1         242       DE       00+     242 #> 16:     2021-08-18  2021-08-22      1         223       DE       00+     223 #> 17:     2021-08-19  2021-08-22      1         202       DE       00+     202 #> 18:     2021-08-20  2021-08-22      1         171       DE       00+     171 #> 19:     2021-08-21  2021-08-22      1         112       DE       00+     112 #> 20:     2021-08-22  2021-08-22      1          45       DE       00+      45 #>     cum_prop_reported delay prop_reported    mean median         sd     mad #>  1:                 1    19   0.000000000 149.000  149.0   0.000000  0.0000 #>  2:                 1    18   0.000000000 167.440  167.0   1.306946  1.4826 #>  3:                 1    17   0.000000000 135.804  136.0   1.910297  1.4826 #>  4:                 1    16   0.000000000 141.039  141.0   2.336009  1.4826 #>  5:                 1    15   0.007194245 145.916  146.0   3.245223  2.9652 #>  6:                 1    14   0.000000000 103.674  103.0   3.004455  2.9652 #>  7:                 1    13   0.000000000  63.014   63.0   2.633769  2.9652 #>  8:                 1    12   0.000000000 185.131  185.0   3.861703  4.4478 #>  9:                 1    11   0.000000000 255.938  256.0   6.338796  5.9304 #> 10:                 1    10   0.004219409 267.445  267.0   7.795495  7.4130 #> 11:                 1     9   0.000000000 236.189  235.5   8.328183  8.1543 #> 12:                 1     8   0.015873016 230.969  230.0   9.851248  9.6369 #> 13:                 1     7   0.040000000 165.393  165.0  10.147883 10.3782 #> 14:                 1     6   0.010204082 129.419  129.0   8.341524  8.8956 #> 15:                 1     5   0.012396694 293.442  292.0  12.342730 11.8608 #> 16:                 1     4   0.017937220 292.867  292.0  15.235795 14.8260 #> 17:                 1     3   0.019801980 292.416  291.0  20.600906 19.2738 #> 18:                 1     2   0.070175439 294.685  291.0  29.652944 28.1694 #> 19:                 1     1   0.383928571 312.347  307.0  52.500656 50.4084 #> 20:                 1     0   1.000000000 377.870  363.0 106.473272 93.4038 #>         q5 q20    q35   q50    q65 q80    q95      rhat  ess_bulk  ess_tail #>  1: 149.00 149 149.00 149.0 149.00 149 149.00        NA        NA        NA #>  2: 166.00 166 167.00 167.0 168.00 168 170.00 0.9984731 1072.5191 1068.0041 #>  3: 133.00 134 135.00 136.0 136.00 137 139.00 1.0001748 1040.7197 1025.8570 #>  4: 138.00 139 140.00 141.0 142.00 143 145.00 0.9985918 1021.8261  829.9055 #>  5: 141.00 143 145.00 146.0 147.00 148 152.00 1.0014625 1036.5263  915.7683 #>  6:  99.00 101 102.00 103.0 105.00 106 109.00 1.0008170 1084.2564  888.0770 #>  7:  59.00  61  62.00  63.0  64.00  65  68.00 1.0001596 1170.0810  845.5932 #>  8: 179.00 182 183.00 185.0 186.00 188 192.00 1.0016498  826.3595  989.6300 #>  9: 246.00 251 253.00 256.0 258.00 261 267.00 1.0008653  976.1162  943.8214 #> 10: 256.00 261 264.00 267.0 270.00 274 281.00 1.0020121 1016.2724  988.2011 #> 11: 224.00 229 233.00 235.5 239.00 243 251.00 0.9993738 1119.8109  785.8675 #> 12: 216.00 223 227.00 230.0 234.00 239 247.00 0.9997526 1067.0426  980.9775 #> 13: 150.00 157 161.00 165.0 168.00 173 184.00 0.9989137 1252.9097  836.7735 #> 14: 116.00 122 126.00 129.0 132.00 136 144.00 1.0002835 1111.6597  956.2202 #> 15: 276.00 283 288.00 292.0 297.00 303 316.00 0.9993443 1076.8727  782.2336 #> 16: 271.00 279 286.00 292.0 297.00 305 320.05 1.0000165 1040.5391  767.7477 #> 17: 263.00 275 283.00 291.0 298.35 309 331.00 1.0007083  950.4381  731.4047 #> 18: 251.95 270 282.00 291.0 302.00 318 347.05 1.0031517 1230.4660  982.6347 #> 19: 237.00 269 287.65 307.0 327.00 351 403.15 1.0029817 1076.9075  871.5941 #> 20: 239.95 292 327.00 363.0 401.00 451 576.15 1.0034715 1394.6975  915.4979  # Nowcast posterior samples summary(nowcast, type = \"nowcast_samples\") #>        reference_date report_date .group max_confirm location age_group confirm #>     1:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>     2:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>     3:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>     4:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>     5:     2021-08-03  2021-08-22      1         149       DE       00+     149 #>    ---                                                                          #> 19996:     2021-08-22  2021-08-22      1          45       DE       00+      45 #> 19997:     2021-08-22  2021-08-22      1          45       DE       00+      45 #> 19998:     2021-08-22  2021-08-22      1          45       DE       00+      45 #> 19999:     2021-08-22  2021-08-22      1          45       DE       00+      45 #> 20000:     2021-08-22  2021-08-22      1          45       DE       00+      45 #>        cum_prop_reported delay prop_reported .chain .iteration .draw sample #>     1:                 1    19             0      1          1     1    149 #>     2:                 1    19             0      1          2     2    149 #>     3:                 1    19             0      1          3     3    149 #>     4:                 1    19             0      1          4     4    149 #>     5:                 1    19             0      1          5     5    149 #>    ---                                                                      #> 19996:                 1     0             1      2        496   996    350 #> 19997:                 1     0             1      2        497   997    584 #> 19998:                 1     0             1      2        498   998    324 #> 19999:                 1     0             1      2        499   999    385 #> 20000:                 1     0             1      2        500  1000    294  # Nowcast model fit summary(nowcast, type = \"fit\") #>                    variable          mean       median          sd        mad #>   1:                   lp__ -1373.6368700 -1373.315000   6.9527607  6.7532430 #>   2: expr_lelatent_int[1,1]     4.1748223     4.179150   0.1619883  0.1564588 #>   3:           expr_beta[1]     0.3569145     0.364988   0.5764547  0.5484506 #>   4:           expr_beta[2]    -0.3476120    -0.323849   0.5760045  0.5536463 #>   5:           expr_beta[3]    -0.8381675    -0.830248   0.5693749  0.5711331 #>  ---                                                                          #> 852:       pp_inf_obs[16,1]   292.8670000   292.000000  15.2357947 14.8260000 #> 853:       pp_inf_obs[17,1]   292.4160000   291.000000  20.6009063 19.2738000 #> 854:       pp_inf_obs[18,1]   294.6850000   291.000000  29.6529437 28.1694000 #> 855:       pp_inf_obs[19,1]   312.3470000   307.000000  52.5006563 50.4084000 #> 856:       pp_inf_obs[20,1]   377.8700000   363.000000 106.4732720 93.4038000 #>                 q5           q20           q80           q95     rhat  ess_bulk #>   1: -1386.2310000 -1379.0460000 -1367.8760000 -1.362648e+03 1.015041  273.7189 #>   2:     3.8992910     4.0439780     4.3080020  4.432952e+00 1.002543  671.6598 #>   3:    -0.5943839    -0.1192264     0.8382168  1.310382e+00 1.001063  660.0161 #>   4:    -1.2701980    -0.8110838     0.1161202  5.934481e-01 1.002668 1335.8326 #>   5:    -1.8262760    -1.3394920    -0.3511062  7.013007e-02 1.001699 1163.2292 #>  ---                                                                            #> 852:   271.0000000   279.0000000   305.0000000  3.200500e+02 1.000016 1040.5391 #> 853:   263.0000000   275.0000000   309.0000000  3.310000e+02 1.000708  950.4381 #> 854:   251.9500000   270.0000000   318.0000000  3.470500e+02 1.003152 1230.4660 #> 855:   237.0000000   269.0000000   351.0000000  4.031500e+02 1.002982 1076.9075 #> 856:   239.9500000   292.0000000   451.0000000  5.761500e+02 1.003471 1394.6975 #>      ess_tail #>   1: 446.3735 #>   2: 514.3376 #>   3: 535.7780 #>   4: 740.6334 #>   5: 789.4890 #>  ---          #> 852: 767.7477 #> 853: 731.4047 #> 854: 982.6347 #> 855: 871.5941 #> 856: 915.4979  # Posterior predictions summary(nowcast, type = \"posterior_prediction\") #>      reference_date report_date .group max_confirm location age_group confirm #>   1:     2021-07-13  2021-07-13      1          59       DE       00+      21 #>   2:     2021-07-13  2021-07-14      1          59       DE       00+      33 #>   3:     2021-07-13  2021-07-15      1          59       DE       00+      36 #>   4:     2021-07-13  2021-07-16      1          59       DE       00+      40 #>   5:     2021-07-13  2021-07-17      1          59       DE       00+      43 #>  ---                                                                          #> 626:     2021-08-20  2021-08-21      1         171       DE       00+     159 #> 627:     2021-08-20  2021-08-22      1         171       DE       00+     171 #> 628:     2021-08-21  2021-08-21      1         112       DE       00+      69 #> 629:     2021-08-21  2021-08-22      1         112       DE       00+     112 #> 630:     2021-08-22  2021-08-22      1          45       DE       00+      45 #>      cum_prop_reported delay new_confirm prop_reported   mean median        sd #>   1:         0.3559322     0          21    0.35593220 19.346     18  8.783133 #>   2:         0.5593220     1          12    0.20338983 20.514     19  9.362236 #>   3:         0.6101695     2           3    0.05084746  6.038      6  3.282275 #>   4:         0.6779661     3           4    0.06779661  4.102      4  2.592357 #>   5:         0.7288136     4           3    0.05084746  2.370      2  1.829330 #>  ---                                                                           #> 626:         0.9298246     1          61    0.35672515 83.928     80 34.506949 #> 627:         1.0000000     2          12    0.07017544 12.644     11  6.681610 #> 628:         0.6160714     0          69    0.61607143 74.909     70 32.940428 #> 629:         1.0000000     1          43    0.38392857 48.384     45 21.248248 #> 630:         1.0000000     0          45    1.00000000 41.418     38 19.492389 #>          mad    q5  q20 q35 q50 q65   q80    q95      rhat  ess_bulk  ess_tail #>   1:  8.8956  7.00 12.0  15  18  21  26.0  35.00 0.9983637  932.3646  881.3256 #>   2:  8.8956  8.00 12.0  16  19  23  27.2  38.00 1.0011134 1015.9391  735.8017 #>   3:  2.9652  2.00  3.0   4   6   7   9.0  12.00 0.9992062 1084.5500 1021.5623 #>   4:  2.9652  1.00  2.0   3   4   5   6.0   9.00 1.0029845  784.8228  875.2947 #>   5:  1.4826  0.00  1.0   1   2   3   4.0   6.00 1.0010223  901.9783  995.0932 #>  ---                                                                           #> 626: 34.0998 37.95 54.0  67  80  94 110.0 147.05 0.9996878  948.3040  881.5462 #> 627:  5.9304  4.00  7.0   9  11  14  18.0  25.00 1.0002821 1086.3185  891.6927 #> 628: 29.6520 33.00 47.8  58  70  82  98.0 137.05 1.0027174 1147.8921  986.6337 #> 629: 19.2738 21.00 31.0  38  45  53  63.0  90.05 1.0014923  944.8684  966.2908 #> 630: 17.7912 16.00 25.0  32  38  46  55.0  79.00 0.9984329 1035.6813  850.9586"},{"path":"package.epinowcast.org/dev/reference/write_stan_files_no_profile.html","id":null,"dir":"Reference","previous_headings":"","what":"Write copies of the .stan files of a Stan model and its #include files with all profiling statements removed. — write_stan_files_no_profile","title":"Write copies of the .stan files of a Stan model and its #include files with all profiling statements removed. — write_stan_files_no_profile","text":"Write copies .stan files Stan model #include files profiling statements removed.","code":""},{"path":"package.epinowcast.org/dev/reference/write_stan_files_no_profile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write copies of the .stan files of a Stan model and its #include files with all profiling statements removed. — write_stan_files_no_profile","text":"","code":"write_stan_files_no_profile(   stan_file,   include_paths = NULL,   target_dir = tempdir() )"},{"path":"package.epinowcast.org/dev/reference/write_stan_files_no_profile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write copies of the .stan files of a Stan model and its #include files with all profiling statements removed. — write_stan_files_no_profile","text":"stan_file path .stan file containing Stan program. include_paths Paths directories Stan look files specified #include directives Stan program. target_dir path directory manipulated .stan files without profiling statements stored. avoid overriding original .stan files, different directory original model include_paths.","code":""},{"path":"package.epinowcast.org/dev/reference/write_stan_files_no_profile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write copies of the .stan files of a Stan model and its #include files with all profiling statements removed. — write_stan_files_no_profile","text":"list containing path .stan file without profiling statements include_paths included .stan files without profiling statements","code":""},{"path":[]},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-023","dir":"Changelog","previous_headings":"","what":"epinowcast 0.2.3","title":"epinowcast 0.2.3","text":"release development yet ready production use.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"contributors-0-2-3","dir":"Changelog","previous_headings":"","what":"Contributors","title":"epinowcast 0.2.3","text":"@medewitt, @adrian-lison, @seabbs contributed code release. @adrian-lison, @seabbs reviewed pull requests release. @jbracher, @medewitt, @pearsonca, @bisaloo, @parksw3, @adrian-lison, @seabbs reported bugs, made suggestions, contributed discussions led improvements release.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"bugs-0-2-3","dir":"Changelog","previous_headings":"","what":"Bugs","title":"epinowcast 0.2.3","text":"Fixed bug identified @jbracher enw_expectation() module appropriately defining initial conditions multiple groups present. issue related recent changes cmdstan 2.32.1 required order use versions cmdstan beyond 2.32.0 models contain multiple time series. See #282 @seabbs self-reviewed. Fixed typos model vignette. See #292 @medewitt reviewed @seabbs. Fixed bug snapshots (.e. returned metadata enw_preprocess_data()) defined based report vs reference date. won’t impacted usage problem trying fit model retrospective (completely reported) data. See #312 @seabbs self-reviewed.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"package-0-2-3","dir":"Changelog","previous_headings":"","what":"Package","title":"epinowcast 0.2.3","text":"Added additional tests ensure enw_expectation() module appropriately defining initial conditions multiple groups present. See #282 @seabbs self-reviewed. Added integration test epinowcast() check models multiple time series can fit expected example data. See #282 @seabbs reviewed @adrian-lison. Added {touchstone} benchmark includes multiple time-series ensure functionality appropriately tested. See #282 @seabbs reviewed @adrian-lison. Added merge_group option required GitHub Actions. enables use merge queue pull requests. See #300 @seabbs self-reviewed. Added internal check_group_date_unique() function ensures user supplied groups result unique combinations group dates. function used enw_preprocess_data() enw_complete_dates() ensure user supplied groups valid. See #295 @adrian-lison reviewed @seabbs. Added support non-daily reference date models (.e., process models). example, allows modelling weekly data weekly. may desirable delays long, computational resources limited, possible specify sufficiently flexible daily model account observed reporting patterns either reference report dates. model unit less entails changes model . See #303 @seabbs self-reviewed. Added new helper function simulate_double_censored_pmf() helps users define “correct” probability mass functions double censored delays based work epidist @parksw3 @seabbs. Note function likely spun package near future. See #312 @seabbs self-reviewed.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"model-0-2-3","dir":"Changelog","previous_headings":"","what":"Model","title":"epinowcast 0.2.3","text":"Update internal handling PMF discretisation assume uniform window two days centred delay interest rather window one day starting delay interest. better approximates underlying continuous distribution primary secondary event censoring. Due change models may perform slightly differently versions delay distribution estimates means half day longer (note corrects previous bias). See #288 @seabbs reviewed @adrian-lison. Updated default prior initialising model include ascertainment rate inferred latent reporting delay distribution can improper probability mass function (.e. one sum 1). See #312 @seabbs self-reviewed.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"documentation-0-2-3","dir":"Changelog","previous_headings":"","what":"Documentation","title":"epinowcast 0.2.3","text":"Updated distributions vignette match updated handling discretisation. See #288 @seabbs reviewed @adrian-lison. Updated use citation() function README command shown users output treated like normal text. See #272 @seabbs self-reviewed. Added vignette walking estimate effective reproduction number real-time (comparing retrospective estimates) data source right truncated. See #312 @seabbs self-reviewed. Switched using bookdown pkgdown vignettes moved flatly theme pkgdown rather preferably theme. See #312 @seabbs self-reviewed.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-022","dir":"Changelog","previous_headings":"","what":"epinowcast 0.2.2","title":"epinowcast 0.2.2","text":"minor release fixes bug handling optional initial conditions introduced recent change cmdstan 2.32.1. Upgrading recommended users wish use versions cmdstan beyond 2.32.0. addition fixing issue, release also includes minor documentation vignette improvements, along enhancements input checking.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"contributors-0-2-2","dir":"Changelog","previous_headings":"","what":"Contributors","title":"epinowcast 0.2.2","text":"@sbfnk @seabbs contributed code release. @seabbs reviewed pull requests release. @sbfnk @seabbs reported bugs, made suggestions, contributed discussions led improvements release.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"bugs-0-2-2","dir":"Changelog","previous_headings":"","what":"Bugs","title":"epinowcast 0.2.2","text":"Improved handling optional initial conditions consistently passed arrays stan required cmdstan 2.32.1. fix required order use versions cmdstan beyond 2.32.0. See #276 @seabbs self-reviewed.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"package-0-2-2","dir":"Changelog","previous_headings":"","what":"Package","title":"epinowcast 0.2.2","text":"Added input checking max_delay enw_preprocess_data() ensure maximum delay greater equal 1 can coerced integer. See #274 @sbfnk reviewed @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"documentation-0-2-2","dir":"Changelog","previous_headings":"","what":"Documentation","title":"epinowcast 0.2.2","text":"Improved discrete delay distributions vignette including escaping functions improve readibility right-closing discretised bins. See #275 @sbfnk reviewed @seabbs. Improved documentation max_delay enw_preprocess_data() fixed typo documentation. See #274 @sbfnk reviewed @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-021","dir":"Changelog","previous_headings":"","what":"epinowcast 0.2.1","title":"epinowcast 0.2.1","text":"release, focused improving internal code structure, documentation, development infrastructure package make easier maintain extend functionality future. also fixed number bugs made minor improvements interface. changes included extending test documentation coverage across package functions, improving internal data checking internalization, removing deprecated functions. changes expected impact users, recommend users upgrade version. also suggest users fitted models random effects random walks refit models compare output previous fits order understand impact bug specification models fixed release. release lays groundwork planned features 0.3.0 0.4.0 including: support non-parametric delays, non-daily data non-daily process model (.e. weekly data weekly process model), additional flexibility specifying generation times latent reporting delays, improved case studies, adding support forecasting. Full details changes release can found following sections GitHub release notes. see development timeline release see 0.2.1 project.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"contributors-0-2-1","dir":"Changelog","previous_headings":"","what":"Contributors","title":"epinowcast 0.2.1","text":"@adrian-lison, @Bisaloo, @pearsonca, @FelixGuenther, @Lnrivas, @seabbs, @sbfnk, @jhellewell14 made code contributions release. @pearsonca, @Bisaloo, @adrian-lison, @seabbs reviewed pull requests release. @Gulfa, @WardBrian, @parkws3, @adrian-lison, @Bisaloo, @pearsonca, @FelixGuenther, @Lnrivas, @seabbs, @sbfnk @jhellewell14 reported bugs, made suggestions, contributed discussions led improvements release.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"potentially-breaking-changes-0-2-1","dir":"Changelog","previous_headings":"","what":"Potentially breaking changes","title":"epinowcast 0.2.1","text":"enw_add_pooling_effect(): replaced string argument ... argument, enable passing arbitrary arguments finder_fn argument. general usage supported, now e.g. default argument supply prefix = \"somevalue\" vs string = \"somevalue\" argument positions changed. function primarily internal use expect small subset advanced users creating models outside currently supported formula interface impacted See #222 @pearsonca reviewed @seabbs. enw_dates_to_factors(): Deprecated removed longer needed. expect function little external use little impact users. See #216 @seabbs reviewed @adrian-lison.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"bugs-0-2-1","dir":"Changelog","previous_headings":"","what":"Bugs","title":"epinowcast 0.2.1","text":"Fixed bug first highlighted @Gulfa #166 localised investigation #223 random effects random walks improperly constructed enw_formula() variances parameters shared correct parameters used together. impacts models used formulas random effects random walks models appears led increased run-times, fitting issues, potentially unreliable posterior estimates less significant impact actual nowcasts. suggest refitting models comparing output previous fits order understand impact usage. See #228 @seabbs self-reviewed. Fixed bug enw_replace_priors() function deal epinowcast summarised posterior estimates due new use pillar class. Added tests catch issue reoccurs future. See #228 @seabbs self-reviewed. Fixed issue (#198) interface scoringutils. unknown reason example data contained pillar classes (likely due upstream change). caused issue internal scoringutils using implicit type conversion (see ). See #201 @seabbs reviewed @pearsonca. Fixed bug enw_plot_quantiles() documented default log FALSE actual default TRUE. See #209 @seabbs self-reviewed. Fixed bug enw_expectation() models specified zero intercept initial condition still specified intercept growth rate (expr_r_int, #246). flagged issue cmdstan 2.31.0 cmdstan 2.32.0, due improvements initial conditions read (stan-dev/stan#3182), throws error causing models fail. Solution suggested @WardBrian, implemented #255 @seabbs, reviewed @pearsonca.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"depreciations-0-2-1","dir":"Changelog","previous_headings":"","what":"Depreciations","title":"epinowcast 0.2.1","text":"enw_incidence_to_cumulative(): Deprecated warning favour enw_add_cumulative(). renaming better reflect function’s purpose. enw_incidence_to_cumulative() removed 0.3.0. See #247 @seabbs reviewed @pearsonca. enw_cumulative_to_incidence(): Deprecated warning favour enw_add_incidence(). renaming better reflect function’s purpose. enw_cumulative_to_incidence() removed 0.3.0. See #247 @seabbs reviewed @pearsonca.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"package-0-2-1","dir":"Changelog","previous_headings":"","what":"Package","title":"epinowcast 0.2.1","text":"Fixed typos README.md, NEWS.md, model.Rmd vignette convolution_matrix() documentation. WORDLIST used spelling also updated eliminate false positives. See #221 @Bisaloo reviewed @seabbs @adrian-lison. Added non-default linters .lintr configuration file. file used lintr::lint_package() run new lint-changed-files.yaml GitHub Actions workflow. See #220 @Bisaloo reviewed @pearsonca @seabbs. Switched lint-changed-files.yaml GitHub Actions workflow instead regular lint.yaml avoid annotations unrelated changes made PR. See #220 @Bisaloo reviewed @pearsonca @seabbs. Added tests summary.epinowcast() plot.epinowcast() methods. See #209 @seabbs reviewed @pearsonca. Added tests enw_plot_obs() otherwise covered plot.epinowcast() tests. See #209 @seabbs reviewed @pearsonca. Refactored consolidate data checking internalization single internal function coerce_dt(), addressing issues #242, #241, #214, #149. eliminates need add_group(), check_by(), check_dates() (associated documentation, tests - intermediate capabilities introduced within minor version; see #208) removed. Also starts enable internal versus external use exposed methods copy = ... argument. See #239 @pearsonca, reviewed @seabbs. Resolved spurious test warnings snapshot tests linked unstated formatting requirements. See #208 @seabbs reviewed @pearsonca. Removed unused internal plot helpers. See #217 @seabbs reviewed @adrian-lison. Added tests internal check_ functions used check inputs. See #217 @seabbs reviewed @adrian-lison. Removed problematic double specification default arguments target_date enw_metadata() flagged #212 @pearsonca using formals() instead detect default values function specification. See #232 @seabbs self-reviewed. words Jenny Bryan: “else, .” else return() stop() increases number branches code, makes harder read. also translates higher cyclomatic complexity. removed else statements return() stop() package. See #229 @Bisaloo reviewed @seabbs. Removed internal definition no_contrasts enw_formula() unused. Identified @bisaloo #220 raised #223. See #228 @seabbs self-reviewed. Added tests enw_replace_priors() check can handle epinowcast summarised posterior estimates. See #228 @seabbs self-reviewed. Added prefix (rw__) enw_formula() construct_rw() indicate random effect variance random walk versus random effect. See #228 @seabbs reviewed . Added support using variable random effect random walk. settings advised. See #228 @seabbs self-reviewed. Added error message construct_rw() random walk specified variable numeric variable. See #228 @seabbs self-reviewed. Added support preprocessing model fitting benchmarking using touchstone based implementation EpiNow2 @sbfnk. See #200 @seabbs, @adrian-lison, @sbfnk, self-reviewed. Added complete set data converters map line list (.e. row case) count data (.e incidence cumulative counts reference report date). particular, help workflows individual line list data available can now formatted ready preprocessing using single call enw_linelist_to_incidence() previously took several steps. See #247 @seabbs @jhellewell14 reviewed @pearsonca. Dropped use develop branch development versions package. change discussed #250 major motivator since introduction release builds R Universe longer need stable main branch GitHub control releases. See #256 @seabbs reviewed @Bisaloo @pearsonca. Cleaned enw_formula_as_data_list() better align DRY principles. See #245 @Lnrivas, reviewed @pearsonca, @Bisaloo, @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"documentation-0-2-1","dir":"Changelog","previous_headings":"","what":"Documentation","title":"epinowcast 0.2.1","text":"Added examples summary.epinowcast() plot.epinowcast() methods documentation. See #209 @seabbs reviewed @pearsonca. Extended documentation, examples, tests internal, preprocessing, postprocessing functions. See #208 @seabbs reviewed @pearsonca. Added examples plot functions. See #209 @seabbs reviewed @pearsonca. Added example enw_replace_priors() showing use nowcast posterior update default priors. See #228 @seabbs self-reviewed. Updated package citation documentation include new authors 0.2.1 release use recommended bibentry() approach. See #236 #237 @seabbs reviewed @Bisaloo. Added package style guide (STYLE_GUIDE.md) document style conventions used package. See #64 @seabbs reviewed @pearsonca @Bisaloo. Improved extended documentation discretized, parametric delay distributions. Changed structure package vignettes (two categories, model definition vignettes case study vignettes). See #265 @FelixGuenther @adrian-lison reviewed @seabbs. Improved extended README quick start feedback @parksw3 #260. See #267 @seabbs reviewed @adrian-lison @parksw3.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-020","dir":"Changelog","previous_headings":"","what":"epinowcast 0.2.0","title":"epinowcast 0.2.0","text":"release adds several extensions modelling framework, including modelling missing data, flexible modelling generative process underlying case counts, optional renewal equation-based generative process (enabling direct estimation effective reproduction number), convolution-based latent reporting delays (enabling modelling directly observed unobserved delays well partial ascertainment). Much methodology used extensions based work done Adrian Lison currently evaluated. top model extensions release also adds range quality life features, helper functions constructing convolution matrices combining probability mass functions. also comes improved computational efficiency, thanks refactoring hazard model computations log scale extended parallelisation likelihood optimised structure input data. also extended package documentation streamlined contribution process. large-scale project, package remains experimental state, though sufficiently stable research production usage. core development needed improve post-processing, pre-processing, documentation coverage, evaluate optimal configurations different settings) please see community site, contributing guide, list issues/proposed features interested involved (scale contribution warmly welcomed including user feedback, requests extend functionality cover setting, evaluating package context). community project needs support users order provide improved tools real-time infectious disease surveillance. thank @adrian-lison, @choi-hannah, @sbfnk, @Bisaloo, @seabbs, @pearsonca, @pratikunterwegs code contributions release. also thank community members contributions including @jhellewell14, @FelixGuenther, @parksw3, @jbracher. Full details changes release can found following sections.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"package-0-2-0","dir":"Changelog","previous_headings":"","what":"Package","title":"epinowcast 0.2.0","text":"Added .Rhistory .gitignore file. See #132 @choi-hannah. Fixed indentations authors contributors DESCRIPTION file. See #132 @choi-hannah. Renamed enw_new_reports() enw_cumulative_to_incidence() added reverse function enw_incidence_to_cumulative() functions use argument allow specification variable groupings. See #157 @seabbs. Switched class checking inherits(x, \"class\") rather class(x) %% \"class\". See #155 @Bisaloo. Changed enw_add_metaobs_features() interface holidays argument series dates. Changed interface enw_preprocess_data() pass ... enw_add_metaobs_features(). Interface changes come internal rewrite unit tests. part internal rewrite, introduces coerce_date() R/utils.R, wraps data.table::.IDate() error handling. See #151 @pearsonca. Changed style using match.arg validating inputs. Briefly, preference now define options via function arguments validate automatic match.arg idiom corresponding enumerated documentation options. idiom, first item definition default. approach applies string-based arguments; different types arguments matched way, can arguments allow vector-valued options (e.g., somearg = c(\"option1\", \"option2\") legal argument indicating use options). See #162 @pearsonca addressing issue #156 @Bisaloo. Refined use data ordering throughout preprocessing functions. See #147 @seabbs. Skipped tests use cmdstan locally improve developer/contributor experience. See #147 @seabbs @adrian-lison. Added basic simulator function missing reference data. See #147 @seabbs @adrian-lison. Added support right hand side interactions syntax sugar random effects. allows specification , example, independent random effects day strata another variable. See #169 @seabbs. Added support passing cpp_options cmdstanr::cmdstan_model(). See #182 @seabbs. Add function, convolution_matrix() constructing convolution matrices. See #183 @seabbs. Add pass enw_model() write_stan_files_no_profile() target_dir argument. allows users compile model share compiled model across sessions rather recompile time temporary directory cleared. See #185 @seabbs. Added add_pmfs(), sum probability mass functions new probability mass function. Initial implementation @seabbs #183, refactored @pratikunterwegs #187, following suggestion issue #186 @pearsonca. Added warning observed empirical maximum delay less specified maximum delay. See #190 @seabbs. Added nested support converting array syntax convert_cmdstan_to_rstan. See #192 @sbfnk.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"model-0-2-0","dir":"Changelog","previous_headings":"","what":"Model","title":"epinowcast 0.2.0","text":"Added support parametric log-logistic delay distributions. See #128 @adrian-lison. Implemented direct specification parametric baseline hazards. See #134 @adrian-lison. Refactored observation model, combination logit hazards, effects priors contained generic functions make extending package functionality easier. See #137 @seabbs. Implemented specification parametric baseline hazards probabilities log scale increase robustness efficiency. Also includes refactoring functions reorganisation inst/stan/epinowcast.stan increase modularity clarity. See #140 @seabbs. Introduced two new delay likelihoods delay_snap_lmpf delay_group_lmpf. stratify either snapshots groups. helpful models (missingness module). ability choose function used exposed user enw_fit_opts() via likelihood_aggregation argument. functions rely newly added expected_obs_from_snaps function vectorises expected_obs_from_index. See #138 @seabbs @adrian-lison. Added support supplying missingness model parameters model well optional priors effect estimation. See #138 @seabbs @adrian-lison. Refactored model generated quantities functional. See #138 @seabbs @adrian-lison. Added support modelling missing reference dates likelihood. See #147 @seabbs @adrian-lison. Added additional functionality delay_group_lmpf support modelling observations missing reference dates. Also updated generated quantities support mode. See #147 @seabbs @adrian-lison based #64 @adrian-lison. Added flexible expectation process growth rate scale. default expectation model updated group-wise random walk growth rate. See #152 @seabbs @adrian-lison. Added deterministic renewal equation, latent reporting process. See #152 #183 @seabbs @adrian-lison. Added support intercept expectation model general formula support enable feature modules going forward. See #170 @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"documentation-0-2-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"epinowcast 0.2.0","text":"Removed explicit links authors issues NEWS.md file. See #132 @choi-hannah. Added new example using simulated data enw_missing() model module. See #138 @seabbs @adrian-lison. Update model definition vignette include missing reference date model. See #147 @seabbs @adrian-lison. Added use expectation model “Hierarchical nowcasting age stratified COVID-19 hospitalisations Germany” vignette. See #193 @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"bugs-0-2-0","dir":"Changelog","previous_headings":"","what":"Bugs","title":"epinowcast 0.2.0","text":"probability-model (.e parametric distribution used hence hazard scale needed) used due mistake specifying ref_as_p stan code. additional issue enw_report() module currently self-declares regardless . bug impact results increased runtimes simple models. issues fixed #142 @seabbs. addition meta features week month properly sequentially number weeks months time series crossed year boundaries. impact models included effects expecting fact sequentially numbered (e.g. random walks). Fixed #151 @pearsonca. #151 also corrects minor issue enw_example() pointing old file name type=\"script\". @pearsonca.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-010","dir":"Changelog","previous_headings":"","what":"epinowcast 0.1.0","title":"epinowcast 0.1.0","text":"major release focusing improving user experience, preparing future package extensions, increase modularity, development flexible full-featured formula interface, hopefully future-proofing far possible. prepares ground future model extensions allow broad range real-time infectious disease questions better answered. extensions include: Modelling missing data (#43). Non-parametric modelling delay reference date logit hazard (#4). Flexible expectation modelling (#5). Forecasting beyond horizon data (#3). Known reporting structures (#33). Renewal equation-based reproduction number estimation (potentially part #5). Latent infections (.e implemented packages EpiNow2, epidemia, etc.). Convolution-based delay models (.e hospitalisations deaths) partially reported data. Additional observation models. interested contributing features, aspects package development (example improving post-processing, coverage documentation, contributing case studies) please see contributing guide /just reach . community project needs support users order provide improved tools real-time infectious disease surveillance. release contains multiple breaking changes. needing old interface please install 0.0.7 GitHub. ease, stratified changes interface, package, documentation, model changes. Note package still flagged experimental regular use authors. @adrian-lison, @sbfnk, @seabbs contributed release.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"interface-0-1-0","dir":"Changelog","previous_headings":"","what":"Interface","title":"epinowcast 0.1.0","text":"fully featured flexible formula interface added allows specification fixed effects, lme4 random effects, random walks. See #27 @seabbs. major overhaul, described #57, interface epinowcast() particular focus improving modularity model components (described modules documentation). package documentation vignettes updated reflect new interface. See #112 @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"package-0-1-0","dir":"Changelog","previous_headings":"","what":"Package","title":"epinowcast 0.1.0","text":"Renamed package updated description give clarity problem space focusses . See #110 @seabbs. new helper function enw_delay_metadata() added. produces metadata delay distribution vector may helpful future modelling. prepares way #4 data.frame combined reference metadata order build non-parametric hazard reference delay-based models. addition adding function, also added output enw_preprocess_data() order make metadata readily available end-users. See #80 @seabbs. Two new helper functions enw_filter_reference_dates() enw_filter_report_dates() added. replace enw_retrospective_data() allow users similarly construct retrospective data. Splitting functions components also allows additional use cases previously possible. Note definition assumed report date given reference date must equal greater (.e report happen event reported occurs). See #82 @sbfnk @seabbs. internal grouping variables refactored reduce chance clashes columns data.frames supplied user. also error thrown case variable clash, making preprocessing safer. See #102 @adrian-lison @seabbs, solves #99. Support preprocessing observations missing reference dates added along new data object returned enw_preprocess_data() highlights information user (alternatively can accessed users using enw_missing_reference()). addition, missing observations setup passed stan order allow use modelling. feature preparation adding full support missing observations (see #43). See #106 @adrian-lison @seabbs. discretised reporting probability function extended handle delays beyond maximum delay three different ways: ignore, add maximum, normalize. nowcasting model uses “normalise” though work ongoing. See #113 @adrian-lison #121 @seabbs. Fixed issue (#105) cmdstan 2.30.0 passing optimisation flags stanc_options default causing compilation error passing flags default. See #117 @sbfnk @seabbs. Addition regression/integration tests example data epinowcast() enw_preprocess_data() convergence checking several example nowcasting models. Lower level tests model tools model modules also added. See #112 @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"model-0-1-0","dir":"Changelog","previous_headings":"","what":"Model","title":"epinowcast 0.1.0","text":"Added support parametric exponential delay distributions (note comparable intercept-non-parametric hazard model) potentially parametric delay (though currently throw error due lack appropriate non-parametric hazard). See #84 @seabbs. Added support Poisson observation model though recommended users make use default negative binomial model. See #120 @seabbs. Updated expectation random walk model use efficient cumulative_sum implementation suggested @adrian-lison #98. See #103 @seabbs. Aligned implementation overdispersion prior prior choice recommendations stan wiki. See #111 @adrian-lison.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"documentation-0-1-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"epinowcast 0.1.0","text":"model description updated reflect currently implemented model improve readability. use reference report date nomenclature also standardised across package. See #71 @sbfnk @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"internals-0-1-0","dir":"Changelog","previous_headings":"","what":"Internals","title":"epinowcast 0.1.0","text":"Array declarations stan model updated. maintain compatibility expose_stan_fns() (depends rstan), additional functionality added parse stan code function. See #74, #85, #93 @sbfnk @seabbs. Remove spurious warnings due missing initial values optional parameters. See #76 @sbfnk @seabbs.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-007","dir":"Changelog","previous_headings":"","what":"epinowcast 0.0.7","title":"epinowcast 0.0.7","text":"Adds additional quality life data processing maximum number (max_confirm) notifications available every row (cumulative incidence notifications) cumulative daily empirical proportion reported calculated user pre-processing (see #62 @seabbs). default approach handling reported notifications beyond maximum delay changed. 0.0.6 previous versions notifications beyond maximum delay silently dropped. 0.0.7 now optional behaviour (set using max_delay_strat enw_preprocess_data()) default instead add notifications last included delay present. produce accurate long-term nowcasts data available means reported notifications maximum delay need interpreted mind. See #62 @seabbs. Adds basic testing documentation preprocessing functions. See #62 @seabbs. Stabilises calculation expected observations increasing proportion calculation performed log scale. results reduced computation time majority coming switching using neg_binomial_2_log family functions (natural scale counterparts). See #65 @seabbs","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-006","dir":"Changelog","previous_headings":"","what":"epinowcast 0.0.6","title":"epinowcast 0.0.6","text":"Simplifies optimises internal functions used estimate parametric daily reporting probability. now exposed user via distribution parameter Lognormal Gamma families tested work. Note parameterisations use standard parameterisations given stan manual (see #42 @adrian-lison @seabbs) Add profiling switch model compilation, allowing toggle profiling (https://mc-stan.org/cmdstanr/articles/profiling.html) /model. Also supports .stan files found include_paths (see #41 #54 @adrian-lison). Fully vectorise likelihood flattening observations pre-specify expected observations vector calculating log-likelihood (see #40 @seabbs). Adds vectorisation zero truncated normal distributions (see #38 @seabbs) hazard_to_prob optimised using vectorisation (see #53 @adrian-lison @seabbs). prob_to_hazard optimised required cumulative probabilities calculated (see #53 @adrian-lison @seabbs). Updated use inv_sqrt stan function (see #60 @seabbs). Added support scoringutils 1.0.0 (see #61 @seabbs). Added basic example helper function, enw_example(), power examples tests based work done forecast.vocs (see #61 @seabbs).","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-005","dir":"Changelog","previous_headings":"","what":"epinowcast 0.0.5","title":"epinowcast 0.0.5","text":"Convert retrospective data date fields class IDate utilising enw_retrospective_data solve esoteric error. Added full argument name include_paths avoid console chatter Adds stanc_options argument enw_model() specifies new default list(\"01\") enables simple pre-compilation optimisations. See optimisation details. Remove inv_logit logit may instead use base R plogit qlogit.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-004","dir":"Changelog","previous_headings":"","what":"epinowcast 0.0.4","title":"epinowcast 0.0.4","text":"Add support extracting summarising posterior nowcast samples Package spell check Update read quick start use 40 days delay vs 30 Add section read quick start showing example handling nowcast samples. Add support passing custom models included files enw_model(). Fix bug enw_summarise_samples() returned duplicate samples. Add support passing holidays variable adjusting converting holiday day custom day week (default Sunday set user). Added support scoring natural log scale. represents absolute relative scoring respectively.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-003","dir":"Changelog","previous_headings":"","what":"epinowcast 0.0.3","title":"epinowcast 0.0.3","text":"Add support passing priors Add case study vignette Add model definition implementation details. Add support sample scoring (using scoringutils).","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-002","dir":"Changelog","previous_headings":"","what":"epinowcast 0.0.2","title":"epinowcast 0.0.2","text":"Initial version package broadly working functionality first draft vignettes.","code":""},{"path":"package.epinowcast.org/dev/news/index.html","id":"epinowcast-001","dir":"Changelog","previous_headings":"","what":"epinowcast 0.0.1","title":"epinowcast 0.0.1","text":"Initial package version development code","code":""}]
